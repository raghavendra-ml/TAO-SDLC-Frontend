import os
import json
import sys
from typing import Dict, Any, List, Tuple
from dotenv import load_dotenv
from openai import AsyncOpenAI

# Fix encoding issue for emojis
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

load_dotenv()

class AIService:
    def __init__(self):
        self.api_key = os.getenv("OPENAI_API_KEY")
        self.client = AsyncOpenAI(api_key=self.api_key)
    
    def _extract_technologies_from_text(self, text: str) -> set:
        """
        DYNAMIC technology extraction - NO HARDCODED LISTS.
        Extract ANY technology/tool/platform mentioned in text using pattern recognition.
        This ONLY finds what's explicitly mentioned, nothing else.
        
        Strategy: Look for words that typically indicate technologies/tools:
        - ALL-CAPS words (SQL, API, etc.)
        - Words followed by version numbers (Node v14, Python 3.11, etc.)
        - Known technology naming patterns (service names, product names in quotes)
        - Capitalized tech names (PostgreSQL, MongoDB, Redis, etc.)
        """
        if not text or not isinstance(text, str):
            return set()
        
        found_tech = set()
        words = text.split()
        
        for i, word in enumerate(words):
            word_clean = word.strip('.,;:!?()-[]{}"\'"')
            word_lower = word_clean.lower()
            
            # Pattern 1: Capitalized words that look like tech products
            # Examples: PostgreSQL, MongoDB, Node.js, React, Docker, Kubernetes
            if word_clean and word_clean[0].isupper() and len(word_clean) > 2:
                # Check if it looks like a technology product name
                if any(indicator in word_lower for indicator in [
                    'sql', 'db', 'api', 'server', 'service', 'framework', 
                    'language', 'platform', 'cache', 'queue', 'messaging',
                    'auth', 'gateway', 'monitor', 'log', 'storage', 'cloud',
                    'container', 'orchestr', 'deploy', 'ci/', 'cd', 'broker',
                    'search', 'stream', 'queue', 'store'
                ]):
                    found_tech.add(word_clean)
            
            # Pattern 2: ALL CAPS abbreviations (longer than 2 chars to avoid FI, OR, etc.)
            if word_clean.isupper() and len(word_clean) > 2 and len(word_clean) < 10:
                found_tech.add(word_clean)
            
            # Pattern 3: Words with version numbers (indicates a specific tech)
            # Examples: Node.js, Python 3.11, Java8, etc.
            if any(char.isdigit() for char in word_clean):
                if word_lower not in ['2024', '2023', '2022', '2021', '2020', '2019']:  # Exclude years
                    if len(word_clean) > 2:
                        found_tech.add(word_clean)
            
            # Pattern 4: Check next word - if current word is "technology" or similar
            # and next word is capitalized, extract the next word
            if i < len(words) - 1:
                if word_lower in ['technology:', 'tech:', 'use', 'uses', 'using', 'with', 'based', 'on']:
                    next_word = words[i + 1].strip('.,;:!?()-[]{}"\'"')
                    if next_word and next_word[0].isupper():
                        found_tech.add(next_word)
        
        # Filter out common non-tech words
        non_tech_words = {
            'The', 'This', 'That', 'These', 'Those', 'A', 'An', 'And', 'Or', 'But',
            'For', 'From', 'To', 'In', 'On', 'At', 'Is', 'Are', 'Was', 'Were',
            'System', 'Application', 'Component', 'Service', 'Layer', 'Module', 'Package',
            'We', 'Our', 'Their', 'It', 'Its', 'I', 'You', 'Your'
        }
        
        found_tech = {t for t in found_tech if t not in non_tech_words and len(t) > 1}
        
        return found_tech
    
    def _generate_fallback_e2e_flows(self, epics: list, user_stories: list, execution_order: list) -> list:
        """
        Generate fallback E2E flow diagrams if AI didn't generate them
        Creates basic but complete flow diagrams based on available data
        """
        try:
            flows = []
            
            # Get first 2-3 user stories for flows
            if user_stories:
                # Flow 1: First story (PRIMARY)
                story1 = user_stories[0] if len(user_stories) > 0 else None
                if story1:
                    flow1_title = f"Foundation: {story1.get('title', 'Primary Flow')[:50]}"
                    flow1_story = story1.get('title', 'N/A')
                    epic_id = story1.get('epic_id', 1)
                    epic_name = "Unknown Epic"
                    for epic in epics:
                        if epic.get('id') == epic_id:
                            epic_name = epic.get('title', 'Unknown')
                            break
                    
                    flow1_mermaid = """graph TD
    U[User] -->|Request| FE[Frontend]
    FE -->|Submit| API[API Gateway]
    API -->|Authenticate| Auth[Auth Service]
    Auth -->|Token Valid| Logic[Business Logic]
    Logic -->|Process| DB[(Database)]
    DB -->|Query Result| Logic
    Logic -->|Response| API
    API -->|Data| FE
    FE -->|Display| U"""
                    
                    flows.append({
                        'title': flow1_title,
                        'user_story': flow1_story,
                        'epic': epic_name,
                        'description': f'Request-Response flow for {flow1_story}',
                        'mermaid': flow1_mermaid
                    })
                
                # Flow 2: Second story (SECONDARY) if available
                if len(user_stories) > 1:
                    story2 = user_stories[1]
                    flow2_title = f"Core Process: {story2.get('title', 'Secondary Flow')[:50]}"
                    flow2_story = story2.get('title', 'N/A')
                    epic_id = story2.get('epic_id', 1)
                    epic_name = "Unknown Epic"
                    for epic in epics:
                        if epic.get('id') == epic_id:
                            epic_name = epic.get('title', 'Unknown')
                            break
                    
                    flow2_mermaid = """graph TD
    U[User Action] -->|Trigger| Service[Service]
    Service -->|Queue Job| Queue[Message Queue]
    Queue -->|Process| Worker[Background Worker]
    Worker -->|Update| DB[(Database)]
    DB -->|Notify| Queue
    Queue -->|Event| WebSocket[WebSocket Server]
    WebSocket -->|Broadcast| U"""
                    
                    flows.append({
                        'title': flow2_title,
                        'user_story': flow2_story,
                        'epic': epic_name,
                        'description': f'Async flow for {flow2_story}',
                        'mermaid': flow2_mermaid
                    })
                
                # Flow 3: If more stories, add one more
                if len(user_stories) > 2:
                    story3 = user_stories[2]
                    flow3_title = f"Advanced: {story3.get('title', 'Advanced Flow')[:50]}"
                    flow3_story = story3.get('title', 'N/A')
                    epic_id = story3.get('epic_id', 1)
                    epic_name = "Unknown Epic"
                    for epic in epics:
                        if epic.get('id') == epic_id:
                            epic_name = epic.get('title', 'Unknown')
                            break
                    
                    flow3_mermaid = """graph TD
    System[System] -->|Data Stream| Processor[Stream Processor]
    Processor -->|Transform| Cache[Cache Layer]
    Cache -->|Check| DB[(Database)]
    DB -->|Update| Cache
    Cache -->|Latest| Client[Client]
    Client -->|Subscribe| WebSocket[WebSocket]
    WebSocket -->|Updates| Client"""
                    
                    flows.append({
                        'title': flow3_title,
                        'user_story': flow3_story,
                        'epic': epic_name,
                        'description': f'Real-time flow for {flow3_story}',
                        'mermaid': flow3_mermaid
                    })
            
            if not flows:
                # Create a generic flow if no stories available
                print("[WARNING] No user stories available for fallback E2E flow generation")
                flows.append({
                    'title': 'Generic Flow',
                    'user_story': 'N/A',
                    'epic': 'N/A',
                    'description': 'Generic system flow',
                    'mermaid': """graph TD
    U[User] -->|Request| API[API]
    API -->|Process| Service[Service]
    Service -->|Data| DB[(Database)]
    DB -->|Result| Service
    Service -->|Response| API
    API -->|Response| U"""
                })
            
            print(f"[OK] Generated {len(flows)} fallback E2E flow diagrams")
            return flows
            
        except Exception as e:
            print(f"[ERROR] Failed to generate fallback E2E flows: {str(e)}")
            # Return at least one flow even if there's an error
            return [{
                'title': 'Default Flow',
                'user_story': 'Default',
                'epic': 'Default',
                'description': 'Default system flow',
                'mermaid': 'graph TD\n    A[Start] --> B[Process]\n    B --> C[End]'
            }]
        
    async def process_query(self, query: str, phase_name: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        Process user query with AI assistance
        """
        # Mock response for now - integrate with actual LLM in production
        return {
            "response": f"AI response for '{query}' in phase '{phase_name}'. Context: {context}",
            "confidence_score": 85,
            "alternatives": [
                "Alternative approach 1",
                "Alternative approach 2"
            ],
            "explanation": "This is the recommended approach based on best practices."
        }
    
    async def generate_content(self, phase_name: str, content_type: str, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Generate phase-specific content
        """
        print(f"ðŸ” generate_content called with phase_name='{phase_name}', content_type='{content_type}'")
        
        # Log phase name analysis
        has_development = "Development" in phase_name
        has_phase5 = "Phase 5" in phase_name
        print(f"   DEBUG: 'Development' in phase_name = {has_development}")
        print(f"   DEBUG: 'Phase 5' in phase_name = {has_phase5}")
        print(f"   DEBUG: content_type == 'user_story_dev_delivery' = {content_type == 'user_story_dev_delivery'}")
        
        # Generate content based on phase and type
        # Check for Planning phase (Phase 2)
        if "Planning" in phase_name or "Backlog" in phase_name or phase_name == "Phase 2: Planning & Product Backlog":
            if content_type == "epics":
                content = await self._generate_epics(data)
            elif content_type == "user_stories":
                content = await self._generate_user_stories(data)
            elif content_type == "epics_and_stories":
                print(f"âœ… Calling _generate_epics_and_stories for content_type={content_type}")
                content = await self._generate_epics_and_stories(data)
            else:
                content = "Generated planning content"
        elif "Requirements" in phase_name:
            if content_type == "prd":
                content = await self._generate_prd(data)
            elif content_type == "brd":
                content = await self._generate_brd(data)
            elif content_type == "requirements":
                content = self._generate_requirements(data)
            else:
                content = "Generated content for " + content_type
        elif "Architecture" in phase_name:
            if content_type == "architecture":
                content = await self._generate_architecture(data)
            else:
                content = "Generated architecture content"
        elif "LLD" in phase_name or "Detailed Technical Design" in phase_name:
            if content_type == "component_wise_lld":
                # Component-Wise LLD returns its own structured format, pass it through directly
                return await self._generate_component_wise_lld(data)
            else:
                content = f"Generated LLD content for {content_type}"
        elif "Development" in phase_name or "Phase 5" in phase_name:
            # Phase 5: Development - generate code, tests, API docs, README
            print(f"   âœ… Matched Development/Phase5 condition")
            if content_type == "user_story_dev_delivery":
                print(f"âœ… Calling _generate_user_story_dev_delivery for Phase 5")
                try:
                    result = await self._generate_user_story_dev_delivery(data)
                    print(f"âœ… _generate_user_story_dev_delivery returned successfully")
                    print(f"   Result type: {type(result)}")
                    print(f"   Result keys: {list(result.keys()) if isinstance(result, dict) else 'N/A'}")
                    return result
                except Exception as e:
                    print(f"âŒ ERROR in _generate_user_story_dev_delivery: {str(e)}")
                    import traceback
                    traceback.print_exc()
                    raise
            else:
                content = f"Generated development content for {content_type}"
        else:
            print(f"âš ï¸ Phase name '{phase_name}' doesn't match any known patterns! content_type={content_type}")
            # Try to handle specific content types even if phase name is unexpected
            if content_type == "epics_and_stories":
                print(f"âš ï¸ Attempting fallback: calling _generate_epics_and_stories anyway")
                content = await self._generate_epics_and_stories(data)
            elif content_type == "user_story_dev_delivery":
                print(f"âš ï¸ Attempting fallback: calling _generate_user_story_dev_delivery for Phase 5 content")
                try:
                    result = await self._generate_user_story_dev_delivery(data)
                    print(f"âœ… Fallback _generate_user_story_dev_delivery returned successfully")
                    return result
                except Exception as e:
                    print(f"âŒ ERROR in fallback _generate_user_story_dev_delivery: {str(e)}")
                    import traceback
                    traceback.print_exc()
                    raise
            else:
                content = f"Generated {content_type} for {phase_name}"
        
        return {
            "content": content,
            "confidence_score": 85
        }
    
    async def _generate_prd(self, data: Dict[str, Any]) -> str:
        """
        Generate Product Requirements Document using the comprehensive PRD prompt.
        Input: All extracted requirements output + user input
        Output: Complete, professional PRD with 13 sections
        """
        # Extract all necessary data
        requirements = data.get('requirements', [])
        functional_reqs = data.get('functionalRequirements', [])
        non_functional_reqs = data.get('nonFunctionalRequirements', [])
        gherkin_reqs = data.get('gherkinRequirements', [])
        business_proposal = data.get('businessProposal', {})
        stakeholders = data.get('extractedStakeholders', [])
        extracted_risks = data.get('extractedRisks', {})
        technology_and_tools = data.get('technologyAndTools', {})
        tech_stack = data.get('extractedTechStack', {})
        scope = business_proposal.get('Scope', {})
        success_metrics = business_proposal.get('SuccessMetrics', [])
        user_input = data.get('userInput', '')  # Original user input
        project_info = data.get('project', {})
        
        print(f"[INFO] Generating PRD using comprehensive prompt for project: {project_info.get('name', 'Project')}")
        
        # Prepare comprehensive requirement context
        fr_context = ""
        if functional_reqs:
            fr_context += "\nFunctional Requirements:\n"
            for idx, fr in enumerate(functional_reqs, 1):
                service = fr.get('Service', 'General')
                req = fr.get('Requirement', fr.get('requirement', 'N/A'))
                priority = fr.get('Priority', 'Medium')
                category = fr.get('Category', 'Feature')
                fr_context += f"  {idx}. [{service}] {req} (Priority: {priority}, Category: {category})\n"
        
        nfr_context = ""
        if non_functional_reqs:
            nfr_context += "\nNon-Functional Requirements:\n"
            for idx, nfr in enumerate(non_functional_reqs, 1):
                category = nfr.get('Category', 'Performance')
                req = nfr.get('Requirement', nfr.get('requirement', 'N/A'))
                description = nfr.get('Description', '')
                nfr_context += f"  {idx}. [{category}] {req}"
                if description:
                    nfr_context += f" - {description}"
                nfr_context += "\n"
        
        scope_context = ""
        if scope:
            scope_context += "\nProject Scope:\n"
            in_scope = scope.get('InScope', [])
            out_scope = scope.get('OutOfScope', [])
            if in_scope:
                scope_context += "  In Scope:\n"
                for item in in_scope:
                    scope_context += f"    - {item}\n"
            if out_scope:
                scope_context += "  Out of Scope:\n"
                for item in out_scope:
                    scope_context += f"    - {item}\n"
        
        stakeholder_context = ""
        if stakeholders:
            stakeholder_context += "\nStakeholders:\n"
            for sh in stakeholders:
                if isinstance(sh, str):
                    stakeholder_context += f"  - {sh}\n"
                elif isinstance(sh, dict):
                    role = sh.get('Role', sh.get('role', 'N/A'))
                    stakeholder_context += f"  - {role}\n"
        
        tech_context = ""
        if tech_stack or technology_and_tools:
            tech_context += "\nTechnology Stack:\n"
            # Extracted tech
            extracted = tech_stack.get('Extracted', {}) or technology_and_tools.get('Extracted', {})
            if extracted:
                tech_context += "  Extracted (Mentioned by user):\n"
                for category, items in extracted.items():
                    if items:
                        tech_context += f"    {category}: {', '.join(items)}\n"
            # Suggested tech
            suggested = tech_stack.get('Suggested', {}) or technology_and_tools.get('Suggested', {})
            if suggested:
                tech_context += "  Suggested (Recommended):\n"
                for category, items in suggested.items():
                    if items:
                        tech_context += f"    {category}: {', '.join(items)}\n"
        
        metrics_context = ""
        if success_metrics:
            metrics_context += "\nSuccess Metrics:\n"
            for metric in success_metrics:
                metrics_context += f"  - {metric}\n"
        
        risks_context = ""
        if extracted_risks:
            risks_context += "\nRisks Identified:\n"
            for risk_type, risk_list in extracted_risks.items():
                risks_context += f"  {risk_type}:\n"
                if isinstance(risk_list, list):
                    for risk in risk_list:
                        risks_context += f"    - {risk}\n"
                else:
                    risks_context += f"    - {risk_list}\n"
        
        # Build the system prompt with PRD instructions
        prd_system_prompt = """You are a Product Manager AI assistant.
Your task is to generate a complete, professional, industry-standard Product Requirements Document (PRD)
using ONLY the extracted requirements provided by the user.

The input will be structured (Title, Problem to Solve, Vision, Scope, Requirements, Tech Stack, etc.)
Do NOT invent new data unless the input is vague.
If vague â†’ infer minimal, domain-aligned details (never create fictional features).
Suggestions must ONLY appear where allowed.

All PRD content must be:
- Precise
- Minimal
- Cleanly formatted
- Strictly aligned with extracted input content

The PRD must always contain the following sections in order:

=======================================================
1. Product Overview
=======================================================
- Summarize the product strictly from extracted Title + Vision.
- Keep it concise and product-focused (2â€“4 sentences maximum).

=======================================================
2. Problem Statement
=======================================================
- Use ONLY the extracted "Problem to Solve".
- No extra assumptions.

=======================================================
3. Goals & Objectives
=======================================================
- Derive goals ONLY from Vision + Scope.
- Convert into measurable objectives.
- No invented goals.

=======================================================
4. User Personas / Stakeholders
=======================================================
- Use extracted Stakeholders.
- If none â†’ infer minimal typical personas for the domain (e.g., "Fleet Manager").

=======================================================
5. Scope
=======================================================
In-Scope:
- Use extracted In-Scope items ONLY.

Out-of-Scope:
- Use extracted Out-of-Scope items ONLY.
- If empty â†’ mark "NA".

=======================================================
6. User Stories / Use Cases
=======================================================
- Convert Functional Requirements into user stories.
- Format:
  "As a <user>, I want to <action>, so that <outcome>."
- One story per functional module/requirement.

=======================================================
7. Feature Requirements (Functional)
=======================================================
- Transform functional requirements into clear feature specifications.
- If architecture mentions microservices/modules â†’ preserve structure.
- If no architecture mentioned â†’ list features flat without assumptions.

=======================================================
8. Non-Functional Requirements
=======================================================
- Use extracted NFRs ONLY.
- Include performance, reliability, security, scalability, usability â€” ONLY if present.

=======================================================
9. Technical Dependencies & Constraints
=======================================================
- Use extracted technology/tools as constraints.
- Do NOT invent additional tech.
- If a major technology (e.g., MySQL) is in input, mark it as REQUIRED.

=======================================================
10. Success Metrics (KPIs)
=======================================================
- Use extracted metrics ONLY.
- If none â†’ infer minimal measurable KPIs aligned to goals.

=======================================================
11. Assumptions
=======================================================
- Add minimal logical assumptions ONLY if needed for comprehension.
- No fictional features or systems.

=======================================================
12. Risks & Mitigation
=======================================================
- Use extracted Risk Analysis.
- For each extracted risk â†’ add a practical mitigation strategy.

=======================================================
13. Release Plan / Milestones
=======================================================
- Infer a simple rollout plan based ONLY on module decomposition.
- No artificial extra phases.

=======================================================
RULES (Strict)
=======================================================
1. Do NOT deviate from input requirements.
2. Do NOT add new features not provided or logically inferred.
3. Do NOT ask clarifying questions.
4. Do NOT generate long essays â€” keep all sections minimal and professional.
5. Suggestions must appear ONLY in allowed areas (e.g., Assumptions, Mitigations).
6. Technologies mentioned by user MUST be extracted and preserved.
7. The entire PRD must be readable, structured, and industry-standard.

Format the PRD with clear markdown headers and structure."""

        # Build user prompt with all extracted data
        user_prompt = f"""Generate a complete Product Requirements Document using the following extracted requirements and inputs:

PROJECT INFORMATION
===================
Project Name: {business_proposal.get('Title', project_info.get('name', 'Project'))}
Problem to Solve: {business_proposal.get('ProblemToSolve', 'Not specified')}
Vision: {business_proposal.get('Vision', 'Not specified')}

{scope_context}
{fr_context}
{nfr_context}
{stakeholder_context}
{metrics_context}
{tech_context}
{risks_context}

ORIGINAL USER INPUT
===================
{user_input[:3000] if user_input else 'Not provided'}

Generate the complete 13-section PRD now, adhering strictly to the instructions provided."""

        try:
            response = await self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": prd_system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.3,  # Low temperature for consistent, precise output
                max_tokens=6000
            )
            prd_content = response.choices[0].message.content.strip()
            print(f"[OK] PRD generated successfully using comprehensive prompt ({len(prd_content)} characters)")
            return prd_content
        except Exception as e:
            print(f"[ERROR] PRD generation failed: {str(e)}")
            return self._generate_fallback_prd(project_info, functional_reqs or requirements)

    async def _generate_brd(self, data: Dict[str, Any]) -> str:
        """
        Generate Business Requirements Document using the comprehensive BRD prompt.
        Input: All extracted requirements output + user input
        Output: Complete, professional BRD with 14 sections focused on business value
        """
        # Extract all necessary data
        requirements = data.get('requirements', [])
        functional_reqs = data.get('functionalRequirements', [])
        non_functional_reqs = data.get('nonFunctionalRequirements', [])
        gherkin_reqs = data.get('gherkinRequirements', [])
        business_proposal = data.get('businessProposal', {})
        stakeholders = data.get('extractedStakeholders', [])
        extracted_risks = data.get('extractedRisks', {})
        technology_and_tools = data.get('technologyAndTools', {})
        tech_stack = data.get('extractedTechStack', {})
        scope = business_proposal.get('Scope', {})
        success_metrics = business_proposal.get('SuccessMetrics', [])
        user_input = data.get('userInput', '')  # Original user input
        ai_notes = data.get('aiNotes', '')
        project_info = data.get('project', {})
        
        print(f"[INFO] Generating BRD using comprehensive prompt for project: {project_info.get('name', 'Project')}")
        
        # Prepare comprehensive requirement context for business focus
        fr_business_context = ""
        if functional_reqs:
            fr_business_context += "\nFunctional Requirements (Business Capabilities Needed):\n"
            for idx, fr in enumerate(functional_reqs, 1):
                service = fr.get('Service', 'General')
                req = fr.get('Requirement', fr.get('requirement', 'N/A'))
                priority = fr.get('Priority', 'Medium')
                fr_business_context += f"  {idx}. [{service}] {req} (Priority: {priority})\n"
        
        nfr_business_context = ""
        if non_functional_reqs:
            nfr_business_context += "\nNon-Functional Requirements (Quality Expectations):\n"
            for idx, nfr in enumerate(non_functional_reqs, 1):
                category = nfr.get('Category', 'Quality')
                req = nfr.get('Requirement', nfr.get('requirement', 'N/A'))
                nfr_business_context += f"  {idx}. [{category}] {req}\n"
        
        scope_context = ""
        if scope:
            scope_context += "\nProject Scope:\n"
            in_scope = scope.get('InScope', [])
            out_scope = scope.get('OutOfScope', [])
            if in_scope:
                scope_context += "  In Scope:\n"
                for item in in_scope:
                    scope_context += f"    - {item}\n"
            if out_scope:
                scope_context += "  Out of Scope:\n"
                for item in out_scope:
                    scope_context += f"    - {item}\n"
        
        stakeholder_context = ""
        if stakeholders:
            stakeholder_context += "\nStakeholders:\n"
            for sh in stakeholders:
                if isinstance(sh, str):
                    stakeholder_context += f"  - {sh}\n"
                elif isinstance(sh, dict):
                    role = sh.get('Role', sh.get('role', 'N/A'))
                    stakeholder_context += f"  - {role}\n"
        
        tech_constraints = ""
        if tech_stack or technology_and_tools:
            tech_constraints += "\nTechnology Constraints:\n"
            extracted = tech_stack.get('Extracted', {}) or technology_and_tools.get('Extracted', {})
            if extracted:
                tech_constraints += "  Required/Mentioned Technologies:\n"
                for category, items in extracted.items():
                    if items:
                        tech_constraints += f"    - {category}: {', '.join(items)}\n"
        
        metrics_context = ""
        if success_metrics:
            metrics_context += "\nBusiness Success Metrics:\n"
            for metric in success_metrics:
                metrics_context += f"  - {metric}\n"
        
        risks_context = ""
        if extracted_risks:
            risks_context += "\nBusiness Risks:\n"
            for risk_type, risk_list in extracted_risks.items():
                risks_context += f"  {risk_type}:\n"
                if isinstance(risk_list, list):
                    for risk in risk_list:
                        risks_context += f"    - {risk}\n"
                else:
                    risks_context += f"    - {risk_list}\n"
        
        # Build the system prompt with comprehensive BRD instructions
        brd_system_prompt = """You are a Business Analyst AI assistant.
Your task is to generate a complete, professional, industry-standard Business Requirements Document (BRD)
using ONLY the extracted requirements provided by the user.

The input will be structured (Title, Problem to Solve, Vision, Scope, Requirements, Tech Stack, etc.)
Do NOT invent new business requirements unless the input is vague.
If vague â†’ infer minimal, domain-aligned business details without creating fictional scenarios.

All BRD content must be:
- Precise
- Business-focused
- Cleanly formatted
- Strictly aligned with extracted input content

The BRD must always contain the following sections in order:

=======================================================
1. Document Overview
=======================================================
- Document Title (from extracted input)
- Version (default: v1.0)
- Prepared By: AI System
- Created Date: Today's Date
- Brief Description: 1â€“2 line summary using extracted Title & Vision.

=======================================================
2. Executive Summary
=======================================================
- High-level business explanation of the product.
- Derived strictly from extracted Title, Vision, and Problem to Solve.
- No technical detail here.

=======================================================
3. Business Problem Statement
=======================================================
- Use ONLY the extracted "Problem to Solve".
- No assumptions or extra interpretation.

=======================================================
4. Business Objectives
=======================================================
- Convert Vision + key business needs into measurable business outcomes.
- Keep minimal and business-focused.

=======================================================
5. Key Stakeholders
=======================================================
- Use extracted Stakeholders.
- If NA â†’ infer typical business-side stakeholders for the domain (e.g., "Operations Manager", "Finance Team").

=======================================================
6. Scope Definition
=======================================================
In-Scope:
- Use extracted In-Scope items ONLY.

Out-of-Scope:
- Use extracted Out-of-Scope items ONLY.
- If none â†’ mark "NA".

=======================================================
7. Business Requirements (Functional)
=======================================================
- Rewrite functional requirements as BUSINESS NEEDS.
- No technical terminology.
- Describe WHAT the business needs, not HOW it will be built.
- If architecture mentions microservices â†’ convert them into business capability streams.

=======================================================
8. Non-Functional / Business Quality Requirements
=======================================================
- Use extracted NFRs.
- Translate into business-quality expectations (e.g., availability â†’ business continuity).
- No technical implementation details.

=======================================================
9. Process Flow / High-Level Workflow
=======================================================
- Create a simple business process flow using extracted requirements.
- Use bullet points or short numbered sequence.
- No diagrams.

=======================================================
10. Assumptions
=======================================================
- Add minimal domain-aligned assumptions only if required for comprehension.
- No fictional business cases.

=======================================================
11. Constraints & Dependencies
=======================================================
- Use extracted Tech/Tools ONLY as business constraints if relevant.
- Example: "System must use MySQL due to organizational preference."

=======================================================
12. Business Risks & Mitigation
=======================================================
- Use extracted Risk Analysis.
- Add real-world business-focused mitigations for each risk.

=======================================================
13. Success Metrics (Business KPIs)
=======================================================
- Use extracted Success Metrics only.
- Convert into business-aligned KPIs (e.g., cost savings, reduced downtime, increased visibility).

=======================================================
14. Recommendations (Optional)
=======================================================
- Provide suggestions ONLY if input is vague.
- Must NOT override extracted requirements.

=======================================================
RULES (Strict)
=======================================================
1. Do NOT deviate from user-extracted requirements.
2. Do NOT add fictional features or business processes.
3. Do NOT include technical implementation details.
4. KEEP ALL content minimal, professional, and structured.
5. Suggestions are allowed ONLY in the Recommendations section.
6. If user input mentions specific tools/tech â†’ treat as business constraints.
7. No clarifying questions.

Format the BRD with clear markdown headers and structure."""

        # Build user prompt with all extracted data
        user_prompt = f"""Generate a complete Business Requirements Document using the following extracted requirements and inputs:

PROJECT INFORMATION
===================
Project Name: {business_proposal.get('Title', project_info.get('name', 'Project'))}
Problem to Solve: {business_proposal.get('ProblemToSolve', 'Not specified')}
Vision: {business_proposal.get('Vision', 'Not specified')}

{scope_context}
{fr_business_context}
{nfr_business_context}
{stakeholder_context}
{metrics_context}
{tech_constraints}
{risks_context}

ORIGINAL USER INPUT
===================
{user_input[:3000] if user_input else 'Not provided'}

Generate the complete 14-section BRD now, adhering strictly to the instructions provided. Focus on BUSINESS VALUE and BUSINESS NEEDS, not technical implementation."""

        try:
            response = await self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": brd_system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.3,  # Low temperature for consistent, precise output
                max_tokens=6000
            )
            brd_content = response.choices[0].message.content.strip()
            print(f"[OK] BRD generated successfully using comprehensive prompt ({len(brd_content)} characters)")
            return brd_content
        except Exception as e:
            print(f"[ERROR] BRD generation failed: {str(e)}")
            return self._generate_fallback_brd(project_info, functional_reqs or requirements)

    def _generate_requirements(self, data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Generate extracted requirements"""
        return [
            {
                "title": "User Authentication & Authorization",
                "priority": "High",
                "status": "documented",
                "description": "Implement secure login system with role-based access control"
            },
            {
                "title": "AI-Powered Document Generation",
                "priority": "High",
                "status": "documented",
                "description": "Generate PRD, BRD, and other documents using AI"
            },
            {
                "title": "Multi-Level Approval Workflow",
                "priority": "High",
                "status": "in_review",
                "description": "Configurable approval chains for each phase"
            },
            {
                "title": "Real-Time Collaboration",
                "priority": "Medium",
                "status": "draft",
                "description": "Enable team members to collaborate in real-time"
            },
            {
                "title": "Integration Hub",
                "priority": "Medium",
                "status": "documented",
                "description": "Connect with Jira, GitHub, Confluence, and CI/CD tools"
            }
        ]
    
    async def _generate_epics(self, data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Generate epics based on Phase 1 requirements, PRD, BRD, and API specifications using OpenAI
        
        Intelligently analyzes requirements and groups them into high-level epics.
        For API-based projects, creates epics based on API endpoint groups.
        Uses ALL extracted data from Phase 1 for comprehensive epic generation.
        """
        # Extract ALL Phase 1 data
        requirements = data.get('requirements', [])
        gherkin_reqs = data.get('gherkinRequirements', [])
        functional_reqs = data.get('functionalRequirements', [])
        non_functional_reqs = data.get('nonFunctionalRequirements', [])
        business_proposal = data.get('businessProposal', {})
        stakeholders = data.get('extractedStakeholders', [])
        risks_data = data.get('extractedRisks', {})
        ai_notes = data.get('aiNotes', '')
        prd = data.get('prd', '')
        brd = data.get('brd', '')
        risks = data.get('risks', [])
        project_info = data.get('project', {})
        
        # Check for API specifications
        api_spec = data.get('apiSpec')
        api_summary = data.get('apiSummary', '')
        
        print(f"[INFO] Generating epics for project: {project_info.get('name', 'Project')}")
        print(f"[DEBUG] Functional requirements: {len(functional_reqs)}")
        print(f"[DEBUG] Non-Functional requirements: {len(non_functional_reqs)}")
        print(f"[DEBUG] Gherkin requirements: {len(gherkin_reqs)}")
        print(f"[DEBUG] Has Business Proposal: {bool(business_proposal)}")
        print(f"[DEBUG] Has API Spec: {bool(api_spec)}")
        print(f"[DEBUG] API Endpoints: {len(api_spec.get('paths', {})) if api_spec else 0}")
        
        # Combine all requirements
        all_reqs = []
        if functional_reqs:
            all_reqs.extend(functional_reqs)
        if non_functional_reqs:
            all_reqs.extend(non_functional_reqs)
        if gherkin_reqs:
            all_reqs.extend(gherkin_reqs)
        if requirements:
            all_reqs.extend(requirements)
        
        # If no requirements and no API specs, don't generate dummy epics
        if not all_reqs and not api_spec and not business_proposal:
            print("[WARNING] No requirements or API specs found - cannot generate meaningful epics")
            return []
        
        # Prepare requirements context for OpenAI
        requirements_context = ""
        
        # Add Functional Requirements
        if functional_reqs:
            requirements_context += "\n### Functional Requirements:\n"
            for idx, req in enumerate(functional_reqs, 1):
                requirements_context += f"\n{idx}. **{req.get('requirement', 'N/A')}**\n"
                requirements_context += f"   - Priority: {req.get('priority', 'Medium')}\n"
                requirements_context += f"   - Stakeholder/Actor: {req.get('stakeholder_actor', 'N/A')}\n"
                requirements_context += f"   - Category: {req.get('category', 'N/A')}\n"
                if req.get('derived_from'):
                    requirements_context += f"   - Derived From: {req.get('derived_from')}\n"
        
        # Add Non-Functional Requirements
        if non_functional_reqs:
            requirements_context += "\n### Non-Functional Requirements:\n"
            for idx, req in enumerate(non_functional_reqs, 1):
                requirements_context += f"\n{idx}. **{req.get('requirement', 'N/A')}**\n"
                requirements_context += f"   - Category: {req.get('category', 'N/A')}\n"
                requirements_context += f"   - Priority: {req.get('priority', 'Medium')}\n"
                requirements_context += f"   - Description: {req.get('description', 'N/A')}\n"
        
        # Add Gherkin Requirements
        if gherkin_reqs:
            requirements_context += "\n### Gherkin Requirements:\n"
            for idx, req in enumerate(gherkin_reqs, 1):
                requirements_context += f"\n{idx}. **{req.get('feature', 'Feature')}** (ID: {req.get('id', '')})\n"
                requirements_context += f"   - As a {req.get('as_a', 'user')}, I want {req.get('i_want', '')}\n"
                requirements_context += f"   - So that {req.get('so_that', '')}\n"
                requirements_context += f"   - Priority: {req.get('priority', 'Medium')}\n"
                
                scenarios = req.get('scenarios', [])
                if scenarios:
                    requirements_context += f"   - Scenarios: {len(scenarios)}\n"
                    for scenario in scenarios[:2]:  # Include first 2 scenarios as examples
                        requirements_context += f"     * {scenario.get('title', '')}\n"
        
        # Add Business Proposal
        business_context = ""
        if business_proposal and business_proposal.get('Title'):
            business_context = f"""
### Business Proposal:
- **Title**: {business_proposal.get('Title', 'N/A')}
- **Problem to Solve**: {business_proposal.get('ProblemToSolve', 'N/A')}
- **Vision**: {business_proposal.get('Vision', 'N/A')}
- **Goals**: {', '.join(business_proposal.get('Goals', []))}
- **Success Metrics**: {', '.join(business_proposal.get('SuccessMetrics', []))}
- **Scope**: {', '.join(business_proposal.get('Scope', []))}
"""
        
        # Add Stakeholders
        stakeholders_context = ""
        if stakeholders:
            stakeholders_context = "\n### Stakeholders:\n"
            for sh in stakeholders:
                role = sh.get('Role') or sh.get('role', 'N/A')
                resp = sh.get('Responsibility') or sh.get('responsibility', 'N/A')
                stakeholders_context += f"- {role}: {resp}\n"
        
        # Extract key sections from PRD and BRD for context
        prd_summary = ""
        if prd and len(prd) > 100:
            # Extract first 2000 characters of PRD for context
            prd_summary = prd[:2000] + "..."
        
        brd_summary = ""
        if brd and len(brd) > 100:
            # Extract first 2000 characters of BRD for context
            brd_summary = brd[:2000] + "..."
        
        # Prepare risk context from extracted risks
        risks_context = ""
        if risks_data:
            risks_context = "\n### Identified Risks:\n"
            for category, description in risks_data.items():
                risks_context += f"- **{category}**: {description}\n"
        elif risks:
            risks_context = "\n### Identified Risks:\n"
            for idx, risk in enumerate(risks[:5], 1):  # Top 5 risks
                risks_context += f"{idx}. {risk.get('description', 'Risk')} (Severity: {risk.get('severity', 'Medium')})\n"
        
        # Add Constraints/Assumptions
        constraints_context = ""
        if ai_notes:
            constraints_context = f"\n### Constraints & Assumptions:\n{ai_notes}\n"
            for idx, risk in enumerate(risks[:5], 1):  # Top 5 risks
                risks_context += f"{idx}. {risk.get('description', 'Risk')} (Severity: {risk.get('severity', 'Medium')})\n"
        
        # Prepare API context if available
        api_context = ""
        if api_spec:
            api_endpoints = api_spec.get('paths', {})
            endpoint_count = len(api_endpoints)
            api_context = f"\n### API Specifications:\n"
            api_context += f"Total Endpoints: {endpoint_count}\n"
            if api_summary:
                api_context += f"Summary: {api_summary[:500]}\n"
            api_context += "\nAPI Endpoint Groups:\n"
            
            # Group endpoints by resource (first path segment)
            endpoint_groups = {}
            for path in api_endpoints.keys():
                # Extract resource from path (e.g., /users, /orders, etc.)
                parts = path.strip('/').split('/')
                resource = parts[0] if parts else 'general'
                if resource not in endpoint_groups:
                    endpoint_groups[resource] = []
                endpoint_groups[resource].append(path)
            
            for resource, paths in endpoint_groups.items():
                api_context += f"- {resource.upper()}: {len(paths)} endpoints\n"
                for path in paths[:3]:  # Show first 3 endpoints
                    methods = list(api_endpoints[path].keys())
                    api_context += f"  * {', '.join([m.upper() for m in methods])} {path}\n"
        
        # Create prompt for OpenAI to generate epics
        is_api_project = bool(api_spec)
        
        if is_api_project:
            # API-focused prompt
            prompt = f"""You are an expert Product Manager and API Architect. Analyze the following API specifications and requirements to generate a comprehensive set of Epics for Phase 2 (Planning & Backlog).

**Project**: {project_info.get('name', 'API Project')}

**Business Requirements Document (BRD) Summary**:
{brd_summary if brd_summary else "Not provided"}

**Product Requirements Document (PRD) Summary**:
{prd_summary if prd_summary else "Not provided"}

{risks_context}

{api_context}

{requirements_context if requirements_context else ""}

**Instructions for API-Based Epics**:
1. Create epics based on API endpoint groups (e.g., "User Management API", "Order Processing API")
2. Each epic should cover related API endpoints (typically 3-8 endpoints per epic)
3. Number of user stories should match or slightly exceed the number of endpoints (each endpoint = at least 1 story)
4. Estimate story points based on endpoint complexity (simple CRUD: 3-5, complex logic: 8-13 points per endpoint)
5. Consider authentication, error handling, and data validation in story counts
6. Assign priority based on business value and dependencies
7. Reference the actual endpoints in the epic description
8. Map to requirements if provided

**Output Format** (JSON array):
[
  {{
    "id": 1,
    "title": "API Resource Group Name (e.g., User Management API)",
    "description": "Implementation of endpoints: GET /users, POST /users, GET /users/{{id}}, etc.",
    "stories": 5,
    "points": 25,
    "priority": "High",
    "requirements_mapped": ["req-id-1"]
  }}
]

Return ONLY the JSON array, no additional text."""
        else:
            # Regular requirements-based prompt with ALL extracted Phase 1 data
            prompt = f"""You are an expert Product Manager and Agile Coach. Analyze the following requirements from Phase 1 (Requirements Gathering) and generate a comprehensive set of Epics for Phase 2 (Planning & Backlog).

**Project**: {project_info.get('name', 'Software Project')}

{business_context}

{stakeholders_context}

{risks_context}

{constraints_context}

**Business Requirements Document (BRD) Summary**:
{brd_summary if brd_summary else "Not provided"}

**Product Requirements Document (PRD) Summary**:
{prd_summary if prd_summary else "Not provided"}

{requirements_context}

**JIRA Compatibility Requirements**:
- Epic titles must be clear, concise (50-100 chars), and describe the feature/capability
- Epic descriptions should explain the business value and scope
- Use standard Agile terminology (Epic, Story Points, Priority)
- Story point estimates should be realistic (use Fibonacci: 3, 5, 8, 13, 21)
- Number of user stories should reflect actual implementation complexity

**Instructions**:
1. Analyze ALL requirements (functional, non-functional, and gherkin) provided above
2. Use business proposal goals and success metrics to prioritize epics
3. Consider stakeholder needs when grouping requirements into epics
4. Group related requirements into logical, high-level Epics (typically 3-7 epics)
5. Each epic should represent a major feature area or business capability
6. Ensure EVERY requirement is covered by at least one epic
7. Estimate the number of user stories (3-12) and story points (13-55) for each epic
8. Assign priority: High (critical/MVP), Medium (important), Low (nice-to-have)
9. Create meaningful titles and descriptions using ACTUAL requirement data
10. Consider identified risks and constraints when prioritizing
11. For non-functional requirements, create dedicated epics (Performance, Security, etc.)

**Output Format** (JIRA-compatible JSON array):
[
  {{
    "id": 1,
    "title": "Epic Name (max 100 chars)",
    "description": "Business value and scope description with specific requirement details",
    "stories": 5,
    "points": 25,
    "priority": "High",
    "requirements_mapped": ["req-id-1", "req-id-2"]
  }}
]

Return ONLY the JSON array, no additional text."""

        try:
            # Call OpenAI API
            response = await self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You are an expert Product Manager who creates well-structured Epics from requirements. Always respond with valid JSON."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=2000
            )
            
            # Parse the response
            content = response.choices[0].message.content.strip()
            
            # Remove markdown code blocks if present
            if content.startswith("```"):
                content = content.split("```")[1]
                if content.startswith("json"):
                    content = content[4:]
                content = content.strip()
            
            epics = json.loads(content)
            
            # Validate and ensure proper structure
            if isinstance(epics, list) and len(epics) > 0:
                # Ensure all epics have required fields
                for epic in epics:
                    if 'id' not in epic:
                        epic['id'] = epics.index(epic) + 1
                    if 'title' not in epic:
                        epic['title'] = f"Epic {epic['id']}"
                    if 'description' not in epic:
                        epic['description'] = "Epic description"
                    if 'stories' not in epic:
                        epic['stories'] = 5
                    if 'points' not in epic:
                        epic['points'] = epic['stories'] * 5
                    if 'priority' not in epic:
                        epic['priority'] = "Medium"
                    if 'requirements_mapped' not in epic:
                        epic['requirements_mapped'] = []
                
                print(f"[OK] Generated {len(epics)} epics using OpenAI")
                return epics
            else:
                raise ValueError("Invalid epic structure from OpenAI")
                
        except Exception as e:
            print(f"[WARNING] Error generating epics with OpenAI: {str(e)}")
            print(f"Falling back to template-based generation")
            
            # Fallback: Create simplified epics from requirements or API specs
            epics = []
            epic_id = 1
            
            if api_spec:
                # Create epics from API endpoint groups
                api_endpoints = api_spec.get('paths', {})
                endpoint_groups = {}
                
                # Group endpoints by resource
                for path in api_endpoints.keys():
                    parts = path.strip('/').split('/')
                    resource = parts[0] if parts else 'general'
                    if resource not in endpoint_groups:
                        endpoint_groups[resource] = []
                    endpoint_groups[resource].append(path)
                
                # Create epic for each resource group
                for resource, paths in endpoint_groups.items():
                    num_endpoints = len(paths)
                    num_stories = max(num_endpoints, num_endpoints + 2)  # At least 1 story per endpoint + extras
                    estimated_points = num_endpoints * 5  # 5 points per endpoint average
                    
                    epic = {
                        "id": epic_id,
                        "title": f"{resource.title()} API",
                        "description": f"Implementation of {num_endpoints} API endpoints for {resource} resource",
                        "stories": num_stories,
                        "points": estimated_points,
                        "priority": "High" if epic_id == 1 else "Medium",
                        "requirements_mapped": []
                    }
                    epics.append(epic)
                    epic_id += 1
            
            elif gherkin_reqs:
                # Group requirements into 3-4 epics
                reqs_per_epic = max(2, len(gherkin_reqs) // 3)
                
                for i in range(0, len(gherkin_reqs), reqs_per_epic):
                    batch = gherkin_reqs[i:i+reqs_per_epic]
                    if not batch:
                        continue
                    
                    title = batch[0].get('feature', f'Epic {epic_id}')
                    num_stories = min(10, len(batch) * 2)
                    estimated_points = num_stories * 5
                    
                    epic = {
                        "id": epic_id,
                        "title": title,
                        "description": f"Implementation of {len(batch)} related requirements",
                        "stories": num_stories,
                        "points": estimated_points,
                        "priority": "High" if epic_id == 1 else "Medium",
                        "requirements_mapped": [req.get('id', f'req-{i}') for req in batch]
                    }
                    epics.append(epic)
                    epic_id += 1
                    
                    if epic_id > 4:
                        break
        
            return epics
    
    async def _generate_user_stories(self, data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Generate user stories based on epics, requirements, and API specifications using OpenAI
        
        Creates detailed user stories with acceptance criteria and optional subtasks from actual requirements.
        For API projects, creates at least one story per endpoint.
        JIRA-compatible format with subtasks support.
        """
        epics = data.get('epics', [])
        
        # Extract ALL Phase 1 data (same as epics generation)
        gherkin_reqs = data.get('gherkinRequirements', [])
        requirements = data.get('requirements', [])
        functional_reqs = data.get('functionalRequirements', [])
        non_functional_reqs = data.get('nonFunctionalRequirements', [])
        business_proposal = data.get('businessProposal', {})
        stakeholders = data.get('extractedStakeholders', [])
        risks_data = data.get('extractedRisks', {})
        ai_notes = data.get('aiNotes', '')
        prd = data.get('prd', '')
        brd = data.get('brd', '')
        risks = data.get('risks', [])
        project_info = data.get('project', {})
        
        # Check for API specifications
        api_spec = data.get('apiSpec')
        api_summary = data.get('apiSummary', '')
        
        print(f"[INFO] Generating user stories for project: {project_info.get('name', 'Project')}")
        print(f"[DEBUG] Epics count: {len(epics)}")
        print(f"[DEBUG] Functional requirements: {len(functional_reqs)}")
        print(f"[DEBUG] Non-Functional requirements: {len(non_functional_reqs)}")
        print(f"[DEBUG] Gherkin requirements: {len(gherkin_reqs)}")
        print(f"[DEBUG] Has API Spec: {bool(api_spec)}")
        print(f"[DEBUG] API Endpoints: {len(api_spec.get('paths', {})) if api_spec else 0}")
        
        if not epics:
            # Need epics first to generate stories
            print("[WARNING] No epics found - cannot generate user stories")
            return []
        
        # Prepare context for OpenAI
        epics_context = ""
        for epic in epics:
            epics_context += f"\n**Epic {epic.get('id')}**: {epic.get('title')}\n"
            epics_context += f"  - Description: {epic.get('description')}\n"
            epics_context += f"  - Priority: {epic.get('priority')}\n"
            epics_context += f"  - Expected Stories: {epic.get('stories')}\n"
            epics_context += f"  - Story Points: {epic.get('points')}\n"
            epics_context += f"  - Requirements Mapped: {', '.join(epic.get('requirements_mapped', []))}\n"
        
        # Prepare comprehensive requirements context
        requirements_context = ""
        
        # Add Functional Requirements
        if functional_reqs:
            requirements_context += "\n### Functional Requirements:\n"
            for idx, req in enumerate(functional_reqs, 1):
                requirements_context += f"\n{idx}. **{req.get('requirement', 'N/A')}**\n"
                requirements_context += f"   - Priority: {req.get('priority', 'Medium')}\n"
                requirements_context += f"   - Stakeholder/Actor: {req.get('stakeholder_actor', 'N/A')}\n"
                requirements_context += f"   - Category: {req.get('category', 'N/A')}\n"
        
        # Add Non-Functional Requirements
        if non_functional_reqs:
            requirements_context += "\n### Non-Functional Requirements:\n"
            for idx, req in enumerate(non_functional_reqs, 1):
                requirements_context += f"\n{idx}. **{req.get('requirement', 'N/A')}**\n"
                requirements_context += f"   - Category: {req.get('category', 'N/A')}\n"
                requirements_context += f"   - Priority: {req.get('priority', 'Medium')}\n"
                requirements_context += f"   - Description: {req.get('description', 'N/A')}\n"
        
        # Add Gherkin Requirements
        if gherkin_reqs:
            requirements_context += "\n### Gherkin Requirements:\n"
            for req in gherkin_reqs:
                requirements_context += f"\n**{req.get('feature')}** (ID: {req.get('id')})\n"
                requirements_context += f"  - As a {req.get('as_a')}, I want {req.get('i_want')}\n"
                requirements_context += f"  - So that {req.get('so_that')}\n"
                
                scenarios = req.get('scenarios', [])
                if scenarios:
                    requirements_context += f"  - Scenarios:\n"
                    for scenario in scenarios:
                        requirements_context += f"    * {scenario.get('title')}\n"
                        if scenario.get('given'):
                            requirements_context += f"      - Given: {', '.join(scenario.get('given'))}\n"
                        if scenario.get('when'):
                            requirements_context += f"      - When: {', '.join(scenario.get('when'))}\n"
                        if scenario.get('then'):
                            requirements_context += f"      - Then: {', '.join(scenario.get('then'))}\n"
        
        # Add Business Proposal
        business_context = ""
        if business_proposal and business_proposal.get('Title'):
            business_context = f"""
### Business Context:
- **Problem**: {business_proposal.get('ProblemToSolve', 'N/A')}
- **Vision**: {business_proposal.get('Vision', 'N/A')}
- **Goals**: {', '.join(business_proposal.get('Goals', []))}
"""
        
        # Add Stakeholders
        stakeholders_context = ""
        if stakeholders:
            stakeholders_context = "\n### Stakeholders:\n"
            for sh in stakeholders:
                role = sh.get('Role') or sh.get('role', 'N/A')
                stakeholders_context += f"- {role}\n"
        
        # Prepare risk context
        risks_context = ""
        if risks_data:
            risks_context = "\n### Identified Risks:\n"
            for category, description in risks_data.items():
                risks_context += f"- **{category}**: {description}\n"
        elif risks:
            risks_context = "\n### Identified Risks:\n"
            for idx, risk in enumerate(risks[:5], 1):
                risks_context += f"{idx}. {risk.get('description', 'Risk')} (Severity: {risk.get('severity', 'Medium')})\n"
        
        # Prepare API context if available
        api_context = ""
        if api_spec:
            api_endpoints = api_spec.get('paths', {})
            api_context = f"\n### API Endpoints ({len(api_endpoints)} total):\n"
            
            # List all endpoints with methods
            for path, methods in api_endpoints.items():
                for method, spec in methods.items():
                    summary = spec.get('summary', 'No description')
                    api_context += f"- {method.upper()} {path}: {summary}\n"
                    
                    # Include parameters if any
                    params = spec.get('parameters', [])
                    if params:
                        api_context += f"  Parameters: {', '.join([p.get('name', '') for p in params])}\n"
        
        # Create prompt for OpenAI based on project type
        is_api_project = bool(api_spec)
        if is_api_project:
            prompt = f"""You are an expert Agile Scrum Master and API Developer. Based on the Epics and API specifications, generate detailed User Stories for API development.

**Project**: {project_info.get('name', 'API Project')}

## Epics Generated:
{epics_context}

{api_context}

{risks_context}

{requirements_context if requirements_context else ""}

**JIRA Compatibility Requirements**:
- User story titles must follow format: "As a [role], I want [goal], so that [benefit]"
- Include detailed acceptance criteria as array of strings
- Support optional subtasks for complex stories (implementation steps)
- Use Fibonacci story points: 1, 2, 3, 5, 8, 13, 21
- All stories start in "backlog" status, null sprint

**Instructions for API User Stories**:
1. For EACH API endpoint, create AT LEAST ONE user story
2. Each story should follow the format: "As a [API consumer/developer], I want [endpoint functionality], so that [business value]"
3. Include detailed acceptance criteria covering:
   - Request/response format
   - Authentication/authorization
   - Error handling (400, 401, 404, 500 responses)
   - Data validation
   - Performance requirements
4. For complex stories (8+ points), add subtasks array with implementation steps
5. Estimate story points: Simple CRUD: 3-5, Complex logic: 8-13
6. Additional stories for: authentication, error handling, documentation, testing
7. Assign priority based on epic priority and dependencies

**Output Format** (JIRA-compatible JSON array):
[
  {{
    "id": 1,
    "epic": "Epic Title",
    "epic_id": 1,
    "title": "As an API consumer, I want to call GET /users endpoint, so that I can retrieve user list",
    "description": "Implement GET /users endpoint with pagination and filtering",
    "acceptance_criteria": [
      "Returns 200 with user array on success",
      "Supports page and limit query parameters",
      "Returns 401 if not authenticated",
      "Returns proper error messages"
    ],
    "subtasks": [
      "Create API route handler",
      "Implement pagination logic",
      "Add authentication middleware",
      "Write unit tests"
    ],
    "points": 5,
    "priority": "High",
    "sprint": null,
    "status": "backlog"
  }}
]

Return ONLY the JSON array with all user stories, no additional text."""
        else:
            prompt = f"""You are an expert Agile Scrum Master and Product Owner. Based on the Epics and ALL extracted requirements from Phase 1, generate detailed User Stories with acceptance criteria.

**Project**: {project_info.get('name', 'Software Project')}

{business_context}

{stakeholders_context}

## Epics Generated:
{epics_context}

{risks_context}

## Requirements from Phase 1:
{requirements_context}

**JIRA Compatibility Requirements**:
- User story titles must follow format: "As a [role], I want [goal], so that [benefit]"
- Use roles from stakeholders when available
- Include detailed acceptance criteria as array of strings
- Support optional subtasks for complex stories (implementation steps)
- Use Fibonacci story points: 1, 2, 3, 5, 8, 13, 21
- All stories start in "backlog" status, null sprint
- Subtasks should be specific, actionable tasks (development, testing, documentation)

**Instructions**:
1. For EACH Epic, generate user stories that match the "Expected Stories" count
2. Base stories on ACTUAL requirements (functional, non-functional, gherkin)
3. Use stakeholder roles when defining "As a [role]" in user stories
4. Each story should follow: "As a [stakeholder role], I want [capability], so that [business value from proposal]"
5. Derive acceptance criteria from:
   - Functional requirement details
   - Non-functional requirement descriptions
   - Gherkin scenarios (Given-When-Then)
   - Success metrics from business proposal
6. For complex stories (8+ points), add subtasks array with specific implementation steps
7. Estimate story points using Fibonacci: 1,2,3,5,8,13,21
8. Assign priority: High (MVP/critical), Medium (important), Low (nice-to-have)
9. Consider identified risks when defining acceptance criteria
10. All stories in "backlog" status, no sprint assigned

**Output Format** (JIRA-compatible JSON array):
[
  {{
    "id": 1,
    "epic": "Epic Title",
    "epic_id": 1,
    "title": "As a [stakeholder role], I want [capability], so that [business value]",
    "description": "Detailed description from requirement",
    "acceptance_criteria": [
      "Specific, testable criterion 1",
      "Specific, testable criterion 2",
      "Performance/security criterion from NFR"
    ],
    "subtasks": [
      "Design database schema",
      "Implement backend API",
      "Create frontend components",
      "Write unit and integration tests",
      "Update documentation"
    ],
    "points": 8,
    "priority": "High",
    "sprint": null,
    "status": "backlog"
  }}
]

**IMPORTANT**: 
- Use ACTUAL data from requirements, NOT generic placeholders
- Match story count to epic expectations
- Cover ALL requirements across ALL epics
- Include subtasks ONLY for stories with 8+ points

Return ONLY the JSON array with all user stories, no additional text."""


        try:
            # Call OpenAI API
            response = await self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You are an expert Scrum Master who creates detailed user stories from epics and requirements. Always respond with valid JSON."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=4000
            )
            
            # Parse the response
            content = response.choices[0].message.content.strip()
            
            # Remove markdown code blocks if present
            if content.startswith("```"):
                content = content.split("```")[1]
                if content.startswith("json"):
                    content = content[4:]
                content = content.strip()
            
            user_stories = json.loads(content)
            
            # Validate and ensure proper structure
            if isinstance(user_stories, list) and len(user_stories) > 0:
                story_id = 1
                for story in user_stories:
                    # Ensure required fields
                    story['id'] = story_id
                    story_id += 1
                    
                    if 'epic' not in story:
                        story['epic'] = "Unknown Epic"
                    if 'epic_id' not in story:
                        story['epic_id'] = 1
                    if 'title' not in story:
                        story['title'] = "User Story"
                    if 'description' not in story:
                        story['description'] = "Story description"
                    if 'acceptance_criteria' not in story:
                        story['acceptance_criteria'] = []
                    if 'points' not in story:
                        story['points'] = 5
                    if 'priority' not in story:
                        story['priority'] = "Medium"
                    if 'sprint' not in story:
                        story['sprint'] = None
                    if 'status' not in story:
                        story['status'] = "backlog"
                
                print(f"[OK] Generated {len(user_stories)} user stories using OpenAI")
                return user_stories
            else:
                raise ValueError("Invalid user story structure from OpenAI")
                
        except Exception as e:
            print(f"[WARNING] Error generating user stories with OpenAI: {str(e)}")
            print(f"Falling back to template-based generation")
            
            # Fallback: Generate basic stories from epics or API endpoints
            user_stories = []
            story_id = 1
            
            if api_spec:
                # Generate stories from API endpoints
                api_endpoints = api_spec.get('paths', {})
                
                for epic in epics:
                    epic_id = epic.get('id', 0)
                    epic_title = epic.get('title', 'Epic')
                    epic_priority = epic.get('priority', 'Medium')
                    
                    # Get endpoints for this epic (by matching resource in title)
                    resource = epic_title.lower().replace(' api', '').replace('api', '').strip()
                    
                    stories_for_epic = 0
                    for path, methods in api_endpoints.items():
                        if resource in path.lower():
                            for method, spec in methods.items():
                                summary = spec.get('summary', f'{method.upper()} {path}')
                                
                                story = {
                                    "id": story_id,
                                    "epic": epic_title,
                                    "epic_id": epic_id,
                                    "title": f"As an API consumer, I want to call {method.upper()} {path}, so that {summary}",
                                    "description": f"Implement {method.upper()} {path} endpoint",
                                    "acceptance_criteria": [
                                        f"Endpoint responds to {method.upper()} {path}",
                                        "Returns proper status codes (200, 400, 401, 500)",
                                        "Request/response follows API specification",
                                        "Error handling is robust"
                                    ],
                                    "points": 5,
                                    "priority": epic_priority,
                                    "sprint": None,
                                    "status": "backlog"
                                }
                                user_stories.append(story)
                                story_id += 1
                                stories_for_epic += 1
                    
                    # Add authentication story if no stories yet
                    if stories_for_epic == 0:
                        story = {
                            "id": story_id,
                            "epic": epic_title,
                            "epic_id": epic_id,
                            "title": f"As a developer, I want to implement {epic_title}",
                            "description": f"Implement {epic_title} functionality",
                            "acceptance_criteria": [
                                "API endpoints are implemented",
                                "Authentication is handled",
                                "Error responses are proper"
                            ],
                            "points": 8,
                            "priority": epic_priority,
                            "sprint": None,
                            "status": "backlog"
                        }
                        user_stories.append(story)
                        story_id += 1
            else:
                # Generate generic stories from epics
                for epic in epics:
                    epic_id = epic.get('id', 0)
                    epic_title = epic.get('title', 'Epic')
                    num_stories = epic.get('stories', 5)
                    points_per_story = max(3, epic.get('points', 25) // num_stories)
                    
                    # Map to gherkin requirements if available
                    for i, req in enumerate(gherkin_reqs[:num_stories] if gherkin_reqs else range(min(num_stories, 5))):
                        if isinstance(req, dict):
                            title = f"As a {req.get('as_a', 'user')}, I want {req.get('i_want', 'functionality')}"
                            description = f"So that {req.get('so_that', 'business value is delivered')}"
                        else:
                            title = f"As a user, I want to use {epic_title.lower()} functionality"
                            description = f"Implement core functionality for {epic_title}"
                        
                        story = {
                            "id": story_id,
                            "epic": epic_title,
                            "epic_id": epic_id,
                            "title": title,
                            "description": description,
                            "acceptance_criteria": [
                                "Feature is implemented as specified",
                                "All functionality is accessible",
                                "Error handling is robust"
                            ],
                            "points": min(points_per_story, 8),
                            "priority": epic.get('priority', 'Medium'),
                            "sprint": None,
                            "status": "backlog"
                        }
                        user_stories.append(story)
                        story_id += 1
        
        return user_stories
    
    def _estimate_story_points(self, description: str, scenarios: List[Dict]) -> int:
        """
        Estimate story points based on complexity
        
        Fibonacci scale: 1, 2, 3, 5, 8, 13
        """
        # Base points
        points = 3
        
        # Add points based on number of scenarios
        num_scenarios = len(scenarios)
        if num_scenarios > 3:
            points = 8
        elif num_scenarios > 2:
            points = 5
        elif num_scenarios > 1:
            points = 3
        else:
            points = 2
        
        # Add points for complexity keywords
        complexity_keywords = ['integrate', 'api', 'payment', 'security', 'authentication', 'sync', 'complex']
        desc_lower = description.lower()
        
        if any(keyword in desc_lower for keyword in complexity_keywords):
            points += 2
        
        # Cap at 13 (anything larger should be broken down)
        return min(points, 13)
    
    async def _generate_epics_and_stories(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Generate epics and user stories from Phase 1 content (BRD, Requirements, etc.) using comprehensive EPICS_STORIES_PROMPT
        Supports full generation, incremental changes, and gap analysis modes
        Focuses on Requirements + BRD as primary input, ensures microservice/modular architecture approach
        """
        print(f"ðŸš€ Generating Epics and User Stories using EPICS_STORIES_PROMPT...")
        
        # Extract Phase 1 data - support both snake_case and camelCase from frontend
        phase1_data = data.get('phase1_data', {})
        gherkin_requirements = data.get('gherkin_requirements', []) or data.get('gherkinRequirements', [])
        requirements = data.get('requirements', [])
        brd = data.get('brd', '')
        prd = data.get('prd', '')
        functional_reqs = data.get('functional_requirements', []) or data.get('functionalRequirements', [])
        nonfunctional_reqs = data.get('nonfunctional_requirements', []) or data.get('nonFunctionalRequirements', [])
        stakeholders = data.get('stakeholders', [])
        risks = data.get('risks', [])
        api_spec = data.get('api_spec', {}) or data.get('apiSpec', {})
        
        # Existing epics and user stories (for incremental/gap-analysis generation)
        existing_epics = data.get('existing_epics', []) or data.get('existingEpics', [])
        existing_stories = data.get('existing_user_stories', []) or data.get('existingStories', [])
        
        # Generation mode flags
        is_incremental = data.get('is_incremental', False) or data.get('isIncrementalGeneration', False)
        manual_changes_mode = data.get('manual_changes_mode', False) or data.get('manualChangesMode', False)
        changes_only = data.get('changes_only', False) or data.get('changesOnly', False)
        changes_summary_from_frontend = data.get('changes_summary', '') or data.get('changesSummary', '')
        changed_content = data.get('changed_content', {}) or data.get('changedContent', {})
        
        # Project info - support both direct fields and nested project object
        project_obj = data.get('project', {})
        project_name = data.get('project_name', '')
        if not project_name and isinstance(project_obj, dict):
            project_name = project_obj.get('name', project_obj.get('project_name', 'Software Project'))
        if not project_name:
            project_name = 'Software Project'
            
        project_description = data.get('project_description', '')
        if not project_description and isinstance(project_obj, dict):
            project_description = project_obj.get('description', project_obj.get('project_description', ''))
        
        project_info = {
            'name': project_name,
            'description': project_description
        }
        
        print(f"ðŸ“Š Generation Mode:")
        print(f"  - Is Incremental: {is_incremental}")
        print(f"  - Manual Changes Mode: {manual_changes_mode}")
        print(f"  - Changes Only: {changes_only}")
        print(f"  - Existing Epics: {len(existing_epics)}")
        print(f"  - Existing Stories: {len(existing_stories)}")
        
        # Build comprehensive context from Requirements + BRD
        context_parts = []
        
        # 1. BRD Context (primary input)
        if brd:
            context_parts.append(f"**BUSINESS REQUIREMENTS DOCUMENT (BRD)**:\n{brd}\n")
        
        # 2. Requirements Context (primary input)
        requirements_text = ""
        if gherkin_requirements:
            requirements_text += f"\n**GHERKIN SCENARIOS** ({len(gherkin_requirements)} scenarios):\n"
            for idx, scenario in enumerate(gherkin_requirements[:25], 1):
                requirements_text += f"\nScenario {idx}: {scenario.get('scenario_title', 'Untitled')}\n"
                if scenario.get('background'):
                    requirements_text += f"Background: {scenario['background']}\n"
                for step in scenario.get('given_when_then', []):
                    requirements_text += f"  {step}\n"
            if len(gherkin_requirements) > 25:
                requirements_text += f"\n... and {len(gherkin_requirements) - 25} more scenarios"
        
        if requirements:
            requirements_text += f"\n**REQUIREMENTS** ({len(requirements)} items):\n"
            for idx, req in enumerate(requirements[:30], 1):
                if isinstance(req, dict):
                    req_text = req.get('requirement') or req.get('title') or str(req)
                else:
                    req_text = str(req)
                requirements_text += f"{idx}. {req_text}\n"
            if len(requirements) > 30:
                requirements_text += f"\n... and {len(requirements) - 30} more requirements"
        
        if requirements_text:
            context_parts.append(f"**REQUIREMENTS** (FROM PHASE 1):\n{requirements_text}\n")
        
        # 3. Functional/Non-Functional Requirements
        if functional_reqs or nonfunctional_reqs:
            fn_text = "\n**FUNCTIONAL REQUIREMENTS**:\n"
            for idx, req in enumerate(functional_reqs[:20], 1):
                if isinstance(req, dict):
                    req_text = req.get('requirement') or req.get('title') or str(req)
                else:
                    req_text = str(req)
                fn_text += f"  {idx}. {req_text}\n"
            if len(functional_reqs) > 20:
                fn_text += f"  ... and {len(functional_reqs) - 20} more\n"
            
            fn_text += "\n**NON-FUNCTIONAL REQUIREMENTS**:\n"
            for idx, req in enumerate(nonfunctional_reqs[:15], 1):
                if isinstance(req, dict):
                    req_text = req.get('requirement') or req.get('title') or str(req)
                else:
                    req_text = str(req)
                fn_text += f"  {idx}. {req_text}\n"
            if len(nonfunctional_reqs) > 15:
                fn_text += f"  ... and {len(nonfunctional_reqs) - 15} more\n"
            
            context_parts.append(fn_text)
        
        # 4. Risk Context
        if risks:
            risks_text = "\n**IDENTIFIED RISKS**:\n"
            for idx, risk in enumerate(risks[:10], 1):
                risks_text += f"  {idx}. {risk.get('description', 'Risk')} (Severity: {risk.get('severity', 'Medium')})\n"
            if len(risks) > 10:
                risks_text += f"  ... and {len(risks) - 10} more risks\n"
            context_parts.append(risks_text)
        
        # 5. API Context (if available)
        if api_spec:
            api_text = f"\n**API SPECIFICATION**:\n"
            api_text += f"- Title: {api_spec.get('info', {}).get('title', 'API')}\n"
            api_text += f"- Endpoints: {len(api_spec.get('paths', {}))}\n"
            
            api_endpoints = api_spec.get('paths', {})
            resource_groups = {}
            for path, methods in api_endpoints.items():
                resource = path.split('/')[1] if '/' in path else 'general'
                if resource not in resource_groups:
                    resource_groups[resource] = []
                for method, spec in methods.items():
                    summary = spec.get('summary', spec.get('description', 'Endpoint'))
                    resource_groups[resource].append(f"{method.upper()} {path}: {summary}")
            
            for resource, endpoints in resource_groups.items():
                api_text += f"\n{resource.capitalize()} Resource:\n"
                for endpoint in endpoints[:5]:
                    api_text += f"  â€¢ {endpoint}\n"
                if len(endpoints) > 5:
                    api_text += f"  â€¢ ... and {len(endpoints) - 5} more\n"
            
            context_parts.append(api_text)
        
        # Prepare generation context
        full_context = "\n".join(context_parts)
        
        # Build generation mode instructions
        generation_instructions = ""
        
        if is_incremental and existing_epics:
            # Incremental mode: Show existing epics, ask for new ones only
            generation_instructions = f"""
ðŸ”„ **INCREMENTAL GENERATION MODE**

**EXISTING EPICS** (DO NOT REGENERATE OR MODIFY):
{len(existing_epics)} existing epics already approved:
"""
            for idx, epic in enumerate(existing_epics[:10], 1):
                generation_instructions += f"\n  {idx}. **{epic.get('title')}** (ID: {epic.get('id')})"
                generation_instructions += f"\n     - {epic.get('description', '')[:100]}{'...' if len(epic.get('description', '')) > 100 else ''}"
            
            if len(existing_epics) > 10:
                generation_instructions += f"\n  ... and {len(existing_epics) - 10} more existing epics\n"
            
            generation_instructions += f"""

**CRITICAL RULES**:
- âŒ DO NOT return any of the {len(existing_epics)} existing epics above
- âŒ DO NOT modify or recreate existing user stories
- âœ… ONLY create NEW epics for UNCOVERED functionality
- âœ… Ensure new epic IDs start from {len(existing_epics) + 1}
- âœ… If no new functionality found, return empty: {{{{\"epics\": [], \"user_stories\": []}}}}

**NEW CHANGES DETECTED**:
{changes_summary_from_frontend}

Generate ONLY NEW epics for the changes above, not covered by the {len(existing_epics)} existing epics.
"""
        
        elif manual_changes_mode and existing_epics:
            # Gap analysis mode: Compare Phase 1 with existing epics
            generation_instructions = f"""
ðŸ” **GAP ANALYSIS MODE**

**EXISTING EPICS** ({len(existing_epics)} total, shown for reference):
"""
            for idx, epic in enumerate(existing_epics[:15], 1):
                generation_instructions += f"\n  {idx}. **{epic.get('title')}** - {epic.get('description', '')[:80]}{'...' if len(epic.get('description', '')) > 80 else ''}"
            
            if len(existing_epics) > 15:
                generation_instructions += f"\n  ... and {len(existing_epics) - 15} more"
            
            generation_instructions += f"""

**YOUR TASK**:
1. Read ALL Phase 1 content (BRD + Requirements) above completely
2. For EACH requirement, check if covered by ANY of the {len(existing_epics)} existing epics
3. Identify TRULY NEW requirements not covered by any epic
4. Create ONLY NEW epics for uncovered functionality (IDs from {len(existing_epics) + 1})
5. If EVERYTHING is covered, return empty arrays

**CRITICAL RULES**:
- âŒ NEVER return existing epics (IDs 1-{{len(existing_epics)}})
- âŒ NEVER recreate or modify existing stories
- âŒ NEVER create overlapping functionality
- âœ… When in doubt about overlap, create the epic (better to split than miss)
"""
        
        else:
            # Full generation mode: Create all epics from scratch with comprehensive microservice analysis
            generation_instructions = """
ðŸŽ¯ **COMPREHENSIVE 360Â° MICROSERVICE ECOSYSTEM DECOMPOSITION & END-TO-END FLOW MAPPING**

Your task: Decompose Phase 1 into **6-12 INDEPENDENT MICROSERVICE EPICS** covering complete solution architecture with clear end-to-end execution flow.

---

**PHASE 1: COMPREHENSIVE REQUIREMENT ANALYSIS** (Extract EVERY aspect)

Scan Phase 1 and identify:
1. **User Journey**: What is the PRIMARY user action/goal?
2. **Business Process**: WHAT sequence of steps accomplishes this?
3. **Data Entities**: WHAT objects/entities are created/modified/read?
4. **Integration Points**: WHAT external systems are involved?
5. **Quality Needs**: What about latency, throughput, availability, security?
6. **User Roles**: WHO performs WHAT actions with WHAT permissions?
7. **Failure Scenarios**: What can go wrong? How to recover?
8. **Scalability**: Does it mention volumes, peak loads, growth?

---

**PHASE 2: 360Â° ECOSYSTEM MAPPING - 12 STRATEGIC DIMENSIONS**

For EACH category below, check if Phase 1 mentions it. If YES â†’ Create an Epic. If NO â†’ Skip it.

**TIER 1: USER-FACING & ORCHESTRATION (2-3 EPICS)**
â”Œâ”€ 1. USER-FACING FEATURES (Frontend/Client Layer)
â”‚  Purpose: Handle user interactions, workflows, UI/UX
â”‚  INCLUDE if: Phase 1 mentions users, workflows, interfaces, dashboards, forms
â”‚  Example Epics: "Fleet Manager Web Dashboard", "Driver Mobile App", "Admin Portal"
â”‚  
â”œâ”€ 2. CORE BUSINESS LOGIC ORCHESTRATION (Primary Capability)
â”‚  Purpose: Implement main business process, domain rules, workflows
â”‚  INCLUDE if: Phase 1 describes PRIMARY capability (e.g., "track vehicle locations", "process orders")
â”‚  Example Epics: "Real-Time Vehicle Location Tracking Engine", "Order Processing & Fulfillment"
â”‚  MANDATORY: This is the heartbeat of your solution - ALWAYS include
â”‚
â””â”€ 3. API & SERVICE GATEWAY (Microservice Orchestration)
   Purpose: Expose business logic via clean APIs, service coordination
   INCLUDE if: Phase 1 mentions multiple clients, integrations, microservices, REST/GraphQL
   Example Epics: "API Gateway & Microservice Orchestration", "RESTful API Layer"

**TIER 2: DATA & PERSISTENCE (1-2 EPICS)**
â”Œâ”€ 4. DATABASE & DATA PERSISTENCE (Storage Layer)
â”‚  Purpose: Store and retrieve domain data efficiently
â”‚  INCLUDE if: Phase 1 mentions data, entities, persistence, queries
â”‚  Example Epics: "PostgreSQL Data Persistence & Query Layer", "Document Database for Events"
â”‚  MANDATORY: Unless Phase 1 explicitly has NO data â†’ Create at minimum
â”‚
â””â”€ 5. CACHE & SESSION MANAGEMENT (Performance Layer)
   Purpose: Speed up queries, maintain sessions, reduce database load
   INCLUDE if: Phase 1 mentions performance, caching, sessions, OR high query volumes
   Example Epics: "Redis Caching & Session Management", "Distributed Cache Layer"

**TIER 3: SECURITY & ACCESS (2-3 EPICS)**
â”Œâ”€ 6. AUTHENTICATION & IDENTITY MANAGEMENT (Security Foundation)
â”‚  Purpose: User authentication, JWT/OAuth, MFA, session tokens
â”‚  INCLUDE if: Phase 1 mentions users, login, security, authentication
â”‚  Example Epics: "OAuth 2.0 Authentication Service", "JWT-Based Identity Management"
â”‚  MANDATORY: If Phase 1 mentions users â†’ ALWAYS create this
â”‚
â”œâ”€ 7. AUTHORIZATION & ACCESS CONTROL (Permission Management)
â”‚  Purpose: RBAC, permission policies, resource-level access control
â”‚  INCLUDE if: Phase 1 mentions roles (admin, user, etc.) OR different access levels
â”‚  Example Epics: "Role-Based Access Control (RBAC) Service", "Permission Policy Engine"
â”‚  CONDITIONAL: Only if Phase 1 explicitly mentions MULTIPLE ROLES with DIFFERENT permissions
â”‚
â””â”€ 8. DATA SECURITY & ENCRYPTION (Compliance Layer)
   Purpose: Encrypt sensitive data, audit logging, compliance (GDPR/HIPAA), PII protection
   INCLUDE if: Phase 1 mentions security, compliance, sensitive data, payment info
   Example Epics: "Data Encryption & Security Compliance", "Audit Logging & Compliance"

**TIER 4: INTEGRATION & ASYNC (2-3 EPICS)**
â”Œâ”€ 9. THIRD-PARTY INTEGRATIONS (External Systems)
â”‚  Purpose: Connect payment gateways, email services, SMS, analytics, maps, etc.
â”‚  INCLUDE if: Phase 1 EXPLICITLY names external services (e.g., "Stripe", "SendGrid", "Google Maps")
â”‚  Example Epics: "Payment Gateway Integration (Stripe)", "Email & SMS Notification Service"
â”‚  CRITICAL: ONLY create if Phase 1 specifically mentions external service
â”‚
â”œâ”€ 10. REAL-TIME & EVENT STREAMING (Async Communication)
â”‚   Purpose: Message queues, WebSockets, event broadcasting, async workflows
â”‚   INCLUDE if: Phase 1 mentions real-time, notifications, async, event-driven, or streaming
â”‚   Example Epics: "Message Queue & Event Streaming (Kafka)", "Real-Time WebSocket Notifications"
â”‚
â””â”€ 11. BACKGROUND JOBS & SCHEDULED TASKS (Async Processing)
    Purpose: Batch processing, cron jobs, scheduled workflows, cleanup tasks
    INCLUDE if: Phase 1 mentions background jobs, scheduled tasks, batch processing
    Example Epics: "Background Job Queue (Celery/Hangfire)", "Scheduled Task Processor"

**TIER 5: OPERATIONS & OBSERVABILITY (1-3 EPICS)**
â”Œâ”€ 12. MONITORING, LOGGING & ALERTING (Observability)
â”‚   Purpose: Centralized logging, metrics collection, health checks, alerting
â”‚   INCLUDE if: Phase 1 mentions 24/7 operations, SLAs, uptime requirements, monitoring
â”‚   Example Epics: "Centralized Logging (ELK/Splunk)", "Monitoring & Alerting (Prometheus/Datadog)"
â”‚
â”œâ”€ 13. DEPLOYMENT & CI/CD (DevOps)
â”‚   Purpose: Infrastructure automation, deployment pipeline, containers, Kubernetes
â”‚   INCLUDE if: Phase 1 mentions deployment, scaling, environments (dev/staging/prod)
â”‚   Example Epics: "Docker Containerization & CI/CD Pipeline", "Kubernetes Infrastructure"
â”‚
â””â”€ 14. ADMIN PANEL & SYSTEM MANAGEMENT (Maintenance)
    Purpose: Admin functions, system configuration, data management, reporting
    INCLUDE if: Phase 1 mentions admin functions, reporting, configuration
    Example Epics: "Admin Management Console", "System Configuration & Reporting"

---

**PHASE 3: MICROSERVICE INDEPENDENCE VALIDATION**

EACH epic MUST satisfy ALL of these:

âœ… **Single Responsibility**: One clear purpose (NOT "Frontend + Backend + DB")
âœ… **Independent Deployability**: Can deploy WITHOUT deploying other epics
âœ… **Isolated Data Storage**: Own database/schema (or cache) - NOT shared tables
âœ… **Clean Interfaces**: APIs (REST/Events), NOT direct function calls
âœ… **Minimal Dependencies**: List other epics it NEEDS (usually 0-2)
âœ… **Testable in Isolation**: Can mock dependencies and test independently
âœ… **Domain-Specific Title**: NOT generic ("Frontend", "Backend", "Database")
âœ… **Clear Ownership**: One team can build, deploy, operate this

---

**PHASE 4: END-TO-END FLOW MAPPING**

Map the COMPLETE USER JOURNEY:

1. **Identify Primary User Goal** from Phase 1
   Example: "Driver logs in â†’ sees live vehicle location â†’ accepts delivery â†’ navigates to destination"

2. **Map Each Step to an Epic**:
   Step 1 (Login) â†’ Epic: "Authentication Service"
   Step 2 (View location) â†’ Epic: "Vehicle Location Tracking Engine"
   Step 3 (Accept delivery) â†’ Epic: "Order Processing & Fulfillment"
   Step 4 (Navigation) â†’ Epic: "Real-Time Navigation Service"

3. **Identify Dependencies**:
   "Order Processing" depends on: "Authentication" (verify user), "Payment" (process payment)
   "Location Tracking" depends on: "Database" (store locations), "Message Queue" (broadcast updates)

4. **Define Execution Order**:
   - LEVEL 0 (Independent): Authentication, Database, Cache
   - LEVEL 1 (Depend on L0): Business Logic, API Gateway
   - LEVEL 2 (Depend on L1): Integrations, Real-Time Services
   - LEVEL 3 (Depend on L2): Admin, Monitoring, CI/CD

5. **Validate NO Circular Dependencies**:
   âŒ BAD: A depends on B, B depends on A
   âœ… GOOD: A â†’ B â†’ C (one-directional flow)

---

**PHASE 5: EPIC GENERATION STRATEGY**

For EACH applicable category from Phase 1:

1. Create DOMAIN-SPECIFIC title (not generic)
   âŒ "User Service"
   âœ… "OAuth 2.0 Authentication Service for Fleet Management"

2. Write description explaining architectural reason
   âŒ "Handles users"
   âœ… "Provides centralized OAuth 2.0 authentication for all clients. Separate from business logic to enable single sign-on across web and mobile. Manages JWT token lifecycle and session validation."

3. List why it's a separate microservice
   âŒ "It's important"
   âœ… "Independent microservice because Phase 1 requires multi-client access (web + mobile), JWT-based auth, and MFA support. Can scale/patch separately without affecting other services."

4. Extract FR/NFR directly from Phase 1 (NO INVENTED FEATURES)
   âœ… "Phase 1 requirement: Support OAuth 2.0"
   âœ… "Phase 1 requirement: MFA for admin users"
   âŒ "Support GraphQL APIs" (if not mentioned)

5. Identify DEPENDENCIES (which other epics this needs)
   Example: "Authorization Service" depends on ["Authentication Service", "Database"]

---

**PHASE 6: STORY DISTRIBUTION ACROSS 5 DIMENSIONS**

For EACH epic, create 2-6 stories distributed across:

1. **API/Contract Stories** (How external systems call this epic)
   - REST endpoints, response formats, error handling
   - "As a client app, I want to call the API to get vehicle location, so that I can display it"

2. **Backend Logic Stories** (Business rules, algorithms, processing)
   - Domain logic, validation, processing
   - "As the system, I want to calculate route optimization, so that deliveries are efficient"

3. **Database/Persistence Stories** (Data storage, queries, migrations)
   - Schema, data models, query optimization
   - "As a developer, I want efficient geospatial queries for nearby vehicles, so that location search is fast"

4. **Integration/External Stories** (External system connections)
   - Payment processing, third-party APIs, webhooks
   - "As the order service, I want to call Stripe API to process payment, so that we get paid"

5. **Quality/Cross-Cutting Stories** (Testing, monitoring, security)
   - Tests, monitoring, error handling, security
   - "As an operator, I want to monitor API latency, so that I know service health"

DISTRIBUTION GUIDANCE:
- Simple epic (2 epics): 2 stories (e.g., API + Logic OR Logic + DB)
- Medium epic (3-4 stories): 3-4 stories (API + Logic + DB + one more)
- Complex epic (4-6 stories): 5-6 stories (all 5 dimensions + additional depth)

---

**FINAL GENERATION CHECKLIST**

Before returning JSON:
â˜‘ Decomposed Phase 1 into 6-12 microservice epics
â˜‘ Each epic satisfies SINGLE RESPONSIBILITY principle
â˜‘ Each epic independently deployable
â˜‘ Covered 360Â° ecosystem: User-facing, Core Logic, APIs, Data, Security, Integration, Async, Monitoring, DevOps
â˜‘ Mapped complete end-to-end user journey
â˜‘ Defined clear dependencies between epics (NO circular)
â˜‘ Created 2-6 stories per epic (minimum 2)
â˜‘ Total stories = 2-3x number of epics
â˜‘ Each story covers one of 5 dimensions: API, Logic, DB, Integration, Quality
â˜‘ FR/NFR are text, extracted from Phase 1 (NOT invented)
â˜‘ Epic titles are domain-specific (NOT generic)
â˜‘ Dependencies listed in execution order (0-independent, 1-depends on L0, etc.)
â˜‘ NO overlapping responsibilities between epics
â˜‘ EVERY epic has at least 2 user stories (MANDATORY)

---

**ANTI-PATTERNS TO AVOID**

âŒ Generic titles: "Frontend", "Backend", "Database", "Service"
   âœ… Instead: "Driver Mobile App", "Order Processing Engine", "PostgreSQL Time-Series DB", "OAuth Service"

âŒ Overlapping epics: Both "User Management" AND "Authentication"
   âœ… Split cleanly: "Authentication" (login/tokens), "User Profile" (profile updates)

âŒ Invented features not in Phase 1
   âœ… Only decompose what's explicitly mentioned or logically required

âŒ Fewer than 2 stories per epic
   âœ… Each epic needs minimum 2 stories for meaningful implementation

âŒ More than 12 epics (unless truly massive system)
   âœ… Consolidate related epics (e.g., "Auth" + "Authz" â†’ "Identity & Access Service")

âŒ Circular dependencies: A â†’ B â†’ A
   âœ… Always one-directional: A â†’ B â†’ C

---

**GENERATION OUTPUT REQUIREMENTS**

Generate JSON with:
- 6-12 microservice epics (minimum 3 for tiny projects)
- Each epic with 2-6 user stories (minimum 2, maximum 6)
- Total stories = 2-3x total epics
- Stories distributed across 5 dimensions (API, Logic, DB, Integration, Quality)
- Complete 360Â° ecosystem coverage
- Clear end-to-end execution flow
- Valid JSON ONLY (no markdown, no explanations)
"""

        # Build the comprehensive prompt
        project_name = project_info.get('name', 'Software Project')
        prompt = f"""You are an expert Enterprise Architect specializing in microservice decomposition and 360Â° ecosystem design.

**PROJECT**: {project_name}

**PHASE 1 REQUIREMENTS** (Your PRIMARY source of truth):

{full_context}

---

{generation_instructions}

---

**USER STORIES GENERATION REQUIREMENTS** (CRITICAL - GENERATE 2-5 STORIES PER EPIC):

ðŸ”¥ **MANDATORY RULE**: Every epic MUST have MINIMUM 2 stories and MAXIMUM 5 stories
- DO NOT generate the same number for all epics
- DO NOT always generate 5 stories
- DO vary the number based on each epic's requirements and complexity
- Simple epics: 2-3 stories
- Complex epics: 3-5 stories

**HOW TO DECIDE STORY COUNT FOR EACH EPIC**:
- Read epic description (length and complexity)
- Read epic.dependencies (more deps = more stories)
- Read epic.points (higher points = more stories)
- Decide: Is this simple (2-3 stories) or complex (3-5 stories)?
- Generate that many stories, NOT all the same number

ðŸ”¥ **FR/NFR MAPPING RULE**: Functional and Non-Functional Requirements MUST be extracted from Phase 1 content above, NOT invented or generic
- Search the Phase 1 requirements section above for each capability mentioned
- Extract EXACT text from Phase 1 (don't paraphrase or generalize)
- Each story's functional_requirements[] must cite requirements from Phase 1
- Each story's nonfunctional_requirements[] must cite constraints/SLAs from Phase 1
- If Phase 1 mentions "95% uptime requirement", map to relevant story NFR
- If Phase 1 mentions "Support OAuth 2.0 authentication", map to relevant story FR

ðŸ”¥ **BLOCKER IDENTIFICATION RULE**: Identify REAL blockers from Phase 1, not dummy data
- Search Phase 1 for: risks, constraints, dependencies, limitations, third-party integrations
- Only include blockers if explicitly mentioned or implied in Phase 1
- Examples of valid blockers from Phase 1:
  * "Requires integration with Stripe payment gateway" â†’ blocker for payment processing epic
  * "Must comply with PCI-DSS standards" â†’ blocker for payment/data handling epic
  * "Currently on SQL Server 2012" â†’ blocker for database migration epic
  * "Awaiting vendor API documentation" â†’ blocker for integration epic
- If Phase 1 doesn't mention specific blockers, leave blockers array empty (not dummy data)

**TARGET STORY COUNT BY EPIC COMPLEXITY**:
- âŒ NEVER generate only 2 stories per epic (this is minimum, not target)
- ðŸ“Š Simple Epic (low complexity): 2-3 stories
- ðŸ“Š Standard Epic (medium complexity): 3-4 stories  
- ðŸ“Š Complex Epic (high complexity): 4-5 stories
- âš ï¸ If any epic ends up with only 2 stories, ADD AT LEAST 1 MORE to reach 3+

For EACH epic you generate, create 2-5 stories distributed across these 5 DIMENSIONS:

**DIMENSION 1: API/CONTRACT STORIES** (How external systems interact)
- How frontend/clients call this service
- REST endpoints, GraphQL, response formats, error handling
- Example: "As a mobile app, I want to call the location API to get current vehicle position, so that I can display it on map"
- Include: 1 story per epic (MANDATORY)

**DIMENSION 2: BACKEND LOGIC STORIES** (Business rules & algorithms)
- Domain logic, processing, validation, transformations
- Business rules implementation, state management
- Example: "As the system, I want to validate order details before processing payment, so that invalid orders are rejected"
- Include: 1 story per epic (MANDATORY)

**DIMENSION 3: DATABASE/PERSISTENCE STORIES** (Data storage & access)
- Schema design, data models, query optimization, migrations
- Persistence patterns, indexing, relationships
- Example: "As a developer, I want efficient geospatial queries for finding nearby vehicles, so that search returns results in <200ms"
- Include: 1 story if epic involves data (COMMON)

**DIMENSION 4: INTEGRATION/EXTERNAL STORIES** (Third-party system connections)
- Payment processing, email/SMS sending, external APIs, webhooks
- Authorization tokens, error recovery, rate limiting
- Example: "As the order service, I want to call Stripe API to charge payment, so that customers are billed correctly"
- Include: 1 story if epic integrates with external systems (CONDITIONAL)

**DIMENSION 5: QUALITY/CROSS-CUTTING STORIES** (Testing, monitoring, security)
- Automated tests, monitoring, error handling, security checks, audit logging
- Health checks, alerts, documentation
- Example: "As an operator, I want to monitor API response times and error rates, so that I know service health in real-time"
- Include: 1 story per epic (RECOMMENDED)

**STORY COUNT GUIDANCE BY EPIC TYPE** (STRICTLY FOLLOW):

Simple Epic (short description, few/no dependencies, simple responsibility):
- GENERATE: 2-3 stories (NOT MORE, NOT ALWAYS 3)
- Examples: "Simple Login Service", "Notification Service", "Cache Service"
- Include: API endpoint + logic + optional quality/monitoring

Standard Epic (medium description, 1-2 dependencies):
- GENERATE: 3-4 stories (NOT MORE, NOT ALWAYS 4)
- Examples: "Order Processing", "User Management", "Payment Processing"
- Include: API + logic + database + optional quality

Complex Epic (long description, 2+ dependencies, multiple integrations):
- GENERATE: 4-5 stories (NOT MORE, NOT LESS)
- Examples: "Real-Time Tracking Engine", "Advanced Analytics", "Multi-service Integration"
- Include: API + logic + database + integration + quality

**KEY RULE**: Count varies per epic - DON'T generate all epics with same number of stories

**STORY DISTRIBUTION TABLE**:

For 6-epic project, generate 12-18 total stories:
- Epic 1 (Frontend): 2-3 stories (Dim1, Dim2, Dim5)
- Epic 2 (Core Logic): 4 stories (Dim1, Dim2, Dim3, Dim5)
- Epic 3 (Database): 2-3 stories (Dim2, Dim3, Dim5)
- Epic 4 (Auth): 3 stories (Dim1, Dim2, Dim5)
- Epic 5 (Integration): 3-4 stories (Dim1, Dim4, Dim5)
- Epic 6 (Monitoring): 2-3 stories (Dim1, Dim2, Dim5)
- TOTAL: 16-20 stories (2.7-3.3 per epic)

**STORY CREATION RULES**:

1. EVERY story must use "As a [role], I want [action], so that [benefit]" format
   âŒ "Login functionality"
   âœ… "As a user, I want to log in with email and password, so that I can access my account"

2. EVERY story must have 2-4 acceptance criteria (testable, specific)
   âœ… Criterion 1: Given user enters valid email, when clicked login, system validates email format
   âœ… Criterion 2: Given user enters wrong password, when clicked login, error message shows
   âœ… Criterion 3: When login successful, system redirects to dashboard

3. EVERY story must cite actual Phase 1 requirements (NOT invented)
   âŒ FR: "Support GraphQL" (if Phase 1 doesn't mention it)
   âœ… FR: "Support REST APIs" (if Phase 1 mentions multiple client access)
   
   **CRITICAL**: functional_requirements and nonfunctional_requirements MUST be extracted directly from Phase 1 requirements above
   - Search Phase 1 for mentions of each capability
   - Extract the EXACT requirement text (not paraphrased)
   - Map each story to Phase 1 requirements it implements
   - DO NOT generate dummy FR/NFR - every item must reference Phase 1 content

4. EVERY story must identify blockers from Phase 1 context
   - Search for: risks, dependencies, constraints, limitations in Phase 1
   - Examples of real blockers from Phase 1:
     * "Requires payment gateway integration" (dependency on external vendor)
     * "Must comply with HIPAA" (regulatory constraint)
     * "Currently on legacy database" (technical constraint)
     * "Awaiting third-party API documentation" (external blocker)
   - DO NOT invent blockers - only list if mentioned in Phase 1

4. EVERY story must have story points (2-8 range)
   - 2 pts: Trivial (1-2 day task)
   - 3 pts: Small (2-3 day task)
   - 5 pts: Medium (3-5 day task)
   - 8 pts: Large (full week task)

5. Each story MUST belong to exactly ONE epic
   - Set "epic_id" to the parent epic's ID
   - Set "epic" to the parent epic's title

6. Story IDs MUST be sequential across ALL stories
   - Story 1, 2, 3, 4, ... (NOT 1, 2, 1, 2 per epic)

---

**FINAL VALIDATION BEFORE JSON OUTPUT**

Count stories for each epic:
```
for each epic in epics:
  story_count = count(stories where story.epic_id == epic.id)
  ASSERT story_count >= 2, f"Epic {{epic.id}} '{{epic.title}}' has only {{story_count}} stories (minimum: 2)"
```

Validate total coverage:
```
total_epics = count(epics)
total_stories = count(user_stories)
target_ratio = total_stories / total_epics
ASSERT target_ratio >= 2.0, f"Only {{target_ratio}}x stories per epic (target: 2-3x)"
```

Validate 5-dimension coverage:
```
For each epic:
  dimensions_covered = count(distinct dimensions in epic's stories)
  ASSERT dimensions_covered >= 1, f"Epic {{epic.id}} doesn't cover any of 5 dimensions"
```

---

**JSON OUTPUT SCHEMA** (Valid JSON ONLY, no markdown):

{{
  "epics": [
    {{
      "id": 1,
      "title": "[DOMAIN-SPECIFIC TITLE - e.g., 'Real-Time Vehicle Location Tracking Engine']",
      "description": "Business value and scope - why this service exists",
      "why_separate": "Architectural reason for being independent microservice",
      "suggested": false,
      "suggested_reason": null,
      "dependencies": [2, 3],
      "blockers": ["Clear text blocker description"],
      "priority": "High"
    }}
  ],
  "user_stories": [
    {{
      "id": 1,
      "epic": "Epic Title",
      "epic_id": 1,
      "title": "As a [role], I want [goal], so that [benefit]",
      "description": "Detailed description of what needs to be implemented",
      "acceptance_criteria": [
        "Specific, testable criterion 1",
        "Specific, testable criterion 2",
        "Specific, testable criterion 3"
      ],
      "functional_requirements": ["Functional requirement this implements (text)", "Another FR requirement"],
      "nonfunctional_requirements": ["Performance requirement: Response time < 500ms", "Security: Use OAuth 2.0"],
      "dependencies": ["Story title this depends on", "Another story title"],
      "blockers": ["Blocker description: e.g., 'Requires API key from third party'"],
      "points": 5,
      "priority": "High",
      "sprint": null,
      "status": "backlog"
    }}
  ]
}}

**CRITICAL REQUIREMENTS**:
1. Return ONLY valid JSON, no markdown or explanation
2. Ensure all epic IDs are unique and sequential
3. Ensure all story IDs are unique and sequential
4. Every story must have an epic_id pointing to a valid epic in the response
5. Generate 5-8 epics if justified by 360Â° analysis (minimum 3 always)
6. **MINIMUM 2-3 USER STORIES PER EPIC** (maximum depends on epic complexity):
   - Simple epics: minimum 2 stories
   - Complex epics: 3-5 stories
   - Very complex (like API or Database): 4-6 stories
   - TOTAL stories should be 2-3x number of epics
   - Example: 6 epics = 12-18 total stories (2-3 per epic minimum)
7. Use TEXT descriptions for:
   - "functional_requirements": List of specific capabilities/requirements (NOT numbers)
   - "nonfunctional_requirements": Performance, security, scalability requirements (NOT numbers)
   - "dependencies": Story titles or descriptions (NOT just IDs)
   - "blockers": Clear text descriptions of blockers (NOT abbreviated)
8. In incremental mode: ONLY include NEW epics (IDs {{{{len(existing_epics) + 1}}}} and higher)
9. In incremental mode: If NO new epics needed, return {{{{\"epics\": [], \"user_stories\": []}}}}
10. Use microservice/modular thinking: separate concerns, clear boundaries
11. NO invented features: only decompose Phase 1 content
12. EVERY EPIC MUST HAVE AT LEAST 2 USER STORIES - this is MANDATORY
"""
        
        try:
            print(f"ðŸ“¤ Calling OpenAI API with comprehensive prompt (temperature=0.3 for consistency)...")
            
            # Call OpenAI API with temperature 0.3 for consistent output
            response = await self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system", 
                        "content": "You are an expert Product Manager and Agile Scrum Master who creates comprehensive, hierarchical epics and user stories from requirements. You deeply understand microservice architecture and decomposition. You ALWAYS respond with ONLY valid JSON, no explanations or markdown."
                    },
                    {
                        "role": "user", 
                        "content": prompt
                    }
                ],
                temperature=0.3,  # Consistent, deterministic output
                max_tokens=6000
            )
            
            # Parse the response
            content = response.choices[0].message.content.strip()
            print(f"ðŸ“¥ Received response from OpenAI ({len(content)} chars)")
            
            # Remove markdown code blocks if present
            if content.startswith("```"):
                content = content.split("```")[1]
                if content.startswith("json"):
                    content = content[4:]
                content = content.strip()
            
            result = json.loads(content)
            
            # Validate structure
            if 'epics' not in result or 'user_stories' not in result:
                raise ValueError("Missing epics or user_stories in response")
            
            epics = result.get('epics', [])
            user_stories = result.get('user_stories', [])
            
            print(f"âœ… Generated {len(epics)} epics and {len(user_stories)} user stories")
            
            # ðŸ”§ POST-PROCESSING: Ensure story count varies (2-5 per epic, not constant 5)
            print(f"\nðŸ”§ POST-PROCESSING: Varying story counts 2-5 per epic...")
            for epic_idx, epic in enumerate(epics):
                epic_id = epic.get('id')
                epic_title = epic.get('title', f'Epic {epic_id}')
                epic_stories = [s for s in user_stories if s.get('epic_id') == epic_id]
                current_count = len(epic_stories)
                
                # Calculate target based on epic properties to vary the count
                target_count = 2  # Default minimum
                
                # Vary by complexity signals
                if epic_idx % 3 == 0:  # Every 3rd epic gets 2-3 stories
                    target_count = 2 + (epic_idx % 2)  # 2 or 3
                elif epic_idx % 3 == 1:  # Every 3rd epic gets 3-4 stories
                    target_count = 3 + (epic_idx % 2)  # 3 or 4
                else:  # Every 3rd epic gets 4-5 stories
                    target_count = 4 + (epic_idx % 2)  # 4 or 5
                
                # Also consider epic properties for variation
                if epic.get('priority') == 'High' and epic.get('points', 0) > 30:
                    target_count = min(5, max(3, target_count + 1))  # Increase complex high-priority epics
                elif epic.get('priority') == 'Low' and epic.get('points', 0) < 15:
                    target_count = max(2, min(3, target_count - 1))  # Decrease simple low-priority epics
                
                # Enforce minimum 2, maximum 5
                target_count = max(2, min(5, target_count))
                
                print(f"  Epic {epic_idx + 1}: '{epic_title[:40]}' - Current: {current_count}, Target: {target_count}")
                
                if current_count > target_count:
                    # Remove excess stories (keep first target_count)
                    excess = current_count - target_count
                    story_ids_to_remove = [s.get('id') for s in epic_stories[target_count:]]
                    user_stories = [s for s in user_stories if s.get('id') not in story_ids_to_remove]
                    print(f"    âž¡ï¸ Removed {excess} stories (too many)")
            
            # Normalize IDs in incremental mode
            if is_incremental and existing_epics:
                try:
                    max_existing_epic_id = max([e.get('id', 0) for e in existing_epics] or [0])
                    max_existing_story_id = max([s.get('id', 0) for s in existing_stories] or [0])
                except (ValueError, TypeError):
                    max_existing_epic_id = len(existing_epics)
                    max_existing_story_id = len(existing_stories)
                
                # Remap epic IDs if needed
                epic_id_map = {}
                for epic in epics:
                    old_id = epic.get('id', 1)
                    if old_id <= max_existing_epic_id:
                        new_id = max_existing_epic_id + 1
                        epic_id_map[old_id] = new_id
                        epic['id'] = new_id
                        max_existing_epic_id = new_id
                    else:
                        epic_id_map[old_id] = old_id
                
                # Remap story IDs and epic_id references
                for story in user_stories:
                    if story.get('id', 1) <= max_existing_story_id:
                        max_existing_story_id += 1
                        story['id'] = max_existing_story_id
                    
                    # Remap epic_id reference
                    if 'epic_id' in story and story['epic_id'] in epic_id_map:
                        story['epic_id'] = epic_id_map[story['epic_id']]
            
            # Ensure all stories have required fields
            for epic in epics:
                if 'id' not in epic:
                    epic['id'] = len(epics)
                if 'title' not in epic:
                    epic['title'] = f"Epic {epic['id']}"
                if 'description' not in epic:
                    epic['description'] = ""
                if 'why_separate' not in epic:
                    epic['why_separate'] = ""
                if 'dependencies' not in epic:
                    epic['dependencies'] = []
                if 'blockers' not in epic:
                    epic['blockers'] = []
                if 'points' not in epic:
                    epic['points'] = 0
                if 'priority' not in epic:
                    epic['priority'] = "Medium"
                if 'requirements_mapped' not in epic:
                    epic['requirements_mapped'] = []
            
            # Ensure all stories have required fields
            for story in user_stories:
                if 'id' not in story:
                    story['id'] = len(user_stories)
                if 'epic_id' not in story and epics:
                    story['epic_id'] = epics[0]['id']
                if 'epic' not in story and epics:
                    story['epic'] = epics[0].get('title', 'Unknown')
                if 'title' not in story:
                    story['title'] = f"Story {story['id']}"
                if 'description' not in story:
                    story['description'] = ""
                if 'acceptance_criteria' not in story:
                    story['acceptance_criteria'] = []
                if 'fr_mapping' not in story:
                    story['fr_mapping'] = []
                if 'nfr_mapping' not in story:
                    story['nfr_mapping'] = []
                if 'dependencies' not in story:
                    story['dependencies'] = []
                if 'blockers' not in story:
                    story['blockers'] = []
                if 'points' not in story:
                    story['points'] = 5
                if 'priority' not in story:
                    story['priority'] = "Medium"
                if 'sprint' not in story:
                    story['sprint'] = None
                if 'status' not in story:
                    story['status'] = "backlog"
            
            # ðŸš¨ CRITICAL VALIDATION: Enforce minimum 2 stories per epic based on weightage
            print(f"\nðŸ“Š STORY COUNT VALIDATION (Minimum 2 per epic):")
            
            max_story_id = max([s.get('id', 0) for s in user_stories] or [0])
            stories_to_add = []
            
            for epic in epics:
                epic_id = epic.get('id')
                epic_title = epic.get('title', f'Epic {epic_id}')
                
                # Count existing stories for this epic
                epic_stories = [s for s in user_stories if s.get('epic_id') == epic_id]
                story_count = len(epic_stories)
                
                # Calculate target stories based on epic weightage/complexity
                # Simple metric: use priority and complexity hints
                priority = epic.get('priority', 'Medium')
                points = epic.get('points', 0)
                
                # Determine target story count
                target_stories = 2  # Minimum
                if points > 20 or priority == 'High' or len(epic.get('dependencies', [])) > 2:
                    target_stories = 3  # Medium complexity
                if points > 40 or len(epic.get('functional_requirements', [])) > 3:
                    target_stories = 4  # Higher complexity
                if points > 60 or epic.get('suggested') == False:  # Core epic
                    target_stories = 5  # Complex epic
                
                print(f"  Epic {epic_id} '{epic_title[:50]}': {story_count} stories (target: {target_stories})")
                
                # Generate missing stories if needed
                if story_count < target_stories:
                    shortage = target_stories - story_count
                    print(f"    âš ï¸ Adding {shortage} generated stories to reach target of {target_stories}")
                    
                    # Synthetic stories covering the 5 dimensions
                    dimensions = [
                        {
                            'title': f'As a user, I want to access {epic_title} via API, so that I can integrate with other systems',
                            'description': f'Provide REST API endpoints for {epic_title}. Include error handling and response pagination.',
                            'dimension': 'API/Contract',
                            'functional_requirements': [f'Expose {epic_title} functionality via REST API'],
                            'nonfunctional_requirements': ['API response time < 500ms', 'Support concurrent requests'],
                            'points': 5
                        },
                        {
                            'title': f'As a developer, I want to implement core business logic for {epic_title}, so that requirements are met',
                            'description': f'Implement backend logic and validation for {epic_title}. Handle edge cases and error scenarios.',
                            'dimension': 'Backend Logic',
                            'functional_requirements': [f'Implement core logic for {epic_title}', 'Validate input data'],
                            'nonfunctional_requirements': ['Process requests within SLA', 'Maintain data consistency'],
                            'points': 5
                        },
                        {
                            'title': f'As a database architect, I want to design persistence schema for {epic_title}, so that data is efficiently stored and queried',
                            'description': f'Design and implement database schema for {epic_title}. Create indexes for performance optimization.',
                            'dimension': 'Database/Persistence',
                            'functional_requirements': [f'Design schema for {epic_title}', 'Create necessary indexes'],
                            'nonfunctional_requirements': ['Query response time < 200ms', 'Support data retention policies'],
                            'points': 3
                        },
                        {
                            'title': f'As an operator, I want to monitor {epic_title} service health and performance, so that issues are detected early',
                            'description': f'Implement monitoring, logging, and alerting for {epic_title}. Track key metrics and error rates.',
                            'dimension': 'Quality/Monitoring',
                            'functional_requirements': [f'Monitor {epic_title} performance metrics', 'Log all operations'],
                            'nonfunctional_requirements': ['Alert on error rate > 5%', 'Centralized logging'],
                            'points': 3
                        },
                        {
                            'title': f'As a tester, I want to create automated tests for {epic_title}, so that quality is maintained',
                            'description': f'Create unit, integration, and end-to-end tests for {epic_title}. Target >80% code coverage.',
                            'dimension': 'Quality/Testing',
                            'functional_requirements': [f'Create comprehensive tests for {epic_title}', 'Test error scenarios'],
                            'nonfunctional_requirements': ['Test execution < 5 minutes', '>80% code coverage'],
                            'points': 5
                        }
                    ]
                    
                    # Add shortage number of stories
                    for i in range(shortage):
                        max_story_id += 1
                        dimension_idx = i % len(dimensions)
                        dim_story = dimensions[dimension_idx]
                        
                        new_story = {
                            'id': max_story_id,
                            'epic': epic_title,
                            'epic_id': epic_id,
                            'title': dim_story['title'],
                            'description': dim_story['description'],
                            'acceptance_criteria': [
                                f'Story implements {dim_story["dimension"]} aspect',
                                f'Code follows {dim_story["dimension"]} best practices',
                                'Story meets acceptance criteria'
                            ],
                            'functional_requirements': dim_story['functional_requirements'],
                            'nonfunctional_requirements': dim_story['nonfunctional_requirements'],
                            'dependencies': [],
                            'blockers': [],
                            'points': dim_story['points'],
                            'priority': epic.get('priority', 'Medium'),
                            'sprint': None,
                            'status': 'backlog'
                        }
                        
                        stories_to_add.append(new_story)
                        print(f"      + Story {max_story_id}: {dim_story['dimension']} ({dim_story['points']} pts)")
            
            # Add synthesized stories to user_stories
            if stories_to_add:
                user_stories.extend(stories_to_add)
                print(f"\nâœ… Added {len(stories_to_add)} synthetic stories")
            
            # Final validation - log story count per epic
            print(f"\nðŸ“ˆ FINAL STORY DISTRIBUTION:")
            total_stories_per_epic = {}
            for story in user_stories:
                epic_id = story.get('epic_id')
                total_stories_per_epic[epic_id] = total_stories_per_epic.get(epic_id, 0) + 1
            
            for epic in epics:
                epic_id = epic.get('id')
                count = total_stories_per_epic.get(epic_id, 0)
                status = "âœ…" if count >= 2 else "âŒ"
                print(f"  {status} Epic {epic_id}: {count} stories")
            
            print(f"\nâœ… FINAL: {len(epics)} epics with {len(user_stories)} total stories ({len(user_stories)/max(len(epics), 1):.1f}x ratio)")
            
            return {
                'epics': epics,
                'user_stories': user_stories
            }
            
        except json.JSONDecodeError as e:
            print(f"âŒ JSON Parse Error: {str(e)}")
            print(f"Content: {content[:200] if len(content) > 200 else content}")
            raise
        except Exception as e:
            print(f"âŒ Error generating epics and stories: {str(e)}")
            print(f"Falling back to empty generation")
            
            # Return empty for error cases
            return {
                'epics': [],
                'user_stories': []
            }


    async def _generate_architecture(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Generate comprehensive Architecture and Detailed Design Specification based on epics and user stories
        
        Analyzes epics, user stories, and requirements to extract:
        1. System Architecture Components (with technology logos)
        2. High Level Design
        3. End-to-End Flow Diagram
        4. Low Level & System Design (API, DB, Integration, Infrastructure)
        """
        epics = data.get('epics', [])
        user_stories = data.get('userStories', [])
        execution_order = data.get('executionOrder', [])
        requirements = data.get('requirements', [])
        functional_reqs = data.get('functionalRequirements', [])
        non_functional_reqs = data.get('nonFunctionalRequirements', [])
        business_proposal = data.get('businessProposal', {})
        
        print(f"\n{'='*80}")
        print(f"[ðŸ”´ ARCHITECTURE GENERATION START]")
        print(f"{'='*80}")
        print(f"[INFO] Generating Architecture and Detailed Design Specification")
        print(f"[DEBUG] Epics: {len(epics)}, User Stories: {len(user_stories)}, Execution Order: {len(execution_order)}")
        
        # ðŸ”´ DETAILED INPUT VALIDATION
        if epics:
            print(f"[DEBUG] Epic details:")
            for epic in epics[:3]:
                print(f"        - Epic {epic.get('id')}: {epic.get('title')} ({epic.get('stories', 0)} stories, {epic.get('points', 0)} pts)")
        
        if user_stories:
            print(f"[DEBUG] User story samples:")
            for story in user_stories[:3]:
                print(f"        - {story.get('title')} (Epic: {story.get('epic', 'N/A')}, Points: {story.get('points', 0)})")
        
        if execution_order:
            print(f"[DEBUG] Execution Order: {execution_order}")
        
        # CRITICAL: Don't fallback to dummy data - raise error if Phase 2 data missing
        if not epics and not user_stories:
            print("[ERROR] âŒ No epics or user stories found - Phase 2 data not provided to Phase 3!")
            print("[ERROR] Architecture generation requires Phase 2 data (epics, user stories, execution order)")
            print("[ERROR] Check Phase 3Page.tsx handleGenerateArchitecture to ensure Phase 2 data is loaded and passed")
            raise ValueError("Phase 3 Architecture generation requires Phase 2 data (epics and user stories). Please ensure Phase 2 is completed successfully.")
        
        # Prepare context for OpenAI
        epics_context = ""
        epic_count = 0
        for epic in epics:
            epic_count += 1
            epics_context += f"\n**Epic {epic.get('id')}**: {epic.get('title')}\n"
            epics_context += f"  - Description: {epic.get('description')}\n"
            epics_context += f"  - Stories: {epic.get('stories')}, Points: {epic.get('points')}\n"
            epics_context += f"  - Priority: {epic.get('priority')}\n"
        
        stories_context = ""
        story_count = 0
        for story in user_stories[:20]:  # First 20 stories for context
            story_count += 1
            stories_context += f"\n- {story.get('title')}\n"
            stories_context += f"  Epic: {story.get('epic')}, Points: {story.get('points')}\n"
            if story.get('acceptance_criteria'):
                stories_context += f"  Criteria: {len(story.get('acceptance_criteria', []))} items\n"
        
        # Add execution order context
        execution_order_context = ""
        if execution_order:
            execution_order_context += "\n## Implementation Sequence (from Execution Plan):\n"
            for idx, epic_id in enumerate(execution_order, 1):
                # Find matching epic
                matching_epic = next((e for e in epics if e.get('id') == epic_id), None)
                if matching_epic:
                    execution_order_context += f"{idx}. **{matching_epic.get('title')}** (Epic {epic_id})\n"
                else:
                    execution_order_context += f"{idx}. Epic {epic_id}\n"
        
        # Add requirements context - COMPREHENSIVE with component inference
        requirements_summary = ""
        
        # ðŸ”´ INTELLIGENT COMPONENT TYPE INFERENCE FROM REQUIREMENTS
        component_type_hints = {
            'frontend': [],
            'backend': [],
            'api': [],
            'database': [],
            'cache': [],
            'messaging': [],
            'service': [],
            'integration': [],
            'security': [],
            'monitoring': [],
            'infrastructure': []
        }
        
        # Analyze functional requirements for component implications
        if functional_reqs:
            requirements_summary += f"\n**Functional Requirements**: {len(functional_reqs)} items\n"
            for req in functional_reqs:
                req_text = (req.get('requirement') or '').lower()
                requirements_summary += f"- {req.get('requirement')}\n"
                
                # Infer component types from requirement text
                if any(word in req_text for word in ['display', 'show', 'view', 'ui', 'dashboard', 'interface', 'portal', 'app', 'web', 'mobile']):
                    component_type_hints['frontend'].append(req.get('requirement'))
                if any(word in req_text for word in ['process', 'calculate', 'manage', 'handle', 'execute', 'perform', 'business logic', 'service', 'endpoint']):
                    component_type_hints['backend'].append(req.get('requirement'))
                if any(word in req_text for word in ['api', 'rest', 'graphql', 'endpoint', 'request', 'response', 'http']):
                    component_type_hints['api'].append(req.get('requirement'))
                if any(word in req_text for word in ['store', 'save', 'persist', 'database', 'data', 'record', 'history', 'transaction']):
                    component_type_hints['database'].append(req.get('requirement'))
                if any(word in req_text for word in ['fast', 'performance', 'speed', 'cache', 'quick', 'latency', 'response time']):
                    component_type_hints['cache'].append(req.get('requirement'))
                if any(word in req_text for word in ['notify', 'alert', 'email', 'sms', 'message', 'background', 'async', 'queue', 'event']):
                    component_type_hints['messaging'].append(req.get('requirement'))
                if any(word in req_text for word in ['payment', 'external', 'third-party', 'integration', 'gateway', 'api call']):
                    component_type_hints['integration'].append(req.get('requirement'))
                if any(word in req_text for word in ['auth', 'login', 'secure', 'encryption', 'password', 'permission', 'access control', 'security']):
                    component_type_hints['security'].append(req.get('requirement'))
                if any(word in req_text for word in ['monitor', 'log', 'track', 'health', 'performance', 'metrics', 'alert', 'observability']):
                    component_type_hints['monitoring'].append(req.get('requirement'))
        
        # Analyze non-functional requirements for component implications
        if non_functional_reqs:
            requirements_summary += f"\n**Non-Functional Requirements**: {len(non_functional_reqs)} items\n"
            for req in non_functional_reqs:
                req_text = (req.get('requirement') or '').lower()
                category = (req.get('category') or '').lower()
                requirements_summary += f"- {req.get('category')}: {req.get('requirement')}\n"
                
                # NFR categories directly imply components
                if category in ['performance', 'scalability', 'concurrency']:
                    component_type_hints['cache'].append(f"{category}: {req.get('requirement')}")
                    component_type_hints['infrastructure'].append(f"{category}: {req.get('requirement')}")
                if category in ['security', 'authentication', 'authorization']:
                    component_type_hints['security'].append(f"{category}: {req.get('requirement')}")
                if category in ['monitoring', 'logging', 'observability']:
                    component_type_hints['monitoring'].append(f"{category}: {req.get('requirement')}")
                if category in ['availability', 'reliability', 'disaster recovery']:
                    component_type_hints['infrastructure'].append(f"{category}: {req.get('requirement')}")
                if category in ['integration', 'interoperability']:
                    component_type_hints['integration'].append(f"{category}: {req.get('requirement')}")
                if category in ['data persistence', 'data consistency']:
                    component_type_hints['database'].append(f"{category}: {req.get('requirement')}")
        
        # Add component type hints summary to context
        hints_summary = "\n## INFERRED COMPONENT TYPES (from Phase 1 Requirements Analysis):\n"
        for comp_type, hints in component_type_hints.items():
            if hints:
                hints_summary += f"\n**{comp_type.upper()}** (Found {len(hints)} supporting requirements):\n"
                for hint in hints[:3]:  # Show first 3
                    hints_summary += f"  â€¢ {hint}\n"
        
        requirements_summary += hints_summary
        

        # Build comprehensive prompt for AI
        prompt = f"""You are an expert Solution Architect and System Designer. Analyze the following epics, user stories, and requirements to generate a comprehensive Architecture and Detailed Design Specification document.

ðŸš¨ðŸš¨ðŸš¨ CRITICAL - COMPREHENSIVE ARCHITECTURE, NO OVER-SIMPLIFICATION ðŸš¨ðŸš¨ðŸš¨

RULE 1: **INCLUDE ALL REASONABLY REQUIRED COMPONENTS**
- Include components that are EXPLICITLY mentioned in epics/stories
- Include components that are REASONABLY INFERRED from requirements (see hints below)
- If monitoring/tracking is mentioned â†’ include MONITORING component
- If data persistence is mentioned â†’ include DATABASE component
- If users interact with system â†’ include FRONTEND component
- If business logic needed â†’ include BACKEND component
- If APIs needed â†’ include API component
- See INFERRED COMPONENT TYPES section below for automated analysis of what's needed

RULE 2: **EVERY component MUST have clear justification**
- Format: "Component name - Type: XXX - needed for [specific purpose from requirements]"
- Reference specific epics/stories when possible
- But if reasonable inference from requirements, include it anyway

RULE 3: **USE FUNCTIONAL COMPONENT NAMES**
- âœ… GOOD: Component names describe FUNCTION, not technology
- âœ… GOOD: "Vehicle Tracking Dashboard" (if UI requirements exist)
- âœ… GOOD: "Location Processing Service" (if processing mentioned)
- âœ… GOOD: "Transaction Record Store" (if data persistence needed)
- âœ… GOOD: "Alert Notification System" (if monitoring mentioned)

RULE 4: **COMPONENT TYPES TO CONSIDER**
Based on the inferred component types from Phase 1 requirements analysis:
{hints_summary}

For each type with supporting requirements above, GENERATE appropriate components.
You SHOULD include components for each type that has supporting requirements.

RULE 5: **COMPLETE COVERAGE**
Generate components across these categories if requirements suggest them:
- FRONTEND: User-facing applications, dashboards, portals
- BACKEND: Business logic services, application servers
- API: REST APIs, GraphQL, API gateways
- DATABASE: Data storage, persistence layers
- CACHE: Performance optimization, caching layers
- MESSAGING: Event systems, notifications, async processing
- SERVICE: Microservices, specialized services, workers
- INTEGRATION: Third-party integrations, external systems
- SECURITY: Authentication, authorization, security layers
- MONITORING: Logging, monitoring, observability
- INFRASTRUCTURE: Deployment, scaling, infrastructure

## ANALYSIS INPUT:

## PROJECT SUMMARY:
- Total Epics: {epic_count}
- Total User Stories: {story_count}

## Epics from Phase 2:
{epics_context}

## User Stories Sample:
{stories_context}

{execution_order_context}

{requirements_summary}

## Required Output Sections:

### 1. System Architecture Components
**COMPREHENSIVE COMPONENT ANALYSIS**:

**ðŸš¨ CRITICAL TECHNOLOGY VALIDATION RULES ðŸš¨**:
ONLY include technologies that are EXPLICITLY mentioned in the requirements, epics, or user stories provided above.
NO assumptions, NO defaults, NO substitutions.

For EACH technology you list for a component:
1. Search the requirements above for that exact technology name
2. If NOT found â†’ DO NOT include it
3. Component descriptions should explain WHAT the component does, not WHAT technology it uses
4. Technology list should match what's in the provided data - nothing more, nothing less

**GENERATION PROCESS**:
1. Review all epics and user stories above
2. Review ALL inferred component types with their supporting requirements
3. For EACH component type that has supporting requirements â†’ generate 1-2 appropriate components
4. Generate components for FRONTEND, BACKEND, API, DATABASE, CACHE, MESSAGING, SERVICE, INTEGRATION, SECURITY, MONITORING, INFRASTRUCTURE as needed
5. Each component should have clear purpose tied to requirements
6. For EACH component, check what specific technologies were mentioned in requirements
7. ONLY list those specific technologies - use generic names otherwise
8. Ensure you have multiple component types represented (Frontend, Backend, Services, Integrations, Deployments, Reports, Dashboard, Monitoring)

**OUTCOME**: System should have 8-15 components across different types, not just API + Database

**TECHNOLOGY EXTRACTION FROM DATA ONLY**: 
Extract technologies ONLY from what is explicitly mentioned in the requirements above.
Do NOT use placeholders, do NOT suggest alternatives, do NOT use generic names.
If a technology is not mentioned in the provided data, do not include it.

**CATEGORIZATION** (Generate for each as needed):

**FRONTEND Components** (type: "frontend"):
- User-facing web applications
- Mobile applications
- Admin dashboards
- Customer portals
Examples: React Web App, Angular Admin Panel, Mobile App (React Native), Progressive Web App

**BACKEND Components** (type: "backend"):
- Application servers
- Business logic services
- Microservices
Examples: Application Server, Business Logic Service, Processing Engine

**API Components** (type: "api"):
- REST API endpoints
- GraphQL servers
- WebSocket servers
- API Gateways
Examples: API Gateway, REST Interface, Request Handler

**DATABASE Components** (type: "database"):
- Relational databases
- NoSQL databases
- Data warehouses
- Vector databases (if AI/ML features exist)
Examples: Data Store, Record Database, Transaction Store

**CACHE Components** (type: "cache"):
- In-memory caching
- Distributed caching
Examples: Cache Layer, Performance Optimizer

**QUEUE Components** (type: "queue"):
- Message queues
- Event buses
- Streaming platforms
Examples: Message System, Event Handler, Async Processor

**SERVICE Components** (type: "service"):
- Microservices
- Background workers
- Scheduled jobs
Examples: Background Service, Notification Handler, Processing Worker

**INTEGRATION Components** (type: "integration"):
- Third-party API integrations
- External service connectors
Examples: External Service Connector, Third-Party Integration Handler

**SECURITY Components** (type: "security"):
- Authentication services
- Authorization services
- Security gateways
Examples: Authentication Handler, Access Control Service

**MONITORING Components** (type: "monitoring"):
- Logging systems
- Monitoring tools
- Analytics platforms
Examples: System Monitor, Performance Tracker, Alert Handler

**INFRASTRUCTURE Components** (type: "infrastructure"):
- Containers and orchestration
- CI/CD pipelines
- Load balancers
Examples: Docker, Kubernetes, AWS ECS, GitHub Actions, Load Balancer, CDN

For EACH component provide:
- Component name (specific and descriptive)
- Type (MUST be one of: frontend, backend, api, database, cache, queue, service, integration, security, monitoring, infrastructure)
- Description (explain WHY this component is needed based on requirements)
- Technology stack (specific versions based on requirements)
- Tech logos (use lowercase: react, nodejs, postgresql, redis, mongodb, aws, docker, kubernetes, python, java, etc.)

### 2. High Level Design (HLD)
**CRITICAL: MUST BE REQUIREMENT-SPECIFIC** - DO NOT use generic terms. Base EVERY statement on the actual epics and user stories:

**Architecture Style:**
- DON'T say: "Microservices for scalability"
- DO say: "Microservices architecture chosen because Epic X requires independent scaling of the Product Catalog and Order Processing services, with Epic Y needing separate deployment cycles for the Payment module"

**Overview:**
- DON'T say: "The system is designed as a collection of microservices"
- DO say: "Based on the 5 core epics (E1: User Management, E2: Product Catalog, E3: Order Processing, E4: Payment Integration, E5: Notifications), the system implements a domain-driven microservices architecture where each epic maps to an independent service"

**Key Decisions:**
- EACH decision MUST reference a specific epic/story/requirement
- Format: "Decision - Because [Epic/Story ID]: [Specific requirement]"
- Example: "Use of caching - Because User Story US-42 requires product search response time under 200ms, and Epic E2 mentions handling 10,000+ products"

**Component Interactions:**
- DON'T say: "Frontend communicates with backend API"
- DO say: "When User performs [action from Story US-X], the [specific frontend component] calls [specific API endpoint from Epic E-Y] which [specific data flow from requirements]"

**Scalability Strategy:**
- Reference SPECIFIC non-functional requirements or epic details
- Example: "Horizontal scaling for Order Service because Epic E3 mentions Black Friday peak loads of 50K orders/hour"

**Security Overview:**
- Reference SPECIFIC security requirements, stakeholder concerns, or compliance needs
- Example: "JWT authentication chosen because User Story US-10 requires secure API access and Epic E4 mentions PCI-DSS compliance for payment data"

### 3. End-to-End Flow Diagram
**MUST REFLECT ACTUAL USER STORIES - COMPREHENSIVE FLOW WITH EXECUTION SEQUENCE ANALYSIS**

**CRITICAL REQUIREMENTS**:
1. Create MULTIPLE flow diagrams covering different user story flows (pick 2-4 representative stories)
2. Show COMPLETE data flow from user action to final result with ALL component interactions
3. Include ALL components from your system_components list that are involved in each flow
4. Reference SPECIFIC user stories by title and acceptance criteria
5. Reference SPECIFIC epics in the execution sequence
6. Show integration points between all component types
7. Show data persistence (database), caching checks, async operations, security gates
8. Make flows executable - not generic abstract diagrams
9. ANALYZE execution order - flows should show how components are deployed/interact sequentially

**EXECUTION SEQUENCE ANALYSIS**:
{execution_order_context}

**ANALYSIS REQUIREMENTS FOR EACH FLOW**:
1. IDENTIFY EPIC: Which epic does this user story belong to? (from execution order above)
2. ANALYZE DEPENDENCIES: What other epics/components must be ready first?
3. MAP ACCEPTANCE CRITERIA: How does each acceptance criterion map to a component/step?
4. TRACE FULL JOURNEY: Start â†’ API calls â†’ Services â†’ DB â†’ Cache â†’ Async ops â†’ Response
5. IDENTIFY BOTTLENECKS: Which steps are sequential vs parallel?
6. OPTIMIZE FLOW: Which steps can be async/cached to improve performance?

**FLOW CONSTRUCTION ALGORITHM**:
For EACH selected user story:
  Step 1: Parse the user story title and acceptance criteria
  Step 2: Identify the PRIMARY ACTION (e.g., search, create, update, delete, export)
  Step 3: Map SECURITY GATES needed (from functional/non-functional requirements)
  Step 4: Identify BACKEND SERVICES required (based on component types and story description)
  Step 5: Identify DATABASE OPERATIONS needed (what data needs to be persisted/queried)
  Step 6: Identify CACHE STRATEGY (can results be cached? TTL? Invalidation triggers?)
  Step 7: Identify ASYNC OPERATIONS (notifications, exports, batch processing, webhooks?)
  Step 8: Identify EXTERNAL INTEGRATIONS (third-party APIs, payment gateways, etc.)
  Step 9: Identify MONITORING POINTS (what metrics/logs are critical for this flow?)
  Step 10: Map COMPONENT INTERACTIONS in exact sequence based on execution order
  
**STORY SELECTION STRATEGY**:
- Pick 1-2 stories from EARLY epics (showing foundation/infrastructure)
- Pick 1-2 stories from MIDDLE epics (showing business logic)
- Pick 1 story from CRITICAL PATH (highest priority/most complex)
- Ensure coverage of: basic CRUD, complex processing, async operations, external integrations

**USER STORY STRUCTURE ANALYSIS**:
Each user story typically follows: "As a [user type], I want to [action], so that [benefit]"

PARSING RULES FOR FLOW CONSTRUCTION:
1. IDENTIFY ACTOR: Who performs the action? (user type determines frontend vs backend flow)
2. IDENTIFY PRIMARY ACTION: What's the main verb? (GET data, CREATE resource, UPDATE state, DELETE, PROCESS, NOTIFY, EXPORT)
3. EXTRACT ACCEPTANCE CRITERIA:
   - Performance criteria (response time, throughput, latency)
   - Functional criteria (what data is needed, what transformations)
   - Integration criteria (which systems must be involved)
   - Security criteria (what auth/validation is needed)
4. MAP EPIC CONTEXT: Which epic owns this story? (determines which services are available)
5. IDENTIFY DATA FLOWS:
   - Input data: What data does user provide? (form input, API payload)
   - Processing: What happens to the data? (validation, transformation, calculation)
   - Output data: What's returned to user? (JSON, PDF, notification, UI update)
6. IDENTIFY DEPENDENCIES:
   - Temporal: Must other stories/features exist first?
   - Data: Does this story depend on data from other features?
   - Service: Does this story require services from other epics?
7. IDENTIFY PERFORMANCE CONSTRAINTS:
   - Is response time critical? (use cache, async patterns)
   - Is volume high? (pagination, batching, background jobs)
   - Is consistency critical? (transactions, queues, retries)

**USER STORY TO FLOW MAPPING EXAMPLES**:

Story: "As a Fleet Manager, I want to view live vehicle locations on a map, so that I can monitor fleet in real-time"
Parse:
  - Actor: Fleet Manager (needs dashboard/UI)
  - Action: VIEW (read-only, GET request)
  - Criteria: Real-time (use WebSocket/polling), Show all 500 vehicles (need caching/pagination)
  - Epic: E1-Real-Time Tracking (Phase 1)
  - Data: Input = none, Process = fetch location data + map transformation, Output = GeoJSON array
  - Dependencies: Vehicle location data must be ingested (E1 foundation)
  - Performance: <5sec initial load, <500ms updates
Result Flow: Dashboard â†’ Auth â†’ API GET /vehicles/locations â†’ LocationService â†’ Cache Check â†’ DB Query â†’ Response â†’ Map Render

Story: "As a System Admin, I want to receive alerts when vehicle speed exceeds limit, so that I can take action"
Parse:
  - Actor: System Admin (might need SMS/Email notifications)
  - Action: RECEIVE (async notification, not request-driven)
  - Criteria: <2sec alert time, multiple channels (email/SMS/in-app)
  - Epic: E2-Alerts & Notifications (Phase 2)
  - Data: Input = continuous stream of speed data, Process = threshold check + notification logic, Output = alerts to multiple channels
  - Dependencies: Real-time location data (E1), notification infrastructure (E2)
  - Performance: Minimal latency, high volume handling
Result Flow: Speed Monitor â†’ Threshold Check â†’ Queue (async) â†’ Alert Processor â†’ Multiple Services (Email/SMS/WebSocket) â†’ User Notification

**COMPONENT INTERACTION PATTERNS**:
Different story types follow different patterns:

PATTERN 1 - SYNCHRONOUS REQUEST-RESPONSE (for immediate user actions):
  User Action â†’ Frontend â†’ Auth â†’ API â†’ Service â†’ DB Query â†’ Cache Store â†’ Response â†’ Frontend Display

PATTERN 2 - ASYNCHRONOUS WITH NOTIFICATIONS (for background processing):
  Trigger Event â†’ Queue/Event Bus â†’ Background Worker â†’ Process â†’ Multiple Destinations (DB/Email/Webhooks) â†’ Logging

PATTERN 3 - REAL-TIME STREAMING (for live updates):
  Data Source â†’ Stream Processor â†’ Cache â†’ WebSocket Broadcaster â†’ Connected Clients Real-time Updates

PATTERN 4 - BATCH PROCESSING (for reports/exports):
  Request â†’ Validation â†’ Queue â†’ Worker Pool â†’ Data Aggregation â†’ Storage (S3/File) â†’ Notification â†’ Download Link

PATTERN 5 - INTEGRATION WITH EXTERNAL SYSTEMS (for third-party APIs):
  Internal Request â†’ Service â†’ External API Call â†’ Response Processing â†’ Transform & Store â†’ Response to User

**FLOW COMPONENTS TO INCLUDE** (if applicable based on the specific user story):
- User/Client interaction with specific UI action
- Frontend/UI components (if story involves UI)
- Authentication/Security gates (always - unless public endpoint)
- API endpoints (REST paths derived from story actions)
- Backend services (based on component types and epic)
- Database queries (SELECT/INSERT/UPDATE as needed by story)
- Cache operations (check cache, store in cache, invalidate cache)
- Message queues (async operations like notifications, reports, webhooks)
- External integrations (third-party services referenced in story/requirements)
- Monitoring/Logging (record events, track performance)
- Response back to user (in format expected by frontend)

**GOOD FLOW EXAMPLES WITH EXECUTION ANALYSIS**:

Follow the patterns below when creating flows.

**COMPONENT INTERACTION PATTERNS**:
Different story types follow different patterns:

PATTERN 1 - SYNCHRONOUS REQUEST-RESPONSE (for immediate user actions):
  User Action â†’ Frontend â†’ Auth â†’ API â†’ Service â†’ DB Query â†’ Cache Store â†’ Response â†’ Frontend Display

PATTERN 2 - ASYNCHRONOUS WITH NOTIFICATIONS (for background processing):
  Trigger Event â†’ Queue/Event Bus â†’ Background Worker â†’ Process â†’ Multiple Destinations (DB/Email/Webhooks) â†’ Logging

PATTERN 3 - REAL-TIME STREAMING (for live updates):
  Data Source â†’ Stream Processor â†’ Cache â†’ WebSocket Broadcaster â†’ Connected Clients Real-time Updates

PATTERN 4 - BATCH PROCESSING (for reports/exports):
  Request â†’ Validation â†’ Queue â†’ Worker Pool â†’ Data Aggregation â†’ Storage (S3/File) â†’ Notification â†’ Download Link

PATTERN 5 - INTEGRATION WITH EXTERNAL SYSTEMS (for third-party APIs):
  Internal Request â†’ Service â†’ External API Call â†’ Response Processing â†’ Transform & Store â†’ Response to User

### 4. Low Level Design (LLD) & System Design

#### 4.1 API Design
**DERIVE ENDPOINTS FROM USER STORIES**:
- Identify required API endpoints based on user actions in stories
- For each endpoint specify: method, path, description, request/response schema
- Authentication mechanism (based on security requirements)
- Error handling strategy
- API versioning approach
- Rate limiting (if mentioned in requirements)

Example: If user story says "User can search products", include:
- GET /api/v1/products/search
- POST /api/v1/orders
- GET /api/v1/user/profile

#### 4.2 Database Design
**DERIVE SCHEMA FROM DATA ENTITIES IN REQUIREMENTS - BE SPECIFIC**:
- DON'T say: "users table with id, name, email"
- DO say: "users table (from Epic E1: User Management) with fields: id, email, password_hash, role (admin/customer from Story US-5), created_at, last_login (tracking requirement from Story US-12)"

For EACH table, specify:
- Which epic/story requires this table
- Fields needed for those specific stories
- Relationships based on user story requirements
- Indexes justified by query patterns in stories

Example: "orders table (Epic E3: Order Processing) includes user_id (FK to users), product_items (JSONB array from Story US-78), payment_status (Story US-82), shipping_address (Story US-79)"

#### 4.3 Integration Design
**IDENTIFY INTEGRATIONS FROM REQUIREMENTS - REFERENCE SPECIFIC NEEDS**:
- DON'T say: "Payment gateway for processing payments"
- DO say: "Stripe payment gateway (Epic E4: Payment Integration) specifically for User Story US-95 (credit card processing) and US-96 (subscription billing), requires PCI-DSS compliance mentioned in security requirements"

For EACH integration:
- Which epic/story requires it
- Specific functionality needed
- Authentication method and WHY (based on security requirements)

#### 4.4 Infrastructure Design
**BASE ON SCALABILITY AND DEPLOYMENT REQUIREMENTS - JUSTIFY CHOICES**:
- DON'T say: "Kubernetes for container orchestration"
- DO say: "Kubernetes chosen because Epic E3 mentions 50K orders/hour peak load requiring auto-scaling, and DevOps requirement DEV-3 specifies zero-downtime deployments"

Justify EACH infrastructure choice with requirements
- Backup and disaster recovery (if data persistence requirements exist)

**CRITICAL GUIDELINES**:
1. **NO DUMMY DATA** - Every component MUST be justified by requirements
2. **EXTRACT FROM EPICS/STORIES** - If payment is mentioned, include payment components; if AI is mentioned, include vector DB
3. **BE SPECIFIC** - Use actual technology names and versions relevant to the requirements
4. **CATEGORIZE CORRECTLY** - Use proper type categories (frontend, backend, api, database, cache, queue, service, integration, security, monitoring, infrastructure)
5. **COMPREHENSIVE BUT RELEVANT** - Include all necessary components but don't add unnecessary ones
6. **JUSTIFY EACH COMPONENT** - Description should explain WHY it's needed based on requirements

ðŸš¨ COMPONENT GENERATION RULES ðŸš¨
INSTEAD OF: "Only include components explicitly mentioned"
NOW DO: "Include ALL components that are reasonably required by the epics/stories/requirements"

- If monitoring is mentioned â†’ MUST have MONITORING component
- If data persistence is needed â†’ MUST have DATABASE component  
- If users interact â†’ MUST have FRONTEND component
- If business logic â†’ MUST have BACKEND component
- If APIs needed â†’ MUST have API component
- If performance matters â†’ MUST have CACHE component
- If async operations â†’ MUST have MESSAGING component
- If third-party needed â†’ MUST have INTEGRATION component
- If security matters â†’ MUST have SECURITY component
- If scale mentioned â†’ MUST have INFRASTRUCTURE component
- If services needed â†’ MUST have SERVICE component

Review the INFERRED COMPONENT TYPES section above - for EACH type with supporting requirements, generate appropriate components.
Your system should have 8-15 components across 8+ different types, not just API + Database.

ðŸš¨ FINAL REMINDER ðŸš¨
In the "high_level_design" section:
- "architecture_style" should explain the overall design
- "overview" should list the component types and count
- "key_decisions" should explain major choices
- "component_interactions" should describe the data flows
- "scalability_strategy" should address performance needs
- "security_overview" should address security concerns

Aim for COMPREHENSIVE architecture with multiple component types represented.

ðŸš¨ðŸš¨ðŸš¨ **CRITICAL ENFORCEMENT: E2E FLOW DIAGRAMS MANDATE** ðŸš¨ðŸš¨ðŸš¨

The "e2e_flow_diagrams" field is MANDATORY and must ALWAYS be populated:

**ENFORCEMENT RULES**:
1. âœ… MUST generate AT LEAST 2 E2E flow diagrams covering different patterns
2. âœ… MUST reference SPECIFIC user stories from the provided data (not generic placeholders)
3. âœ… MUST follow one of the 5 component interaction patterns (PATTERN 1-5) for EACH flow
4. âœ… MUST use mermaid diagram syntax for visualization
5. âœ… MUST include execution sequence based on the provided execution_order
6. âœ… MUST show end-to-end journey from user action to response
7. âœ… MUST validate flows are COMPLETE - not partial or abstract

**FLOW SELECTION ALGORITHM** (MANDATORY):
1. First Flow: Select the PRIMARY BUSINESS STORY (highest priority) from the user_stories list
   - Should demonstrate the core business capability from the first epic
   - Use PATTERN 1 (Request-Response) for synchronous flows or PATTERN 2 if async
2. Second Flow: Select a SECONDARY story that shows a different pattern
   - Should demonstrate different component types or interaction pattern
   - Could be async notification, real-time streaming, batch, or integration
3. If >5 epics: Add third flow showing ADVANCED/INTEGRATION scenario
4. If >10 epics: Add fourth flow showing COMPLEX/BATCH PROCESSING

**E2E FLOW GENERATION CHECKLIST** (MUST COMPLETE BEFORE RETURNING):
â˜‘ Selected appropriate user stories (at least 2, matching execution order)
â˜‘ Identified epic for each story
â˜‘ Extracted acceptance criteria â†’ component interactions
â˜‘ Mapped to system components from component list
â˜‘ Sequenced by execution_order dependencies
â˜‘ Created mermaid diagrams with proper syntax
â˜‘ Included ALL component types involved in each flow
â˜‘ Added titles, descriptions, and references
â˜‘ Validated flows are complete and not generic

**IF YOU SKIP E2E FLOWS, YOUR RESPONSE IS INCOMPLETE AND FAILS VALIDATION**

**Output Format** (JSON):
GENERATE COMPREHENSIVE SET OF COMPONENTS covering all needed types.

Return a JSON object with:
- system_components array: List each component with id, name, type, epic, user_stories, description, technologies, tech_logos, user_story_requirements, functions
- component_summary: Total count and breakdown by type
- high_level_design: Architecture style, overview, key decisions, interactions, scalability, security
- e2e_flow_diagrams: **âœ… ALWAYS POPULATED - Array of AT LEAST 2 flow diagrams with title, user_story, epic, description, mermaid diagram**
- api_design: Endpoints with method, path, description, user_stories, authentication
- database_design: Tables with name, description, key_fields, user_stories
- integration_design: Third-party services with name, purpose, user_stories
- infrastructure_design: Deployment model and monitoring approach

ðŸš¨ COMPONENT GENERATION VALIDATION:
1. system_components array MUST ONLY contain components from the epics/stories/requirements provided
2. Each component description MUST cite which epic/story requires it
3. High level design MUST reference actual epic numbers and story counts
4. Key decisions MUST be tied to specific requirements
5. **e2e_flow_diagrams MUST contain AT LEAST 2 complete flows with proper mermaid diagrams** â† CRITICAL
6. If PostgreSQL is not mentioned anywhere, DO NOT include it
7. If Redis is not mentioned anywhere, DO NOT include it
8. If RabbitMQ is not mentioned anywhere, DO NOT include it
9. ONLY generate what is explicitly needed by the provided data
"""
        
        # Call OpenAI API with strict architecture generation rules
        try:
            response = await self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You are an expert Solution Architect. Generate ONLY valid JSON architecture specifications based on provided epics and user stories. ONLY include components explicitly mentioned or clearly required by the provided data."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=8000,
                response_format={"type": "json_object"}
            )
            
            response_text = response.choices[0].message.content.strip()
            print(f"[OK] Generated architecture with response length: {len(response_text)} chars")
            
        except Exception as e:
            print(f"[ERROR] OpenAI API call failed: {str(e)}")
            raise ValueError(f"Failed to call OpenAI API for architecture generation: {str(e)}")
        
        # Extract response
        try:
            # Look for JSON in response
            if "```json" in response_text:
                json_match = response_text.split("```json")[1].split("```")[0]
                arch_data = json.loads(json_match)
            elif "{" in response_text:
                # Find the first { and last }
                start_idx = response_text.find("{")
                end_idx = response_text.rfind("}") + 1
                json_str = response_text[start_idx:end_idx]
                arch_data = json.loads(json_str)
            else:
                print("[ERROR] No JSON found in architecture response")
                raise ValueError("Architecture generation failed: No JSON found in OpenAI response. This usually means the prompt failed to produce valid output.")
        except json.JSONDecodeError as e:
            print(f"[ERROR] Failed to parse architecture JSON: {e}")
            # NO FALLBACK - Raise error to user instead of silently returning empty dict
            raise ValueError(f"Architecture generation failed: Invalid JSON response from AI: {str(e)}")
        
        # ðŸ”´ DEBUG: Log what keys were returned
        print(f"[DEBUG] AI Response keys: {list(arch_data.keys())}")
        print(f"[DEBUG] Has e2e_flow_diagrams? {('e2e_flow_diagrams' in arch_data)}")
        if 'e2e_flow_diagrams' in arch_data:
            e2e_val = arch_data['e2e_flow_diagrams']
            print(f"[DEBUG] e2e_flow_diagrams type: {type(e2e_val)}, length: {len(e2e_val) if isinstance(e2e_val, list) else 'N/A'}")
        else:
            print(f"[ERROR] âŒ AI Response is MISSING e2e_flow_diagrams key!")
            print(f"[ERROR] Available keys: {list(arch_data.keys())}")
        
        # ðŸ”´ FORMAT CONVERSION: Convert backend format to match frontend expectations
        print("[INFO] Converting backend response format to frontend format...")
        
        # ðŸ”´ VALIDATION: Ensure components are data-driven, not fallback/default
        print("[INFO] Validating components are not fallback/default values...")
        
        # Extract all technologies mentioned in epics, stories, and requirements
        mentioned_tech = set()
        
        for epic in epics:
            epic_text = (f"{epic.get('title', '')} {epic.get('description', '')}").lower()
            mentioned_tech.update(self._extract_technologies_from_text(epic_text))
        
        for story in user_stories:
            story_text = (f"{story.get('title', '')} {story.get('description', '')}").lower()
            mentioned_tech.update(self._extract_technologies_from_text(story_text))
        
        for req in functional_reqs:
            req_text = (req.get('requirement', '')).lower()
            mentioned_tech.update(self._extract_technologies_from_text(req_text))
        
        for req in non_functional_reqs:
            req_text = (f"{req.get('category', '')} {req.get('requirement', '')}").lower()
            mentioned_tech.update(self._extract_technologies_from_text(req_text))
        
        # ðŸ”´ VALIDATE: Remove any technologies from components that were NOT mentioned in requirements
        # This ensures NO FALLBACK/DEFAULT technologies appear (pure data-driven extraction only)
        if 'system_components' in arch_data:
            for component in arch_data['system_components']:
                tech_list = component.get('technologies', [])
                tech_logos = component.get('tech_logos', [])
                
                # Convert component tech to lowercase for comparison
                tech_lower = [t.lower() for t in tech_list]
                logos_lower = [t.lower() for t in tech_logos]
                
                # Filter out any technology NOT in mentioned_tech
                # Only keep technologies that were explicitly mentioned in requirements/epics/stories
                filtered_tech_list = []
                for tech in tech_list:
                    tech_lower_val = tech.lower()
                    # Check if this exact technology or a variant was mentioned
                    found_in_mentioned = False
                    for mentioned in mentioned_tech:
                        if mentioned in tech_lower_val or tech_lower_val in mentioned:
                            found_in_mentioned = True
                            break
                    
                    if found_in_mentioned:
                        filtered_tech_list.append(tech)
                    else:
                        print(f"[INFO] Removing '{tech}' from component '{component.get('name')}' - NOT mentioned in requirements")
                
                # Apply filtered list
                component['technologies'] = filtered_tech_list
                
                # Similarly filter tech_logos
                filtered_logos = []
                for logo in tech_logos:
                    logo_lower = logo.lower()
                    found_in_mentioned = False
                    for mentioned in mentioned_tech:
                        if mentioned in logo_lower or logo_lower in mentioned:
                            found_in_mentioned = True
                            break
                    
                    if found_in_mentioned:
                        filtered_logos.append(logo)
                    else:
                        print(f"[INFO] Removing logo '{logo}' from component '{component.get('name')}' - NOT mentioned in requirements")
                
                component['tech_logos'] = filtered_logos
        
        print(f"[OK] Validated components - only technologies explicitly mentioned: {mentioned_tech}")
        
        # Extract e2e_flow_diagrams array and convert to single string for frontend
        if 'e2e_flow_diagrams' in arch_data and isinstance(arch_data['e2e_flow_diagrams'], list):
            diagrams = arch_data['e2e_flow_diagrams']
            if diagrams:
                # Combine all mermaid diagrams with titles
                combined_diagrams = "\n\n---\n\n".join([
                    f"## {d.get('title', 'Flow Diagram')}\n**User Story**: {d.get('user_story', 'N/A')}\n**Epic**: {d.get('epic', 'N/A')}\n\n```mermaid\n{d.get('mermaid', '')}\n```"
                    for d in diagrams
                ])
                arch_data['e2e_flow_diagram'] = combined_diagrams
                print(f"[OK] Converted {len(diagrams)} mermaid diagrams to single e2e_flow_diagram field")
            else:
                print(f"[WARNING] âš ï¸ No e2e_flow_diagrams found in response - AI generation may have been incomplete")
                # ðŸ”´ GENERATE FALLBACK FLOWS if array is empty
                print(f"[INFO] Generating fallback E2E flows since array was empty...")
                fallback_diagrams = self._generate_fallback_e2e_flows(epics, user_stories, execution_order)
                if fallback_diagrams:
                    arch_data['e2e_flow_diagrams'] = fallback_diagrams
                    combined_diagrams = "\n\n---\n\n".join([
                        f"## {d.get('title', 'Flow Diagram')}\n**User Story**: {d.get('user_story', 'N/A')}\n**Epic**: {d.get('epic', 'N/A')}\n\n```mermaid\n{d.get('mermaid', '')}\n```"
                        for d in fallback_diagrams
                    ])
                    arch_data['e2e_flow_diagram'] = combined_diagrams
                    print(f"[OK] Generated {len(fallback_diagrams)} fallback E2E diagrams")
                else:
                    print(f"[ERROR] Fallback generation returned empty list!")
                    arch_data['e2e_flow_diagram'] = ""
            # Keep the array too for backward compatibility
        else:
            print(f"[WARNING] âš ï¸ e2e_flow_diagrams field missing from response")
            # ðŸ”´ GENERATE FALLBACK FLOWS if field is completely missing
            print(f"[INFO] Generating fallback E2E flows since field was missing...")
            fallback_diagrams = self._generate_fallback_e2e_flows(epics, user_stories, execution_order)
            if fallback_diagrams:
                arch_data['e2e_flow_diagrams'] = fallback_diagrams
                combined_diagrams = "\n\n---\n\n".join([
                    f"## {d.get('title', 'Flow Diagram')}\n**User Story**: {d.get('user_story', 'N/A')}\n**Epic**: {d.get('epic', 'N/A')}\n\n```mermaid\n{d.get('mermaid', '')}\n```"
                    for d in fallback_diagrams
                ])
                arch_data['e2e_flow_diagram'] = combined_diagrams
                print(f"[OK] Generated {len(fallback_diagrams)} fallback E2E diagrams")
            else:
                print(f"[ERROR] Fallback generation returned empty list!")
                arch_data['e2e_flow_diagram'] = ""
        
        # ðŸ”´ CRITICAL VALIDATION: Ensure e2e_flow_diagrams are ALWAYS present for first generation
        # If missing, log error for debugging
        if not arch_data.get('e2e_flow_diagram') or arch_data.get('e2e_flow_diagram', '').strip() == '':
            print(f"[ERROR] âŒ CRITICAL: e2e_flow_diagram is empty/missing after architecture generation!")
            print(f"[ERROR] This indicates AI did not generate flows properly and fallback failed")
            print(f"[ERROR] Epics count: {len(epics)}")
            print(f"[ERROR] User stories count: {len(user_stories)}")
            print(f"[ERROR] Execution order: {execution_order}")
            print(f"[ERROR] AI response had e2e_flow_diagrams: {'e2e_flow_diagrams' in arch_data}")
            
            # ðŸš¨ FINAL FALLBACK: Force generate flows one more time
            print(f"[CRITICAL] ðŸš¨ FORCE GENERATING FALLBACK E2E FLOWS...")
            try:
                fallback_diagrams = self._generate_fallback_e2e_flows(epics, user_stories, execution_order)
                if fallback_diagrams:
                    arch_data['e2e_flow_diagrams'] = fallback_diagrams
                    combined_diagrams = "\n\n---\n\n".join([
                        f"## {d.get('title', 'Flow Diagram')}\n**User Story**: {d.get('user_story', 'N/A')}\n**Epic**: {d.get('epic', 'N/A')}\n\n```mermaid\n{d.get('mermaid', '')}\n```"
                        for d in fallback_diagrams
                    ])
                    arch_data['e2e_flow_diagram'] = combined_diagrams
                    print(f"[CRITICAL] âœ… Force-generated {len(fallback_diagrams)} fallback E2E diagrams")
                else:
                    print(f"[CRITICAL] âŒ Force generation FAILED - no diagrams returned!")
            except Exception as fe:
                print(f"[CRITICAL] âŒ Force generation EXCEPTION: {str(fe)}")
        
        return arch_data
    
    async def extract_structured_requirements(self, parsed_content: Dict[str, Any]) -> Tuple[Dict[str, Any], str]:
        """
        ðŸš¨ DISABLED - NO FALLBACK ALLOWED
        This function intentionally raises an error and should NEVER be called
        If you're seeing this error, it means Phase 2 data was not provided to Phase 3
        """
        raise ValueError(
            "âŒ ERROR: DEFAULT ARCHITECTURE FALLBACK DISABLED\n"
            "Phase 3 requires complete Phase 2 data (epics, user stories, execution order).\n"
            "If this error appears, it means:\n"
            "1. Phase 2 generation was not completed\n"
            "2. Phase 2 data was not loaded from the database\n"
            "3. Frontend did not pass Phase 2 data to Phase 3\n\n"
            "Action: Complete Phase 2 first, ensure epics/stories are saved, then retry Phase 3."
        )
    
    
    async def extract_structured_requirements_real(self, parsed_content: Dict[str, Any]) -> Tuple[Dict[str, Any], str]:
        
        # ðŸ”´ EXTRACT VARIABLES FROM parsed_content DICTIONARY
        text = parsed_content.get('text', '')
        filename = parsed_content.get('filename', 'unknown_document')
        is_manual = parsed_content.get('is_manual', False)
        
        # ===========================================================================
        # SYSTEM PROMPT - MICROSERVICES FIRST WITH EXPLICIT TECHNOLOGY SEPARATION
        # ===========================================================================
        system_prompt = """You are a highly intelligent requirement-extraction engine specialized in MICROSERVICES and MODULAR ARCHITECTURE design.
Your job is to read ANY user input and generate ONLY the following output sections.
Nothing should be hardcoded. Everything must depend on user input.

If the user input is CLEAR â†’ extract exact requirements.
If the user input is VAGUE â†’ analyze, interpret, infer, and SUGGEST requirements based on the domain.

STRICT RULE (MICROSERVICES FIRST PRINCIPLE):
YOU MUST apply MICROSERVICES/MODULAR thinking to ALL Functional Requirements and Non-Functional Requirements.
- IDENTIFY SERVICE BOUNDARIES: Break down the system into independent, loosely-coupled microservices/modules based on business domains.
- DEFINE SERVICE RESPONSIBILITIES: Assign clear responsibilities to each service (e.g., Payment Service, GPS Service, User Auth Service).
- MAP REQUIREMENTS BY SERVICE: Each FR and NFR must be associated with its owning service/module.
- PRESERVE DATA FLOW: Show how services interact and share data.
- GROUP COHESIVELY: Requirements for the same service must be grouped together.

STRICT RULE (TECHNOLOGY EXTRACTION):
Divide technologies into TWO SEPARATE CATEGORIES based on what the USER explicitly mentioned vs what you infer:

1. EXTRACTED (MUST CONTAIN ONLY technologies EXPLICITLY mentioned by user):
   - Only include technology names, tools, frameworks, platforms that the user directly stated or clearly referenced
   - Examples: If user says "React frontend", include React. If they say "SQL Server database", include SQL Server
   - STRICT: Do NOT add technologies not mentioned. Leave categories empty if nothing is mentioned
   - NEVER assume or infer technologies for Extracted category
   - Be VERY conservative - only things the user explicitly said

2. SUGGESTED (MUST CONTAIN ONLY technologies INFERRED from context):
   - Include complementary technologies that weren't mentioned but would be needed
   - Only add if you can justify it from the context of what user actually requested
   - Examples: If user mentions "API", suggest tools for API testing. If user mentions "authentication", suggest OAuth tools
   - NEVER duplicate extracted technologies
   - Focus on filling genuine gaps in their tech stack

For each technology mentioned by user, determine if it's infrastructure, frontend, backend, database, etc. and place ONLY in Extracted.
For inferred technologies, place ONLY in Suggested.
Both categories should use the same 8 subcategories: Frontend, Backend, Database, CloudInfrastructure, APIs, AIMLTools, TestingTools, AdditionalTools.

STRICT RULE (STAKEHOLDERS FORMATTING):
Stakeholders must be a SIMPLE STRING ARRAY with role names as plain strings.
Example: ["Product Manager", "CTO", "Frontend Lead", "Backend Lead", "QA Lead"]
- If none explicitly mentioned â†’ generate realistic stakeholder roles for the domain (5-7 roles minimum).
- NEVER output "NA" for stakeholders. ALWAYS provide actual role names.
- NEVER use objects like {"Role": "X"} - only plain strings.

STRICT RULE:
Do NOT ask clarifying questions. Do NOT leave anything empty.
Always produce fully populated sections, even if input is vague.

OUTPUT SECTIONS (9 Total):
1. Title - Extract the main title or project name from the user input.
2. Problem to Solve - Extract the problem from user input. If vague, infer the core problem.
3. Vision - Extract any user-stated vision. If missing, propose a future-state vision.
4. Stakeholders - Array of stakeholder role names as STRINGS ONLY. Always 5-7 minimum. Never "NA".
5. Scope - In-Scope and Out-of-Scope items. Consider ALL development aspects: Frontend/UI, APIs, Backend services, Databases, Admin features, Dashboards, Integrations, Monitoring/Analytics. Group logically by development area where applicable.
6. Success Metrics - Extract if provided. If missing, propose measurable KPIs aligned with microservice boundaries and user-visible outcomes.
7. Functional Requirements - 6-10+ items GROUPED BY SERVICE/MODULE across Frontend, Backend, APIs, Dashboards, Supporting Services. Each FR must have a Service field indicating its owning microservice. Think: What UI needs to exist? What API endpoints? What backend logic? What admin dashboards? What scheduled services?
8. Non-Functional Requirements - 5-6+ items categorized by type (Performance, Security, Scalability, Reliability, Usability, Maintainability, Observability). Consider all layers: frontend responsiveness, API performance, backend throughput, database optimization, service communication reliability.
9. TechnologyAndTools - TWO objects: 'Extracted' (mentioned technologies) and 'Suggested' (inferred recommendations). Both with 8 categories each (Frontend, Backend, Database, CloudInfrastructure, APIs, AIMLTools, TestingTools, AdditionalTools).
10. RiskAnalysis - Extract mentioned risks or infer realistic risks grouped by type (TechnicalRisks, OperationalRisks, DependencyRisks, SecurityRisks, RequirementRisks).

CRITICAL: Each FR/NFR MUST explicitly state the Service/Module it belongs to. Technology must be clearly separated between what was mentioned vs. what you recommend."""

        # ===========================================================================
        # USER PROMPT - REQUEST 9 SECTIONS WITH SEPARATED TECH + MICROSERVICES
        # ===========================================================================
        user_prompt = f"""
USER INPUT (from {('manual input' if is_manual else 'document: ' + filename)}):
---
{text[:8000]}
---

Extract requirements following the MICROSERVICES ARCHITECTURE approach and return ONLY this JSON structure (no markdown, no extra text):

{{
  "Title": "Project title extracted from input",
  "ProblemToSolve": "Core problem being addressed",
  "Vision": "Future state or vision statement",
  "Stakeholders": ["Product Manager", "CTO", "Frontend Lead", "Backend Lead", "DevOps Lead"],
  "Scope": {{
    "InScope": ["Item 1", "Item 2"],
    "OutOfScope": ["Item 1", "Item 2"]
  }},
  "SuccessMetrics": ["Metric 1", "Metric 2"],
  "FunctionalRequirements": [
    {{
      "ID": "FR1",
      "Service": "ServiceName",
      "Requirement": "What the system must do",
      "Priority": "Critical|High|Medium|Low",
      "Category": "Feature"
    }},
    {{
      "ID": "FR2",
      "Service": "ServiceName",
      "Requirement": "Another requirement",
      "Priority": "High",
      "Category": "Feature"
    }}
  ],
  "NonFunctionalRequirements": [
    {{
      "ID": "NFR1",
      "Category": "Performance",
      "Requirement": "System must handle 10K concurrent users",
      "Description": "Detailed NFR description",
      "Priority": "High"
    }},
    {{
      "ID": "NFR2",
      "Category": "Security",
      "Requirement": "Encrypt all user data",
      "Description": "Implement AES-256 encryption",
      "Priority": "Critical"
    }}
  ],
  "TechnologyAndTools": {{
    "Extracted": {{
      "Frontend": ["React", "TypeScript"],
      "Backend": ["Node.js", "Express"],
      "Database": ["PostgreSQL"],
      "CloudInfrastructure": ["AWS"],
      "APIs": [],
      "AIMLTools": [],
      "TestingTools": [],
      "AdditionalTools": []
    }},
    "Suggested": {{
      "Frontend": [],
      "Backend": ["Docker", "Kubernetes"],
      "Database": ["Redis"],
      "CloudInfrastructure": [],
      "APIs": [],
      "AIMLTools": [],
      "TestingTools": ["Jest", "Mocha"],
      "AdditionalTools": []
    }}
  }},
  "RiskAnalysis": {{
    "TechnicalRisks": ["Risk 1", "Risk 2"],
    "OperationalRisks": ["Risk 1"],
    "DependencyRisks": ["Risk 1"],
    "SecurityRisks": ["Risk 1"],
    "RequirementRisks": ["Risk 1"]
  }}
}}

IMPORTANT: 
- Generate 6-10 Functional Requirements, grouped by different Services/Modules across ALL development aspects:
  * Consider: Frontend UI/UX features, API endpoints, Backend business logic, Microservices, Data layer, Admin/Management features, Dashboards, Monitoring/Analytics, Integration services
  * Each FR MUST have a Service field indicating which microservice/module owns it (e.g., "Auth Service", "Frontend UI", "API Gateway", "Dashboard Service", "Notification Service", etc.)
  * Think holistically: For each user story/requirement, identify what needs to happen in Frontend, API, Backend, and supporting services
  * Do NOT hardcode services - infer logical service boundaries from the domain (user auth â†’ Auth Service, real-time updates â†’ Notification Service, admin functions â†’ Admin Dashboard Service, etc.)
  * Optimize requirements by breaking them into modular, independently deployable services following microservices best practices
  
- Generate 5-6 Non-Functional Requirements with different categories across all development layers:
  * Categories: Performance, Security, Scalability, Reliability, Usability, Maintainability, Observability, API Design
  * Align each NFR with specific services/modules where applicable
  * Consider operational aspects: logging, monitoring, alerting, tracing across distributed systems
  
- Include at least 3-4 categories in RiskAnalysis
- For TechnologyAndTools CRITICAL RULES:
  * "Extracted" MUST contain ONLY technologies the user EXPLICITLY mentioned. If user doesn't mention tech, leave those categories empty []
  * "Suggested" MUST contain ONLY complementary technologies NOT mentioned, inferred from their requirements
  * NEVER put technologies in both Extracted and Suggested - each technology appears in exactly one place
  * Example: If user says "React frontend with Node.js backend", put React in Frontend/Extracted, Node.js in Backend/Extracted, and suggest Docker, Redis only in Suggested
  * If user doesn't mention any backend technology, leave Backend/Extracted empty []
- Stakeholders must ALWAYS be a string array with real role names, never "NA"
- Always return valid JSON only"""

        try:
            # Call OpenAI API
            response = await self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.3,  # Low temperature for consistent structured output
                max_tokens=6000
            )
            
            # Extract and parse response
            content = response.choices[0].message.content.strip()
            print(f"\n[DEBUG] AI Response (first 800 chars):\n{content[:800]}\n")
            
            # Remove markdown code blocks if present
            if content.startswith("```"):
                content = content.split("```")[1]
                if content.startswith("json"):
                    content = content[4:]
                content = content.strip()
            
            # Parse JSON
            try:
                ai_output = json.loads(content)
            except json.JSONDecodeError as je:
                print(f"[ERROR] JSON parsing failed: {je}")
                print(f"[DEBUG] Content to parse:\n{content[:1000]}")
                raise ValueError(f"Invalid JSON from AI: {je}")
            
            # ==================================================================
            # PARSE AND MAP 9 SECTIONS TO UI OUTPUT STRUCTURE
            # ==================================================================
            
            # SECTION 1-6: Business Proposal & Vision
            business_proposal = {
                "Title": ai_output.get("Title", "Untitled Project"),
                "ProblemToSolve": ai_output.get("ProblemToSolve", ""),
                "Vision": ai_output.get("Vision", ""),
                "Stakeholders": ai_output.get("Stakeholders", "NA"),
                "Scope": ai_output.get("Scope", {"InScope": [], "OutOfScope": []}),
                "SuccessMetrics": ai_output.get("SuccessMetrics", [])
            }
            
            # SECTION 7-8: Functional and Non-Functional Requirements
            all_requirements = []
            
            # Functional Requirements (Section 7)
            fr_list = ai_output.get("FunctionalRequirements", [])
            for fr in fr_list:
                req = {
                    'ID': fr.get('ID', 'FR-unknown'),
                    'type': 'Functional',
                    'Requirement': fr.get('Requirement', ''),
                    'Service': fr.get('Service', 'General'),
                    'Priority': fr.get('Priority', 'Medium'),
                    'Category': fr.get('Category', 'Feature'),
                    'status': 'draft'
                }
                all_requirements.append(req)
            
            # Non-Functional Requirements (Section 8)
            nfr_list = ai_output.get("NonFunctionalRequirements", [])
            for nfr in nfr_list:
                req = {
                    'ID': nfr.get('ID', 'NFR-unknown'),
                    'type': 'Non-Functional',
                    'category': nfr.get('Category', 'Quality'),
                    'requirement': nfr.get('Requirement', ''),
                    'description': nfr.get('Description', ''),
                    'priority': nfr.get('Priority', 'Medium'),
                    'status': 'draft'
                }
                all_requirements.append(req)
            
            # SECTION 9: Technology & Tools (now with Extracted and Suggested)
            raw_tech = ai_output.get("TechnologyAndTools", {})
            # Normalize the structure to ensure we have both Extracted and Suggested
            if isinstance(raw_tech, dict) and "Extracted" in raw_tech and "Suggested" in raw_tech:
                technology_and_tools = raw_tech
            else:
                # Fallback: if old format, put everything in Extracted
                technology_and_tools = {
                    "Extracted": raw_tech if isinstance(raw_tech, dict) else {},
                    "Suggested": {}
                }
            
            # SECTION 10: Risk Analysis
            risks_categorized = ai_output.get("RiskAnalysis", {})
            
            # ==================================================================
            # BUILD FINAL OUTPUT FOR UI
            # ==================================================================
            extracted_output = {
                "business_proposal": business_proposal,
                "requirements": all_requirements,
                "risks_categorized": risks_categorized,
                "technology_and_tools": technology_and_tools,
                "technology_extracted": technology_and_tools.get("Extracted", {}),
                "technology_suggested": technology_and_tools.get("Suggested", {}),
                "ai_notes": f"Extracted from {('manual input' if is_manual else 'document: ' + filename)} using 9-section microservices-first AI extraction"
            }
            
            # Print summary
            fr_count = len([r for r in all_requirements if r.get('type') == 'Functional'])
            nfr_count = len([r for r in all_requirements if r.get('type') == 'Non-Functional'])
            extracted_tech_count = sum(len(v) for v in technology_and_tools.get("Extracted", {}).values() if isinstance(v, list))
            suggested_tech_count = sum(len(v) for v in technology_and_tools.get("Suggested", {}).values() if isinstance(v, list))
            print(f"\n[OK] âœ… EXTRACTION COMPLETE (MICROSERVICES ARCHITECTURE):")
            print(f"   ðŸ“‹ Title: {business_proposal['Title']}")
            print(f"   ðŸ‘¥ Stakeholders: {business_proposal['Stakeholders']}")
            print(f"   âœ… Functional Requirements: {fr_count} (grouped by Service/Module)")
            print(f"   â­ Non-Functional Requirements: {nfr_count}")
            print(f"   ðŸ› ï¸  Technology - Extracted: {extracted_tech_count} | Suggested: {suggested_tech_count}")
            print(f"   âš ï¸  Risk Categories: {len(risks_categorized)}\n")
            
            return extracted_output, content
            
        except Exception as e:
            print(f"[ERROR] Extraction failed: {str(e)}")
            raise
    
    # Keep old method for backward compatibility
    async def convert_to_gherkin(self, parsed_content: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Legacy method - now calls extract_structured_requirements for compatibility"""
        result = await self.extract_structured_requirements(parsed_content)
        # Support both tuple return (new) and direct list return (old)
        if isinstance(result, tuple):
            extracted_data, _ = result
            return extracted_data.get('requirements', [])
        if isinstance(result, dict):
            return result.get('requirements', [])
        if isinstance(result, list):
            return result
        return []
    
    async def generate_prd_from_requirements(self, requirements: List[Dict[str, Any]], project_name: str = "Project") -> str:
        """
        Generate Product Requirements Document from extracted requirements using OpenAI
        
        Args:
            requirements: List of Gherkin requirements
            project_name: Name of the project
            
        Returns:
            Complete PRD document in markdown format
        """
        # Prepare requirements summary
        req_summary = ""
        for idx, req in enumerate(requirements, 1):
            req_summary += f"\n{idx}. **{req.get('feature', 'Feature')}**\n"
            req_summary += f"   - As a {req.get('as_a', 'user')}, I want {req.get('i_want', '')}\n"
            req_summary += f"   - So that {req.get('so_that', '')}\n"
            req_summary += f"   - Priority: {req.get('priority', 'Medium')}\n"
            
            scenarios = req.get('scenarios', [])
            if scenarios:
                req_summary += f"   - Scenarios: {len(scenarios)}\n"
        
        prompt = f"""You are an expert Product Manager. Generate a comprehensive Product Requirements Document (PRD) based on the following extracted requirements.

**Project**: {project_name}

**Extracted Requirements**:
{req_summary}

**Instructions**:
Generate a complete, professional PRD following industry best practices with these sections:

1. **Executive Summary**: Overview and objectives
2. **Product Overview**: What is being built and why
3. **Target Users**: Who will use this product
4. **User Personas**: 2-3 detailed personas based on requirements
5. **Feature Requirements**: Detailed breakdown of each feature from extracted requirements
   - Use the actual requirement details
   - Include user stories
   - Add acceptance criteria from scenarios
6. **Functional Requirements**: System capabilities
7. **Non-Functional Requirements**: Performance, security, scalability
8. **User Experience**: UI/UX considerations
9. **Technical Considerations**: Tech stack suggestions
10. **Success Metrics**: KPIs and measurement criteria
11. **Timeline & Phases**: Suggested development phases
12. **Risks & Mitigations**: Potential challenges

**Format**: Markdown with proper headings, lists, and formatting
**Style**: Professional, clear, actionable
**Length**: Comprehensive (2000-3000 words)

Use the ACTUAL requirement details provided above. Do not use generic placeholders. Make it specific to the extracted requirements.

Return the complete PRD document in markdown format."""

        try:
            response = await self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You are an expert Product Manager who creates comprehensive PRDs. Write in markdown format."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.5,
                max_tokens=4000
            )
            
            prd_content = response.choices[0].message.content.strip()
            print(f"[OK] Generated PRD from {len(requirements)} requirements using OpenAI")
            return prd_content
            
        except Exception as e:
            print(f"[WARNING] Error generating PRD with OpenAI: {str(e)}")
            # Return basic PRD
            return self._generate_prd({'requirements': [], 'gherkinRequirements': requirements, 'project': {'name': project_name}})
    
    async def generate_brd_from_requirements(self, requirements: List[Dict[str, Any]], project_name: str = "Project") -> str:
        """
        Generate Business Requirements Document from extracted requirements using OpenAI
        
        Args:
            requirements: List of Gherkin requirements
            project_name: Name of the project
            
        Returns:
            Complete BRD document in markdown format
        """
        # Prepare requirements summary
        req_summary = ""
        for idx, req in enumerate(requirements, 1):
            req_summary += f"\n{idx}. **{req.get('feature', 'Feature')}** (Priority: {req.get('priority', 'Medium')})\n"
            req_summary += f"   - User Story: As a {req.get('as_a', 'user')}, I want {req.get('i_want', '')}\n"
            req_summary += f"   - Business Value: {req.get('so_that', '')}\n"
        
        prompt = f"""You are an expert Business Analyst. Generate a comprehensive Business Requirements Document (BRD) based on the following extracted requirements.

**Project**: {project_name}

**Extracted Requirements**:
{req_summary}

**Instructions**:
Generate a complete, professional BRD following industry best practices with these sections:

1. **Executive Summary**: Business case and objectives
2. **Business Context**: Industry, market, and competitive landscape
3. **Business Objectives**: Clear, measurable goals (SMART)
4. **Stakeholders**: Key stakeholders and their interests
5. **Scope**: In-scope and out-of-scope items based on requirements
6. **Business Requirements**: High-level business needs
   - Use the actual extracted requirements
   - Group by business capability
   - Link to business value
7. **Functional Requirements**: Detailed functionality needed
8. **Business Rules**: Rules and constraints
9. **Assumptions & Dependencies**: What we're assuming, what we depend on
10. **Success Criteria**: How we measure success
11. **Timeline & Budget**: High-level estimates
12. **Risk Analysis**: Business risks and mitigation strategies
13. **Approval & Sign-off**: Stakeholder approval process

**Format**: Markdown with proper headings, tables, and formatting
**Style**: Business-focused, strategic, clear
**Length**: Comprehensive (2000-3000 words)

Use the ACTUAL requirement details provided above. Focus on BUSINESS VALUE and strategic alignment. Make it specific to the extracted requirements.

Return the complete BRD document in markdown format."""

        try:
            response = await self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You are an expert Business Analyst who creates comprehensive BRDs. Write in markdown format focusing on business value."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.5,
                max_tokens=4000
            )
            
            brd_content = response.choices[0].message.content.strip()
            print(f"[OK] Generated BRD from {len(requirements)} requirements using OpenAI")
            return brd_content
            
        except Exception as e:
            print(f"[WARNING] Error generating BRD with OpenAI: {str(e)}")
            # Return basic BRD
            return self._generate_brd({'requirements': [], 'gherkinRequirements': requirements, 'project': {'name': project_name}})
    
    async def analyze_risks(self, requirements: List[Dict[str, Any]], project_name: str = "Project") -> List[Dict[str, Any]]:
        """
        Analyze risks based on extracted requirements using OpenAI.
        Returns list of risks with priority, impact, and mitigation strategies.
        
        Args:
            requirements: List of Gherkin requirements
            project_name: Name of the project
            
        Returns:
            List of risk assessments
        """
        if not requirements:
            return []
        
        print(f"[DEBUG] analyze_risks: Starting risk analysis for project '{project_name}' with {len(requirements)} requirements.")
        
        # Prepare requirements summary for risk analysis
        req_summary = ""
        for idx, req in enumerate(requirements, 1):
            if 'objective' in req and 'requirements' in req:
                req_summary += f"\n{idx}. **Objective: {req.get('objective', 'N/A')}**\n"
                req_summary += f"   - Summary: {req.get('summary', 'N/A')}\n"
                req_summary += f"   - Priority: {req.get('priority', 'Medium')}\n"
                req_summary += f"   - Category: {req.get('category', 'Functional')}\n"
                req_summary += f"   - Implementation Steps: {len(req.get('requirements', []))}\n"
                for step_idx, step in enumerate(req.get('requirements', [])[:3], 1): # Include first 3 steps
                    req_summary += f"     - Step {step_idx}: {step[:100]}...\n" if len(step) > 100 else f"     - Step {step}\n"
            elif 'as_a' in req:
                req_summary += f"\n{idx}. **Feature: {req.get('feature', 'N/A')}**\n"
            req_summary += f"   - Priority: {req.get('priority', 'Medium')}\n"
            req_summary += f"   - User Story: As a {req.get('as_a', 'user')}, I want {req.get('i_want', '')}\n"
            scenarios = req.get('scenarios', [])
            if scenarios:
                req_summary += f"   - Complexity: {len(scenarios)} scenarios\n"
            else:
                req_summary += f"\n{idx}. **Requirement: {req.get('title', 'N/A')}**\n"
                req_summary += f"   - Priority: {req.get('priority', 'Medium')}\n"
        
        print(f"[DEBUG] analyze_risks: Generated req_summary (first 500 chars):\n{req_summary[:500]}")
        
        prompt = f"""You are an expert Risk Analyst and Project Manager. Analyze the following requirements and identify potential risks for this project.

**Project**: {project_name}

**Requirements**:
{req_summary}

**Instructions**:
Analyze these requirements and identify risks in the following categories:
1. **Technical Risks**: Technology challenges, integration issues, performance concerns
2. **Business Risks**: Market changes, stakeholder alignment, ROI concerns
3. **Resource Risks**: Team availability, skills gaps, dependencies
4. **Schedule Risks**: Timeline pressures, dependencies, scope creep
5. **Quality Risks**: Testing challenges, complexity, technical debt

For each risk, provide:
- **Risk Name**: Clear, specific risk description
- **Category**: Technical/Business/Resource/Schedule/Quality
- **Priority**: Critical/High/Medium/Low (based on likelihood Ã— impact)
- **Impact**: Severe/High/Medium/Low
- **Likelihood**: Very Likely/Likely/Possible/Unlikely
- **Mitigation**: Specific mitigation strategy
- **Contingency**: What to do if risk occurs

**Priority Calculation**:
- Critical: High likelihood + High/Severe impact
- High: Medium/High likelihood + Medium/High impact
- Medium: Low/Medium likelihood + Medium impact
- Low: Low likelihood + Low impact

**Output Format** (JSON array):
[
  {{
    "id": "risk-1",
    "risk": "Specific risk description",
    "category": "Technical|Business|Resource|Schedule|Quality",
    "priority": "Critical|High|Medium|Low",
    "impact": "Severe|High|Medium|Low",
    "likelihood": "Very Likely|Likely|Possible|Unlikely",
    "mitigation": "Specific mitigation strategy",
    "contingency": "Plan if risk occurs",
    "affected_requirements": ["req-1", "req-2"]
  }}
]

Identify 5-10 most significant risks. Be specific to the actual requirements provided. Focus on realistic, actionable risks.

Return ONLY the JSON array."""

        try:
            response = await self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You are an expert Risk Analyst who identifies and assesses project risks. Always respond with valid JSON."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.4,  # Lower temperature for more consistent risk analysis
                max_tokens=2000
            )
            
            content = response.choices[0].message.content.strip()
            
            # Remove markdown code blocks if present
            if content.startswith("```"):
                content = content.split("```")[1]
                if content.startswith("json"):
                    content = content[4:]
                content = content.strip()
            
            risks = json.loads(content)
            
            # Validate and ensure proper structure
            if isinstance(risks, list):
                for idx, risk in enumerate(risks):
                    if 'id' not in risk:
                        risk['id'] = f"risk-{idx + 1}"
                    if 'risk' not in risk:
                        risk['risk'] = f"Risk {idx + 1}"
                    if 'category' not in risk:
                        risk['category'] = "Technical"
                    if 'priority' not in risk:
                        risk['priority'] = "Medium"
                    if 'impact' not in risk:
                        risk['impact'] = "Medium"
                    if 'likelihood' not in risk:
                        risk['likelihood'] = "Possible"
                    if 'mitigation' not in risk:
                        risk['mitigation'] = "To be defined"
                    if 'contingency' not in risk:
                        risk['contingency'] = "Monitor and reassess"
                    if 'affected_requirements' not in risk:
                        risk['affected_requirements'] = []
                
                print(f"[OK] Analyzed {len(risks)} risks using OpenAI")
                return risks
            else:
                raise ValueError("Invalid risk structure from OpenAI")
                
        except Exception as e:
            print(f"[WARNING] Error analyzing risks with OpenAI: {str(e)}")
            
            # Fallback: Return basic risk assessment
            return [
                {
                    "id": "risk-1",
                    "risk": "Technical complexity in implementation",
                    "category": "Technical",
                    "priority": "High",
                    "impact": "High",
                    "likelihood": "Likely",
                    "mitigation": "Conduct technical spike, use proven technologies",
                    "contingency": "Allocate additional development time",
                    "affected_requirements": []
                },
                {
                    "id": "risk-2",
                    "risk": "Resource availability constraints",
                    "category": "Resource",
                    "priority": "Medium",
                    "impact": "Medium",
                    "likelihood": "Possible",
                    "mitigation": "Ensure team allocation in advance",
                    "contingency": "Adjust timeline or scope",
                    "affected_requirements": []
                },
                {
                    "id": "risk-3",
                    "risk": "Scope creep and requirement changes",
                    "category": "Schedule",
                    "priority": "High",
                    "impact": "High",
                    "likelihood": "Likely",
                    "mitigation": "Implement strict change control process",
                    "contingency": "Re-prioritize features, phase delivery",
                    "affected_requirements": []
                }
            ]
    def _generate_fallback_prd(self, project_info: Dict[str, Any], requirements: List[Dict[str, Any]]) -> str:
        """Generate basic PRD when OpenAI fails (supports both new and legacy format)"""
        features_section = ""

        for idx, req in enumerate(requirements, 1):
            if 'type' in req and req['type'] in ['Functional', 'Non-Functional']:
                feature_name = req.get('requirement', f'Requirement {idx}')
                priority = req.get('priority', 'Medium')
                category = req.get('category', 'Functional')
                description = req.get('description', req.get('derived_from', ''))

                features_section += f"\n### {idx}. {feature_name}\n"
                features_section += f"**Type**: {req.get('type')}, **Priority**: {priority}, **Category**: {category}\n"
                if description:
                    features_section += f"**Description**: {description[:200]}...\n" if len(description) > 200 else f"**Description**: {description}\n"
                if req.get('stakeholder_actor'):
                    features_section += f"**Stakeholder**: {req.get('stakeholder_actor')}\n"
                features_section += "\n"
            else:
                feature_name = req.get('feature', req.get('title', f'Feature {idx}'))
                priority = req.get('priority', 'Medium')
                features_section += f"\n### {idx}. {feature_name}\n**Priority**: {priority}\n\n"
        
        prd_content = """
        # Product Requirements Document (PRD)

        ## Project: {project_name}

## 1. Product Overview
        {project_description}

## 2. Key Features
{features_section}

## 3. Requirements Summary
        Total Requirements: {requirements_count}

        ---
        _Generated by TAO SDLC AI Copilot (Fallback Mode)_"""
        return prd_content.format(
            project_name=project_info.get('name', 'Project'),
            project_description=project_info.get('description', 'Product description'),
            features_section=features_section,
            requirements_count=len(requirements)
        )
    
    def _generate_fallback_brd(self, project_info: Dict[str, Any], requirements: List[Dict[str, Any]]) -> str:
        """Generate basic BRD when OpenAI fails (supports both new and legacy format)"""
        scope_items = ""
        business_objectives = []

        for idx, req in enumerate(requirements, 1):
            if 'type' in req and req['type'] in ['Functional', 'Non-Functional']:
                feature_name = req.get('requirement', f'Requirement {idx}')
                priority = req.get('priority', 'Medium')
                category = req.get('category', 'Functional')
                summary = req.get('description', '') # Use description for NFRs, otherwise empty

                scope_items += f"- **{feature_name}** (Priority: {priority}, Category: {category})\n"
                if summary:
                    scope_items += f"  - {summary[:150]}...\n" if len(summary) > 150 else f"  - {summary}\n"
                business_objectives.append(feature_name)
            elif 'objective' in req:
                feature_name = req.get('objective', f'Feature {idx}')
                priority = req.get('priority', 'Medium')
                category = req.get('category', 'Functional')
                summary = req.get('summary', '')
                
                scope_items += f"- **{feature_name}** (Priority: {priority}, Category: {category})\n"
                if summary:
                    scope_items += f"  - {summary[:150]}...\n" if len(summary) > 150 else f"  - {summary}\n"
                business_objectives.append(feature_name)
            else:
                feature_name = req.get('feature', req.get('title', f'Feature {idx}'))
                priority = req.get('priority', 'Medium')
                scope_items += f"- {feature_name} (Priority: {priority})\n"
                business_objectives.append(feature_name)

        objectives_section = ""
        for idx, obj in enumerate(business_objectives[:5], 1):
            objectives_section += f"{idx}. {obj}\n"
        if len(business_objectives) > 5:
            objectives_section += f"... and {len(business_objectives) - 5} more objectives\n"

        brd_content = """
            # Business Requirements Document (BRD)

            ## Project: {project_name}

## 1. Executive Summary
            {project_description}

## 2. Business Objectives
            {objectives_section if objectives_section else '- Deliver high-quality solution meeting all requirements\n- Ensure user satisfaction and adoption\n- Achieve ROI within expected timeframe'}

## 3. Scope

### In Scope
{scope_items}

## 4. Requirements Summary
Total Requirements: {len(requirements)}

---
            _Generated by TAO SDLC AI Copilot (Fallback Mode)_"""
        return brd_content.format(
            project_name=project_info.get('name', 'Project'),
            project_description=project_info.get('description', 'Business case'),
            objectives_section=objectives_section if objectives_section else '- Deliver high-quality solution meeting all requirements\n- Ensure user satisfaction and adoption\n- Achieve ROI within expected timeframe',
            scope_items=scope_items,
            requirements_count=len(requirements)
        )
    
    async def convert_excel_to_swagger(self, parsed_api_spec: Dict[str, Any], excel_filename: str = 'API Requirements') -> Dict[str, Any]:
        """
        Convert Excel-based API requirements to comprehensive Swagger/OpenAPI 3.0 specification
        Uses AI to enhance descriptions, infer missing details, and ensure completeness
        
        Args:
            parsed_api_spec: Parsed API specification from Excel
            excel_filename: Name of the source Excel file
            
        Returns:
            Complete OpenAPI 3.0 specification
        """
        print(f"[INFO] Converting {excel_filename} to Swagger/OpenAPI specification using AI")
        
        # Prepare context for AI
        paths_summary = ""
        endpoint_count = 0
        for path, methods in parsed_api_spec.get('paths', {}).items():
            for method, spec in methods.items():
                endpoint_count += 1
                paths_summary += f"\n{endpoint_count}. {method.upper()} {path}: {spec.get('summary', 'No description')}"
        
        if endpoint_count == 0:
            print("[WARNING] No API endpoints found in Excel")
            return self._enhance_swagger_spec_fallback(parsed_api_spec)
        
        prompt = f"""You are an expert API architect and technical writer. Analyze the following API specification extracted from an Excel document and enhance it to create a complete, professional Swagger/OpenAPI 3.0 specification.

**Source**: {excel_filename}

**Current API Info**:
- Title: {parsed_api_spec.get('info', {}).get('title', 'API')}
- Version: {parsed_api_spec.get('info', {}).get('version', '1.0.0')}
- Description: {parsed_api_spec.get('info', {}).get('description', 'Not provided')}

**Endpoints Found** ({endpoint_count} total):
{paths_summary}

**Your Task**:
1. **Enhance descriptions**: Make them clear, professional, and actionable for developers
2. **Improve schemas**: Ensure all request/response bodies have detailed, realistic schemas with proper types
3. **Add examples**: Create realistic, useful examples for requests and responses
4. **Standardize responses**: Include common error responses (400, 401, 404, 500) for all endpoints
5. **Add metadata**: Improve API info with better description, contact info
6. **Enhance tags**: Improve tag descriptions for better organization
7. **Validate structure**: Ensure perfect OpenAPI 3.0.0 compliance

**Guidelines**:
- Follow OpenAPI 3.0.0 specification exactly
- Use professional, developer-friendly language
- Make the API specification production-ready and complete
- Keep existing path structures and methods from the Excel
- Add detailed property descriptions in schemas
- Include realistic example values
- Add authentication details if security schemes exist

Return a complete, valid OpenAPI 3.0 JSON specification.

Return ONLY the JSON specification, no additional text or markdown."""

        try:
            response = await self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system",
                        "content": "You are an expert API architect who creates perfect OpenAPI 3.0 specifications. Always respond with valid, complete, production-ready JSON. Ensure all schemas are detailed and include example values."
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=4000
            )
            
            # Parse response
            content = response.choices[0].message.content.strip()
            
            # Remove markdown code blocks if present
            if content.startswith("```"):
                content = content.split("```")[1]
                if content.startswith("json"):
                    content = content[4:]
                content = content.strip()
            
            enhanced_spec = json.loads(content)
            
            # Ensure it has openapi version
            enhanced_spec['openapi'] = '3.0.0'
            
            print(f"[OK] Successfully enhanced API specification with AI")
            return enhanced_spec
            
        except Exception as e:
            print(f"[WARNING] AI enhancement failed: {str(e)}, using fallback enhancement")
            return self._enhance_swagger_spec_fallback(parsed_api_spec)

    def _enhance_swagger_spec_fallback(self, spec: Dict[str, Any]) -> Dict[str, Any]:
        """Fallback enhancement without AI"""
        # Ensure OpenAPI version
        spec['openapi'] = '3.0.0'
        
        # Ensure required fields
        if 'info' not in spec:
            spec['info'] = {}
        
        spec['info'].setdefault('title', 'API Specification')
        spec['info'].setdefault('version', '1.0.0')
        spec['info'].setdefault('description', 'API documentation generated from Excel requirements')
        
        # Add contact if not present
        if 'contact' not in spec['info']:
            spec['info']['contact'] = {
                'name': 'API Support',
                'email': 'api-support@example.com'
            }
        
        # Ensure servers
        if not spec.get('servers'):
            spec['servers'] = [
                {'url': 'https://api.example.com/v1', 'description': 'Production server'},
                {'url': 'https://staging-api.example.com/v1', 'description': 'Staging server'}
            ]
        
        # Ensure components
        if 'components' not in spec:
            spec['components'] = {}
        
        # Add common error responses
        if 'responses' not in spec['components']:
            spec['components']['responses'] = {
                'BadRequest': {
                    'description': 'Bad request - Invalid input parameters',
                    'content': {
                        'application/json': {
                            'schema': {
                                'type': 'object',
                                'properties': {
                                    'error': {'type': 'string'},
                                    'message': {'type': 'string'},
                                    'details': {'type': 'array', 'items': {'type': 'string'}}
                                }
                            },
                            'example': {
                                'error': 'Bad Request',
                                'message': 'Invalid input parameters',
                                'details': ['Field "email" is required']
                            }
                        }
                    }
                },
                'Unauthorized': {
                    'description': 'Unauthorized - Authentication required',
                    'content': {
                        'application/json': {
                            'schema': {
                                'type': 'object',
                                'properties': {
                                    'error': {'type': 'string'},
                                    'message': {'type': 'string'}
                                }
                            },
                            'example': {
                                'error': 'Unauthorized',
                                'message': 'Authentication token is missing or invalid'
                            }
                        }
                    }
                },
                'NotFound': {
                    'description': 'Resource not found',
                    'content': {
                        'application/json': {
                            'schema': {
                                'type': 'object',
                                'properties': {
                                    'error': {'type': 'string'},
                                    'message': {'type': 'string'}
                                }
                            },
                            'example': {
                                'error': 'Not Found',
                                'message': 'The requested resource does not exist'
                            }
                        }
                    }
                },
                'ServerError': {
                    'description': 'Internal server error',
                    'content': {
                        'application/json': {
                            'schema': {
                                'type': 'object',
                                'properties': {
                                    'error': {'type': 'string'},
                                    'message': {'type': 'string'}
                                }
                            },
                            'example': {
                                'error': 'Internal Server Error',
                                'message': 'An unexpected error occurred'
                            }
                        }
                    }
                }
            }
        
        return spec
    
    async def _generate_component_wise_lld(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Generate comprehensive Component-Wise Low-Level Design with 12 sections per component.
        Provides detailed technical specifications for each system component.
        """
        from datetime import datetime
        import time
        
        start_time = time.time()
        print("[INFO] Generating Component-Wise LLD with 12-section structure...")
        print(f"[TIMING] Method start: {start_time}")
        
        # ðŸ”´ CRITICAL: Log ALL data keys to see what's being received
        print(f"\nðŸ”´ [_generate_component_wise_lld RECEIVED] All data keys: {list(data.keys())}")
        
        # Extract data
        system_components = data.get('system_components', [])
        user_stories = data.get('user_stories', [])
        epics = data.get('epics', [])
        project_name = data.get('project_name', 'Project')
        
        # ðŸ”´ CRITICAL: Log what we extracted
        print(f"ðŸ”´ [_generate_component_wise_lld] system_components type: {type(system_components)}")
        print(f"ðŸ”´ [_generate_component_wise_lld] system_components length: {len(system_components) if system_components else 0}")
        print(f"ðŸ”´ [_generate_component_wise_lld] system_components is empty? {not system_components}")
        if system_components:
            print(f"ðŸ”´ [_generate_component_wise_lld] First component: {system_components[0].get('name') if isinstance(system_components[0], dict) else system_components[0]}")
            print(f"ðŸ”´ [_generate_component_wise_lld] Full components list NAMES: {[c.get('name', 'NO_NAME') if isinstance(c, dict) else str(c) for c in system_components]}")
        
        if not system_components:
            # Generate basic components if none provided
            print("ðŸ”´ [FALLBACK] No system_components received - USING DEFAULTS!")
            system_components = [
                {
                    "name": "Frontend Application",
                    "type": "Frontend",
                    "description": "User interface layer for web application",
                    "technologies": ["React", "TypeScript"],
                    "responsibilities": ["User interaction", "Form handling", "API integration"]
                },
                {
                    "name": "Backend API Service", 
                    "type": "Backend API",
                    "description": "REST API service for business logic",
                    "technologies": ["FastAPI", "Python"],
                    "responsibilities": ["Business logic", "Data processing", "Authentication"]
                },
                {
                    "name": "Database Layer",
                    "type": "Database", 
                    "description": "Data storage and persistence layer",
                    "technologies": ["PostgreSQL"],
                    "responsibilities": ["Data storage", "Query optimization", "Backup"]
                }
            ]
        else:
            print(f"ðŸŸ¢ [SUCCESS] Using {len(system_components)} provided system_components from request")
        
        # Helper functions for intelligent content generation
        def analyze_component(component: Dict[str, Any]) -> Dict[str, Any]:
            """Analyze component to determine its characteristics and requirements"""
            comp_name = component.get('name', '').lower()
            comp_type = component.get('type', '').lower()
            comp_desc = component.get('description', '').lower()
            technologies = [tech.lower() for tech in component.get('technologies', [])]
            
            # Determine component characteristics
            is_frontend = any(indicator in f"{comp_name} {comp_type} {comp_desc}" for indicator in 
                            ['frontend', 'ui', 'interface', 'web', 'react', 'angular', 'vue'])
            is_backend = any(indicator in f"{comp_name} {comp_type} {comp_desc}" for indicator in 
                           ['backend', 'api', 'service', 'server', 'fastapi', 'django', 'express'])
            is_database = any(indicator in f"{comp_name} {comp_type} {comp_desc}" for indicator in 
                            ['database', 'storage', 'db', 'postgresql', 'mysql', 'mongodb'])
            is_infrastructure = any(indicator in f"{comp_name} {comp_type} {comp_desc}" for indicator in 
                                  ['cache', 'redis', 'queue', 'message', 'infrastructure'])
            
            return {
                'is_frontend': is_frontend,
                'is_backend': is_backend, 
                'is_database': is_database,
                'is_infrastructure': is_infrastructure,
                'has_api': is_backend or 'api' in comp_desc,
                'has_ui': is_frontend or 'interface' in comp_desc,
                'stores_data': is_database or 'storage' in comp_desc,
                'tech_stack': technologies
            }
        
        def map_stories_to_component(component: Dict[str, Any], stories: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
            """
            Enhanced story-to-component mapping with intelligent analysis and Epic structure
            """
            comp_name = component.get('name', '').lower()
            comp_type = component.get('type', '').lower()
            comp_desc = component.get('description', '').lower()
            comp_keywords = set(comp_name.split() + comp_desc.split() + comp_type.split())
            
            # Clean up keywords (remove small words)
            comp_keywords = {kw for kw in comp_keywords if len(kw) > 2}
            
            relevant_stories = []
            for story in stories:
                story_text = f"{story.get('title', '')} {story.get('description', '')}".lower()
                epic_name = story.get('epic', story.get('epic_name', ''))
                
                # Calculate relevance score based on multiple factors
                score = 0
                
                # Direct keyword matching
                for keyword in comp_keywords:
                    if keyword in story_text:
                        score += 3
                
                # Component type specific matching
                if 'frontend' in comp_type or 'ui' in comp_type:
                    ui_terms = ['display', 'show', 'view', 'interface', 'form', 'screen', 'navigate', 'dashboard', 'page']
                    score += sum(2 for term in ui_terms if term in story_text)
                    
                elif 'backend' in comp_type or 'api' in comp_type or 'service' in comp_type:
                    api_terms = ['create', 'manage', 'process', 'authenticate', 'validate', 'register', 'login', 'update', 'delete']
                    score += sum(2 for term in api_terms if term in story_text)
                    
                elif 'database' in comp_type or 'storage' in comp_type:
                    data_terms = ['store', 'save', 'retrieve', 'data', 'record', 'query', 'search']
                    score += sum(3 for term in data_terms if term in story_text)
                
                # Authentication component special handling
                if 'auth' in comp_name or 'authentication' in comp_desc:
                    auth_terms = ['login', 'register', 'password', 'account', 'user', 'authentication', 'session']
                    score += sum(4 for term in auth_terms if term in story_text)
                
                # User management component special handling  
                if 'user' in comp_name and ('manage' in comp_desc or 'management' in comp_desc):
                    user_terms = ['user', 'profile', 'account', 'manage', 'list', 'create', 'update']
                    score += sum(3 for term in user_terms if term in story_text)
                
                if score > 0:
                    relevant_stories.append({
                        **story,
                        '_relevance_score': score,
                        '_epic_name': epic_name or f"Epic E{len(relevant_stories)+1}"
                    })
            
            # Sort by relevance and return top stories
            relevant_stories.sort(key=lambda x: x['_relevance_score'], reverse=True)
            return relevant_stories[:4]  # Top 4 most relevant stories
        
        def generate_api_table(component: Dict[str, Any], analysis: Dict[str, Any], stories: List[Dict[str, Any]]) -> str:
            """
            Generate COMPONENT-SPECIFIC API endpoints.
            âš ï¸ AVOID REPETITION: Only generate APIs relevant to THIS component, not all APIs in the system.
            Analyze component type and map only the stories that directly involve this component.
            """
            if not analysis['has_api']:
                return "N/A - This component does not expose API endpoints."
            
            comp_name = component.get('name', '').lower()
            comp_type = component.get('type', '').lower()
            comp_desc = component.get('description', '').lower()
            comp_orig_name = component.get('name', '')
            
            # Determine component responsibility with more nuanced detection
            is_auth_component = any(term in f"{comp_name}{comp_desc}" for term in ['auth', 'authentication', 'security', 'login', 'session'])
            is_user_component = 'user' in comp_name or 'account' in comp_name or 'profile' in comp_name
            is_transaction_component = 'transaction' in comp_name or 'payment' in comp_name or 'order' in comp_name
            is_data_component = 'product' in comp_name or 'inventory' in comp_name or 'catalog' in comp_name or 'item' in comp_name
            is_dashboard_component = 'dashboard' in comp_name or 'analytics' in comp_name or 'report' in comp_name
            is_service = 'service' in comp_type
            
            # Map relevant stories to this component with detailed analysis
            mapped_stories = []
            for story in stories:
                story_title = story.get('title', '').lower()
                story_desc = story.get('description', '').lower()
                story_text = f"{story_title} {story_desc}"
                
                # Calculate story relevance to component
                component_keywords = set(comp_name.split()) | set(comp_desc.split()) | {comp_orig_name.lower()}
                story_keywords = set(story_text.split())
                common_count = len(component_keywords & story_keywords)
                
                # Include story if relevant to component or component type matches
                if common_count > 0 or comp_type in story_text or any(keyword in story_text for keyword in ['authentication', 'user', 'account', 'transaction', 'order', 'product']):
                    mapped_stories.append({
                        'title': story.get('title', ''),
                        'description': story.get('description', ''),
                        'priority': story.get('priority', 'Medium'),
                        'text': story_text,
                        'relevance': common_count
                    })
            
            # Sort by relevance descending
            mapped_stories = sorted(mapped_stories, key=lambda x: x['relevance'], reverse=True)
            
            apis = []
            
            # Generate health check only for service/API components
            if 'service' in comp_type or 'api' in comp_type:
                base_path = comp_name.replace(' ', '-').replace('service', '').replace('api', '').strip('-')
                apis.append({
                    'method': 'GET',
                    'endpoint': f'/{base_path}/health',
                    'description': 'Service health and dependency status',
                    'business_logic': 'Validate service status, DB connectivity, critical dependencies',
                    'auth': 'None',
                    'mapped_story': 'System monitoring'
                })
            
            # âš ï¸ ENHANCED: Extract specific requirements from mapped stories for sophisticated API generation
            processed_stories = set()
            
            for story in mapped_stories[:8]:  # Process top 8 most relevant stories
                story_text = story['text']
                story_title = story['title'].lower()
                story_id = story['title']
                
                # Skip if already processed
                if story_id in processed_stories:
                    continue
                
                # ========== AUTHENTICATION COMPONENT APIS ==========
                if is_auth_component:
                    # Login/Authentication endpoint
                    if any(term in story_text for term in ['login', 'signin', 'authenticate', 'credential', 'sign in']):
                        if not any(api['endpoint'] == '/auth/login' for api in apis):
                            apis.append({
                                'method': 'POST',
                                'endpoint': '/auth/login',
                                'description': 'Authenticate user with credentials (email/username + password), return JWT auth token',
                                'business_logic': 'Email/username validation, password verification, JWT generation, session creation, login tracking',
                                'auth': 'None',
                                'mapped_story': story_id
                            })
                            processed_stories.add(story_id)
                    
                    # Registration endpoint
                    if any(term in story_text for term in ['register', 'signup', 'create account', 'new user', 'sign up', 'onboarding']):
                        if not any(api['endpoint'] == '/auth/register' for api in apis):
                            apis.append({
                                'method': 'POST',
                                'endpoint': '/auth/register',
                                'description': 'Register new user account with email validation and password confirmation',
                                'business_logic': 'Email uniqueness validation, password strength check, password hashing, user record creation, welcome email sending, default role assignment',
                                'auth': 'None',
                                'mapped_story': story_id
                            })
                            processed_stories.add(story_id)
                    
                    # Password reset endpoint
                    if any(term in story_text for term in ['password', 'reset', 'forgot', 'change password', 'forgot password', 'recover']):
                        if not any(api['endpoint'] == '/auth/password-reset' for api in apis):
                            apis.append({
                                'method': 'POST',
                                'endpoint': '/auth/password-reset',
                                'description': 'Initiate password reset with email verification link',
                                'business_logic': 'Email verification, password reset token generation, token expiry setup (24hrs), secure email notification, rate limiting',
                                'auth': 'None',
                                'mapped_story': story_id
                            })
                        if not any(api['endpoint'] == '/auth/password-reset/confirm' for api in apis):
                            apis.append({
                                'method': 'POST',
                                'endpoint': '/auth/password-reset/confirm',
                                'description': 'Confirm password reset with token validation and new password',
                                'business_logic': 'Token validity check, token expiry validation, password hashing, session revocation, audit logging',
                                'auth': 'None',
                                'mapped_story': story_id
                            })
                        processed_stories.add(story_id)
                    
                    # MFA/2FA endpoints
                    if any(term in story_text for term in ['mfa', 'two-factor', 'otp', 'totp', 'two factor', '2fa', 'authenticator', '2-step']):
                        if not any(api['endpoint'] == '/auth/mfa-setup' for api in apis):
                            apis.append({
                                'method': 'POST',
                                'endpoint': '/auth/mfa-setup',
                                'description': 'Setup multi-factor authentication (TOTP, SMS, Email)',
                                'business_logic': 'MFA type selection, secret generation, QR code generation for authenticator apps, backup codes generation, verification test',
                                'auth': 'Required',
                                'mapped_story': story_id
                            })
                        if not any(api['endpoint'] == '/auth/mfa-verify' for api in apis):
                            apis.append({
                                'method': 'POST',
                                'endpoint': '/auth/mfa-verify',
                                'description': 'Verify MFA code during login process',
                                'business_logic': 'OTP validation, time-window verification (Â±30s for TOTP), attempt tracking, rate limiting (5 attempts), failed attempt logging',
                                'auth': 'None',
                                'mapped_story': story_id
                            })
                        processed_stories.add(story_id)
                    
                    # Logout endpoint
                    if any(term in story_text for term in ['logout', 'signout', 'revoke', 'session', 'sign out']):
                        if not any(api['endpoint'] == '/auth/logout' for api in apis):
                            apis.append({
                                'method': 'POST',
                                'endpoint': '/auth/logout',
                                'description': 'Logout user and invalidate active sessions',
                                'business_logic': 'Token revocation, active session termination, session cleanup, audit logging, redirect URL handling',
                                'auth': 'Required',
                                'mapped_story': story_id
                            })
                        processed_stories.add(story_id)
                    
                    # Token refresh endpoint
                    if any(term in story_text for term in ['refresh', 'token', 'renew', 'extend', 'expir']):
                        if not any(api['endpoint'] == '/auth/refresh-token' for api in apis):
                            apis.append({
                                'method': 'POST',
                                'endpoint': '/auth/refresh-token',
                                'description': 'Refresh expired authentication token with refresh token',
                                'business_logic': 'Refresh token validation, rotation check, new JWT generation, token expiry extension, refresh token rotation',
                                'auth': 'Required',
                                'mapped_story': story_id
                            })
                        processed_stories.add(story_id)
                
                # ========== USER MANAGEMENT COMPONENT APIS ==========
                elif is_user_component:
                    # List users endpoint
                    if any(term in story_text for term in ['list', 'view', 'browse', 'search', 'display', 'retrieve', 'all users']):
                        if not any(api['endpoint'] == '/api/users' and api['method'] == 'GET' for api in apis):
                            apis.append({
                                'method': 'GET',
                                'endpoint': '/api/users',
                                'description': 'Retrieve paginated user list with advanced filtering, sorting and search',
                                'business_logic': 'Filter by status/role/department/email, sorting by name/created/updated, pagination (limit/offset), permission validation, query optimization',
                                'auth': 'Admin',
                                'mapped_story': story_id
                            })
                        if not any(api['endpoint'] == '/api/users/{id}' and api['method'] == 'GET' for api in apis):
                            apis.append({
                                'method': 'GET',
                                'endpoint': '/api/users/{id}',
                                'description': 'Get detailed user profile with roles, permissions and related data',
                                'business_logic': 'User record retrieval, role aggregation, permission calculation, related records fetch (recent actions, settings)',
                                'auth': 'Required',
                                'mapped_story': story_id
                            })
                        processed_stories.add(story_id)
                    
                    # Create user endpoint
                    if any(term in story_text for term in ['create', 'add', 'register', 'onboard', 'new user', 'invite']):
                        if not any(api['endpoint'] == '/api/users' and api['method'] == 'POST' for api in apis):
                            apis.append({
                                'method': 'POST',
                                'endpoint': '/api/users',
                                'description': 'Create new user with roles, department and permissions assignment',
                                'business_logic': 'Data validation, email uniqueness check, role assignment, department mapping, permission inheritance, welcome email sending, audit logging',
                                'auth': 'Admin',
                                'mapped_story': story_id
                            })
                        processed_stories.add(story_id)
                    
                    # Update user endpoint
                    if any(term in story_text for term in ['update', 'edit', 'modify', 'change', 'profile', 'settings']):
                        if not any(api['endpoint'] == '/api/users/{id}' and api['method'] == 'PUT' for api in apis):
                            apis.append({
                                'method': 'PUT',
                                'endpoint': '/api/users/{id}',
                                'description': 'Update user profile, contact info, department and personal settings',
                                'business_logic': 'Permission validation, change history tracking, email notification of changes, audit logging, conflict detection',
                                'auth': 'Required',
                                'mapped_story': story_id
                            })
                        processed_stories.add(story_id)
                    
                    # Delete/Deactivate user endpoint
                    if any(term in story_text for term in ['delete', 'remove', 'deactivate', 'disable', 'archive', 'suspend', 'inactivate']):
                        if not any(api['endpoint'] == '/api/users/{id}' and api['method'] == 'DELETE' for api in apis):
                            apis.append({
                                'method': 'DELETE',
                                'endpoint': '/api/users/{id}',
                                'description': 'Soft delete or deactivate user account with data archival',
                                'business_logic': 'Permission validation, soft-delete flag, data archival, session termination, access revocation, audit trail creation, notification sending',
                                'auth': 'Admin',
                                'mapped_story': story_id
                            })
                        processed_stories.add(story_id)
                    
                    # Role assignment endpoint
                    if any(term in story_text for term in ['role', 'permission', 'access', 'assign', 'grant', 'admin', 'privilege']):
                        if not any(api['endpoint'] == '/api/users/{id}/roles' for api in apis):
                            apis.append({
                                'method': 'PUT',
                                'endpoint': '/api/users/{id}/roles',
                                'description': 'Assign or update user roles and associated permissions',
                                'business_logic': 'Role validation, permission hierarchy checking, access control recalculation, immediate session effect, change history tracking',
                                'auth': 'Admin',
                                'mapped_story': story_id
                            })
                        processed_stories.add(story_id)
                
                # ========== TRANSACTION/ORDER COMPONENT APIS ==========
                elif is_transaction_component:
                    # Create order/transaction
                    if any(term in story_text for term in ['create', 'place', 'submit', 'new order', 'checkout', 'purchase']):
                        if not any(api['endpoint'] == '/api/orders' and api['method'] == 'POST' for api in apis):
                            apis.append({
                                'method': 'POST',
                                'endpoint': '/api/orders',
                                'description': 'Create new order/transaction with items, pricing and payment details',
                                'business_logic': 'Item validation, inventory availability check, pricing calculation with taxes/discounts, payment processing, order confirmation, notification',
                                'auth': 'Required',
                                'mapped_story': story_id
                            })
                        processed_stories.add(story_id)
                    
                    # List orders/transactions
                    if any(term in story_text for term in ['list', 'view', 'retrieve', 'history', 'transaction history', 'order history']):
                        if not any(api['endpoint'] == '/api/orders' and api['method'] == 'GET' for api in apis):
                            apis.append({
                                'method': 'GET',
                                'endpoint': '/api/orders',
                                'description': 'Retrieve paginated order/transaction history with filters and search',
                                'business_logic': 'Filter by status/date-range/amount/customer, pagination, sorting, access control, performance optimization with caching',
                                'auth': 'Required',
                                'mapped_story': story_id
                            })
                        processed_stories.add(story_id)
                    
                    # Payment processing
                    if any(term in story_text for term in ['payment', 'pay', 'charge', 'invoice', 'billing', 'process payment']):
                        if not any(api['endpoint'] == '/api/orders/{id}/payment' for api in apis):
                            apis.append({
                                'method': 'POST',
                                'endpoint': '/api/orders/{id}/payment',
                                'description': 'Process payment for order with multiple payment methods',
                                'business_logic': 'Payment method validation, amount verification, payment gateway integration (Stripe/PayPal), receipt generation, invoice creation',
                                'auth': 'Required',
                                'mapped_story': story_id
                            })
                        processed_stories.add(story_id)
                    
                    # Update order status
                    if any(term in story_text for term in ['status', 'track', 'update', 'confirm', 'ship', 'deliver', 'cancel']):
                        if not any(api['endpoint'] == '/api/orders/{id}' and api['method'] == 'PUT' for api in apis):
                            apis.append({
                                'method': 'PUT',
                                'endpoint': '/api/orders/{id}',
                                'description': 'Update order status, shipping info or cancellation with notifications',
                                'business_logic': 'Status transition validation, workflow checking, inventory updates, shipping integration, customer notification, audit logging',
                                'auth': 'Required',
                                'mapped_story': story_id
                            })
                        processed_stories.add(story_id)
                
                # ========== DASHBOARD/ANALYTICS COMPONENT APIS ==========
                elif is_dashboard_component:
                    # Metrics endpoint
                    if any(term in story_text for term in ['metric', 'stat', 'summary', 'overview', 'dashboard', 'kpi']):
                        if not any(api['endpoint'] == '/api/dashboard/metrics' for api in apis):
                            apis.append({
                                'method': 'GET',
                                'endpoint': '/api/dashboard/metrics',
                                'description': 'Get key business metrics and KPIs with real-time data',
                                'business_logic': 'Data aggregation from sources, metric calculation, date-range filtering, caching strategy (5min), real-time data push via WebSocket',
                                'auth': 'Required',
                                'mapped_story': story_id
                            })
                        processed_stories.add(story_id)
                    
                    # Analytics/Chart data
                    if any(term in story_text for term in ['chart', 'graph', 'report', 'analytics', 'trend', 'visualization']):
                        if not any(api['endpoint'] == '/api/dashboard/analytics' for api in apis):
                            apis.append({
                                'method': 'GET',
                                'endpoint': '/api/dashboard/analytics',
                                'description': 'Get aggregated analytics data for charts and visualizations',
                                'business_logic': 'Time-series data retrieval, grouping (daily/weekly/monthly), aggregation functions (sum/avg/count), trend calculation, performance optimization',
                                'auth': 'Required',
                                'mapped_story': story_id
                            })
                        processed_stories.add(story_id)
                    
                    # Export/Download data
                    if any(term in story_text for term in ['export', 'download', 'report', 'csv', 'pdf', 'excel']):
                        if not any(api['endpoint'] == '/api/dashboard/export' for api in apis):
                            apis.append({
                                'method': 'GET',
                                'endpoint': '/api/dashboard/export',
                                'description': 'Export dashboard data as CSV, PDF or Excel with formatting',
                                'business_logic': 'Data formatting, file generation, file streaming, audit logging of exports, temporary file cleanup',
                                'auth': 'Required',
                                'mapped_story': story_id
                            })
                        processed_stories.add(story_id)
            
            # Remove duplicates and keep unique APIs by endpoint+method
            seen = set()
            unique_apis = []
            for api in apis:
                endpoint_key = f"{api['method']}:{api['endpoint']}"
                if endpoint_key not in seen:
                    seen.add(endpoint_key)
                    unique_apis.append(api)
            
            # Keep top 6-8 most relevant/detailed APIs
            unique_apis = unique_apis[:8]
            
            if not unique_apis:
                return f"N/A - {comp_orig_name} does not have mapped user stories requiring specific API endpoints."
            
            # Generate enhanced table with all columns including mapped story
            table = "| Method | Endpoint | Description | Business Logic | Auth | Mapped Story |\n"
            table += "|--------|----------|-------------|----------------|------|---------------|\n"
            for api in unique_apis:
                mapped_story = api.get('mapped_story', 'N/A')
                # Truncate long mapped story names
                if len(mapped_story) > 40:
                    mapped_story = mapped_story[:37] + "..."
                table += f"| {api['method']} | {api['endpoint']} | {api['description']} | {api['business_logic']} | {api.get('auth', 'Required')} | {mapped_story} |\n"
            
            return table
        
        def generate_ui_table(component: Dict[str, Any], analysis: Dict[str, Any], stories: List[Dict[str, Any]]) -> str:
            """
            Generate SMART, STORY-DRIVEN UI modules specific to THIS component.
            âš ï¸ Enhanced: Extracts specific requirements from mapped stories to generate sophisticated UI.
            Not just generic forms - generates UI based on actual story needs.
            """
            if not analysis['has_ui']:
                return "N/A - This component does not have user-facing UI modules."
            
            comp_name = component.get('name', '')
            comp_desc = component.get('description', '').lower()
            comp_orig_name = comp_name
            comp_name_lower = comp_name.lower()
            
            # Only frontend components should have UI modules
            if 'frontend' not in comp_name_lower and 'interface' not in comp_desc and 'ui' not in comp_desc:
                return f"N/A - {comp_name} is not a frontend component and does not require UI modules."
            
            # Determine component type for UI generation
            is_auth_frontend = 'auth' in comp_name_lower or 'login' in comp_desc or 'signin' in comp_desc
            is_dashboard_frontend = 'dashboard' in comp_name_lower or 'analytics' in comp_name_lower or 'report' in comp_name_lower
            is_admin_frontend = 'admin' in comp_name_lower or 'management' in comp_desc or 'console' in comp_name_lower
            is_user_frontend = 'user' in comp_name_lower or 'profile' in comp_name_lower or 'account' in comp_name_lower
            
            # Map and analyze relevant stories
            mapped_stories = []
            for story in stories:
                story_title = story.get('title', '').lower()
                story_desc = story.get('description', '').lower()
                story_text = f"{story_title} {story_desc}"
                
                component_keywords = set(comp_name_lower.split()) | set(comp_desc.split())
                story_keywords = set(story_text.split())
                common_count = len(component_keywords & story_keywords)
                
                if common_count > 0 or any(keyword in story_text for keyword in ['ui', 'form', 'page', 'screen', 'interface', 'display']):
                    mapped_stories.append({
                        'title': story.get('title', ''),
                        'description': story.get('description', ''),
                        'text': story_text,
                        'relevance': common_count
                    })
            
            mapped_stories = sorted(mapped_stories, key=lambda x: x['relevance'], reverse=True)
            
            modules = []
            processed_modules = set()
            
            # âš ï¸ ENHANCED: Extract specific UI requirements from mapped stories
            for story in mapped_stories[:10]:
                story_title = story['title'].lower()
                story_text = story['text']
                
                # ========== AUTHENTICATION FRONTEND UI ==========
                if is_auth_frontend:
                    # Login form
                    if any(term in story_text for term in ['login', 'signin', 'authenticate', 'credential']):
                        if 'LoginForm' not in processed_modules:
                            modules.append({
                                'module_name': 'LoginForm',
                                'type': 'Functional Component',
                                'responsibility': 'User login form with email/username, password, remember-me checkbox, and forgot password link',
                                'mapped_story': story['title'],
                                'state_management': 'Local State + Form Validation + Error Handling',
                                'features': 'Email validation, password visibility toggle, loading state, error messages'
                            })
                            processed_modules.add('LoginForm')
                    
                    # Registration form
                    if any(term in story_text for term in ['register', 'signup', 'create account', 'new user', 'sign up']):
                        if 'RegistrationForm' not in processed_modules:
                            modules.append({
                                'module_name': 'RegistrationForm',
                                'type': 'Functional Component',
                                'responsibility': 'New user registration form with email, password, confirm password, and terms acceptance',
                                'mapped_story': story['title'],
                                'state_management': 'Local State + Form Validation + Password Strength',
                                'features': 'Email validation, password strength meter, confirmation match, terms checkbox, real-time validation'
                            })
                            processed_modules.add('RegistrationForm')
                    
                    # Password reset form
                    if any(term in story_text for term in ['password', 'reset', 'forgot', 'recover']):
                        if 'PasswordResetForm' not in processed_modules:
                            modules.append({
                                'module_name': 'PasswordResetForm',
                                'type': 'Functional Component',
                                'responsibility': 'Multi-step password reset with email verification and new password confirmation',
                                'mapped_story': story['title'],
                                'state_management': 'Local State + Step Navigation + Form Validation',
                                'features': 'Email input, OTP verification, new password input, progress indicator, submit tracking'
                            })
                            processed_modules.add('PasswordResetForm')
                    
                    # MFA setup component
                    if any(term in story_text for term in ['mfa', 'two-factor', 'otp', 'authenticator', '2fa']):
                        if 'MFASetup' not in processed_modules:
                            modules.append({
                                'module_name': 'MFASetup',
                                'type': 'Container Component',
                                'responsibility': 'MFA configuration with QR code display, backup codes generation and management',
                                'mapped_story': story['title'],
                                'state_management': 'Redux/Context + API Integration + Local State',
                                'features': 'QR code display, backup code generation, copy-to-clipboard, MFA method selection, verification step'
                            })
                            processed_modules.add('MFASetup')
                
                # ========== DASHBOARD/ANALYTICS FRONTEND UI ==========
                elif is_dashboard_frontend:
                    # Dashboard metrics display
                    if any(term in story_text for term in ['metric', 'stat', 'summary', 'kpi', 'overview']):
                        if 'MetricsDisplay' not in processed_modules:
                            modules.append({
                                'module_name': 'MetricsDisplay',
                                'type': 'Container Component',
                                'responsibility': 'Display key business metrics and KPIs with real-time updates and sparkline charts',
                                'mapped_story': story['title'],
                                'state_management': 'Redux/Context + Real-time WebSocket + Caching',
                                'features': 'Real-time metrics, trend indicators, sparklines, comparison with previous period, drill-down capability'
                            })
                            processed_modules.add('MetricsDisplay')
                    
                    # Charts and graphs
                    if any(term in story_text for term in ['chart', 'graph', 'visualization', 'trend', 'analytics']):
                        if 'ChartVisualization' not in processed_modules:
                            modules.append({
                                'module_name': 'ChartVisualization',
                                'type': 'Container Component',
                                'responsibility': 'Interactive charts (line, bar, pie, area) with data filtering, zoom and export functionality',
                                'mapped_story': story['title'],
                                'state_management': 'Redux/Context + API Integration + Chart Library',
                                'features': 'Multiple chart types, date-range selector, interactive legend, export as image, tooltip hover'
                            })
                            processed_modules.add('ChartVisualization')
                    
                    # Dashboard layout
                    if any(term in story_text for term in ['dashboard', 'layout', 'view', 'display', 'screen']):
                        if 'DashboardLayout' not in processed_modules:
                            modules.append({
                                'module_name': 'DashboardLayout',
                                'type': 'Container Component',
                                'responsibility': 'Main dashboard layout with grid system, widget management and responsive grid',
                                'mapped_story': story['title'],
                                'state_management': 'Redux/Context + Local Storage (widget positions)',
                                'features': 'Draggable widgets, responsive grid, save layout, filter controls, time period selector, refresh button'
                            })
                            processed_modules.add('DashboardLayout')
                    
                    # Export/Download component
                    if any(term in story_text for term in ['export', 'download', 'report', 'csv', 'pdf']):
                        if 'ExportDialog' not in processed_modules:
                            modules.append({
                                'module_name': 'ExportDialog',
                                'type': 'Functional Component',
                                'responsibility': 'Modal dialog for exporting data in multiple formats (CSV, PDF, Excel)',
                                'mapped_story': story['title'],
                                'state_management': 'Local State + API Integration',
                                'features': 'Format selection, date-range picker, column selector, scheduled reports option, download progress'
                            })
                            processed_modules.add('ExportDialog')
                
                # ========== ADMIN/MANAGEMENT FRONTEND UI ==========
                elif is_admin_frontend:
                    # User list table
                    if any(term in story_text for term in ['list', 'view', 'display', 'browse', 'manage', 'user']):
                        if 'UserManagementTable' not in processed_modules:
                            modules.append({
                                'module_name': 'UserManagementTable',
                                'type': 'Container Component',
                                'responsibility': 'Sortable and filterable user management table with bulk actions and inline editing',
                                'mapped_story': story['title'],
                                'state_management': 'Redux/Context + API Integration + Pagination',
                                'features': 'Search/filter, sorting, pagination, checkboxes, inline edit, bulk actions, role indicators, status badges'
                            })
                            processed_modules.add('UserManagementTable')
                    
                    # Create/Edit form
                    if any(term in story_text for term in ['create', 'add', 'edit', 'form', 'new', 'onboard']):
                        if 'UserFormDialog' not in processed_modules:
                            modules.append({
                                'module_name': 'UserFormDialog',
                                'type': 'Functional Component',
                                'responsibility': 'Modal form for creating or editing user with role assignment and validation',
                                'mapped_story': story['title'],
                                'state_management': 'Local State + Form Validation + API Integration',
                                'features': 'Form fields validation, role multi-select, department picker, email verification, submit/cancel buttons'
                            })
                            processed_modules.add('UserFormDialog')
                    
                    # Settings/Configuration panel
                    if any(term in story_text for term in ['setting', 'config', 'configuration', 'preference', 'admin']):
                        if 'AdminSettingsPanel' not in processed_modules:
                            modules.append({
                                'module_name': 'AdminSettingsPanel',
                                'type': 'Container Component',
                                'responsibility': 'Admin settings and configuration management with tabs for different setting categories',
                                'mapped_story': story['title'],
                                'state_management': 'Redux/Context + API Integration + Local State',
                                'features': 'Tabbed interface, real-time validation, toggle switches, input fields, save/cancel buttons, confirmation dialogs'
                            })
                            processed_modules.add('AdminSettingsPanel')
                
                # ========== USER PROFILE/ACCOUNT FRONTEND UI ==========
                elif is_user_frontend:
                    # Profile view
                    if any(term in story_text for term in ['profile', 'view', 'account', 'detail', 'information']):
                        if 'UserProfileView' not in processed_modules:
                            modules.append({
                                'module_name': 'UserProfileView',
                                'type': 'Container Component',
                                'responsibility': 'User profile display with editable fields and profile picture management',
                                'mapped_story': story['title'],
                                'state_management': 'Redux/Context + API Integration + Local State',
                                'features': 'Profile info display, edit mode toggle, profile picture upload, save changes, field validation'
                            })
                            processed_modules.add('UserProfileView')
                    
                    # Account settings
                    if any(term in story_text for term in ['setting', 'preference', 'account', 'configuration', 'security']):
                        if 'AccountSettings' not in processed_modules:
                            modules.append({
                                'module_name': 'AccountSettings',
                                'type': 'Container Component',
                                'responsibility': 'Account settings with password change, email preferences and privacy controls',
                                'mapped_story': story['title'],
                                'state_management': 'Redux/Context + API Integration',
                                'features': 'Password change form, email preferences checkboxes, privacy toggles, notification settings, save button'
                            })
                            processed_modules.add('AccountSettings')
                
                # ========== GENERIC UI COMPONENTS (All frontend types) ==========
                # Data table component
                if any(term in story_text for term in ['list', 'table', 'data', 'display', 'show', 'browse', 'view']):
                    if 'DataTable' not in processed_modules and 'UserManagementTable' not in processed_modules:
                        modules.append({
                            'module_name': 'DataTable',
                            'type': 'Container Component',
                            'responsibility': 'Reusable data table with sorting, filtering, pagination and selection support',
                            'mapped_story': story['title'],
                            'state_management': 'Redux/Context + API Integration + Pagination State',
                            'features': 'Multi-sort, column filters, search, pagination, row selection, bulk actions, column resizing'
                        })
                        processed_modules.add('DataTable')
                
                # Form component
                if any(term in story_text for term in ['form', 'create', 'edit', 'add', 'input', 'submit']):
                    if 'FormBuilder' not in processed_modules and 'UserFormDialog' not in processed_modules:
                        modules.append({
                            'module_name': 'FormBuilder',
                            'type': 'Container Component',
                            'responsibility': 'Reusable form builder with field validation, error display and submission handling',
                            'mapped_story': story['title'],
                            'state_management': 'Local State + Form Validation Library',
                            'features': 'Dynamic fields, validation rules, error messages, required field indicators, submit tracking, auto-save'
                        })
                        processed_modules.add('FormBuilder')
            
            if not modules:
                return f"N/A - No specific UI modules could be mapped from provided user stories for {comp_orig_name}."
            
            # Remove duplicates and keep top 6 modules
            unique_modules = []
            seen_names = set()
            for module in modules:
                if module['module_name'] not in seen_names:
                    seen_names.add(module['module_name'])
                    unique_modules.append(module)
            
            unique_modules = unique_modules[:6]
            
            # Generate enhanced table
            table = "| Module Name | Type | Responsibility | Mapped Story | State Mgmt | Features |\n"
            table += "|-------------|------|----------------|--------------|-----------|----------|\n"
            for module in unique_modules:
                mapped_story = module.get('mapped_story', 'N/A')
                if len(mapped_story) > 25:
                    mapped_story = mapped_story[:22] + "..."
                state_mgmt = module.get('state_management', 'Local State').replace(' + ', '/<br>')
                features = module.get('features', 'Standard')
                if len(features) > 30:
                    features = features[:27] + "..."
                table += f"| {module['module_name']} | {module['type']} | {module['responsibility']} | {mapped_story} | {state_mgmt} | {features} |\n"
            
            return table
        
        def generate_sql_schema(component: Dict[str, Any], analysis: Dict[str, Any], stories: List[Dict[str, Any]]) -> str:
            """
            Generate SMART, STORY-DRIVEN SQL schema specific to THIS component.
            âš ï¸ Enhanced: Extracts specific data requirements from mapped stories.
            Only generates tables required by mapped user stories and component functionality.
            """
            if not analysis['stores_data']:
                return """N/A - This component does not directly interact with database storage."""
            
            comp_name = component.get('name', '')
            comp_name_lower = comp_name.lower()
            comp_desc = component.get('description', '').lower()
            
            # Only database components or backend services should have SQL schemas
            if 'database' not in comp_name_lower and 'db' not in comp_name_lower and 'storage' not in comp_desc and component.get('type') == 'frontend':
                return f"N/A - {comp_name} is a frontend component and does not have database storage."
            
            # âš ï¸ ENHANCED: Extract ONLY entities relevant to THIS component from MAPPED stories
            mapped_entities = {}  # entity_name -> {fields, relationships, mapped_stories}
            
            # Map and analyze relevant stories
            mapped_stories = []
            component_keywords = set(comp_name_lower.split()) | set(comp_desc.split())
            
            for story in stories:
                story_title = story.get('title', '').lower()
                story_desc = story.get('description', '').lower()
                story_text = f"{story_title} {story_desc}"
                
                story_keywords = set(story_text.split())
                common_count = len(component_keywords & story_keywords)
                
                if common_count > 0 or any(keyword in story_text for keyword in ['database', 'data', 'store', 'persist', 'save']):
                    mapped_stories.append({
                        'title': story.get('title', ''),
                        'description': story.get('description', ''),
                        'text': story_text,
                        'relevance': common_count
                    })
            
            mapped_stories = sorted(mapped_stories, key=lambda x: x['relevance'], reverse=True)
            
            # âš ï¸ ENHANCED: Extract specific data requirements from stories
            for story in mapped_stories[:8]:  # Top 8 relevant stories
                story_title = story['title'].lower()
                story_text = story['text']
                
                # ========== AUTHENTICATION DATA SCHEMA ==========
                if any(term in story_text for term in ['login', 'auth', 'signin', 'register', 'password']):
                    # Users table
                    if 'user' not in mapped_entities:
                        mapped_entities['user'] = {
                            'fields': [
                                ('id', 'SERIAL PRIMARY KEY'),
                                ('username', 'VARCHAR(100) UNIQUE NOT NULL'),
                                ('email', 'VARCHAR(255) UNIQUE NOT NULL'),
                                ('password_hash', 'VARCHAR(255) NOT NULL'),
                                ('first_name', 'VARCHAR(100)'),
                                ('last_name', 'VARCHAR(100)'),
                                ('phone', 'VARCHAR(20)'),
                                ('status', "VARCHAR(50) DEFAULT 'active'"),
                                ('role', "VARCHAR(50) DEFAULT 'user'"),
                                ('last_login', 'TIMESTAMP'),
                                ('is_mfa_enabled', 'BOOLEAN DEFAULT FALSE'),
                                ('created_at', 'TIMESTAMP DEFAULT NOW()'),
                                ('updated_at', 'TIMESTAMP DEFAULT NOW()')
                            ],
                            'indexes': ['email', 'status', 'role'],
                            'mapped_stories': [story['title']]
                        }
                    
                    # Authentication sessions/tokens
                    if 'auth_session' not in mapped_entities:
                        mapped_entities['auth_session'] = {
                            'fields': [
                                ('id', 'SERIAL PRIMARY KEY'),
                                ('user_id', 'INTEGER NOT NULL REFERENCES users(id) ON DELETE CASCADE'),
                                ('token_hash', 'VARCHAR(255) NOT NULL UNIQUE'),
                                ('refresh_token_hash', 'VARCHAR(255) UNIQUE'),
                                ('token_type', "VARCHAR(50) DEFAULT 'Bearer'"),
                                ('expires_at', 'TIMESTAMP NOT NULL'),
                                ('refresh_expires_at', 'TIMESTAMP'),
                                ('is_active', 'BOOLEAN DEFAULT TRUE'),
                                ('ip_address', 'VARCHAR(45)'),
                                ('user_agent', 'TEXT'),
                                ('created_at', 'TIMESTAMP DEFAULT NOW()'),
                                ('last_used_at', 'TIMESTAMP DEFAULT NOW()')
                            ],
                            'indexes': ['user_id', 'token_hash', 'expires_at'],
                            'mapped_stories': [story['title']]
                        }
                    
                    # MFA data
                    if any(term in story_text for term in ['mfa', 'two-factor', 'otp']):
                        if 'mfa_configuration' not in mapped_entities:
                            mapped_entities['mfa_configuration'] = {
                                'fields': [
                                    ('id', 'SERIAL PRIMARY KEY'),
                                    ('user_id', 'INTEGER NOT NULL REFERENCES users(id) ON DELETE CASCADE'),
                                    ('method', "VARCHAR(50) NOT NULL"),  # 'totp', 'sms', 'email'
                                    ('secret_key', 'VARCHAR(255)'),  # For TOTP
                                    ('backup_codes', 'TEXT'),  # JSON array of backup codes
                                    ('is_verified', 'BOOLEAN DEFAULT FALSE'),
                                    ('verified_at', 'TIMESTAMP'),
                                    ('created_at', 'TIMESTAMP DEFAULT NOW()')
                                ],
                                'indexes': ['user_id'],
                                'mapped_stories': [story['title']]
                            }
                
                # ========== USER PROFILE/ACCOUNT DATA ==========
                elif any(term in story_text for term in ['profile', 'account', 'user management', 'manage user']):
                    if 'user_profile' not in mapped_entities:
                        mapped_entities['user_profile'] = {
                            'fields': [
                                ('id', 'SERIAL PRIMARY KEY'),
                                ('user_id', 'INTEGER NOT NULL REFERENCES users(id) ON DELETE CASCADE'),
                                ('full_name', 'VARCHAR(255)'),
                                ('avatar_url', 'TEXT'),
                                ('bio', 'TEXT'),
                                ('phone', 'VARCHAR(20)'),
                                ('department', 'VARCHAR(100)'),
                                ('designation', 'VARCHAR(100)'),
                                ('location', 'VARCHAR(255)'),
                                ('timezone', "VARCHAR(50) DEFAULT 'UTC'"),
                                ('preferences', 'JSONB'),  # Notification, UI, etc.
                                ('created_at', 'TIMESTAMP DEFAULT NOW()'),
                                ('updated_at', 'TIMESTAMP DEFAULT NOW()')
                            ],
                            'indexes': ['user_id'],
                            'mapped_stories': [story['title']]
                        }
                    
                    # User roles and permissions
                    if 'user_role' not in mapped_entities and any(term in story_text for term in ['role', 'permission', 'access', 'admin']):
                        mapped_entities['user_role'] = {
                            'fields': [
                                ('id', 'SERIAL PRIMARY KEY'),
                                ('user_id', 'INTEGER NOT NULL REFERENCES users(id) ON DELETE CASCADE'),
                                ('role_name', 'VARCHAR(100) NOT NULL'),
                                ('permissions', 'JSONB'),  # JSON array of permissions
                                ('assigned_at', 'TIMESTAMP DEFAULT NOW()'),
                                ('assigned_by', 'INTEGER REFERENCES users(id)')
                            ],
                            'indexes': ['user_id', 'role_name'],
                            'mapped_stories': [story['title']]
                        }
                
                # ========== TRANSACTION/ORDER DATA ==========
                elif any(term in story_text for term in ['order', 'transaction', 'payment', 'purchase', 'billing']):
                    if 'order' not in mapped_entities:
                        mapped_entities['order'] = {
                            'fields': [
                                ('id', 'SERIAL PRIMARY KEY'),
                                ('user_id', 'INTEGER REFERENCES users(id)'),
                                ('order_number', 'VARCHAR(50) UNIQUE NOT NULL'),
                                ('total_amount', 'DECIMAL(12, 2) NOT NULL'),
                                ('subtotal', 'DECIMAL(12, 2)'),
                                ('tax_amount', 'DECIMAL(12, 2)'),
                                ('discount_amount', 'DECIMAL(12, 2)'),
                                ('shipping_cost', 'DECIMAL(12, 2)'),
                                ('status', "VARCHAR(50) DEFAULT 'pending'"),  # pending, confirmed, shipped, delivered, cancelled
                                ('order_date', 'TIMESTAMP DEFAULT NOW()'),
                                ('delivery_date', 'TIMESTAMP'),
                                ('payment_method', 'VARCHAR(50)'),
                                ('notes', 'TEXT'),
                                ('created_at', 'TIMESTAMP DEFAULT NOW()'),
                                ('updated_at', 'TIMESTAMP DEFAULT NOW()')
                            ],
                            'indexes': ['user_id', 'status', 'order_date'],
                            'mapped_stories': [story['title']]
                        }
                    
                    if 'transaction' not in mapped_entities:
                        mapped_entities['transaction'] = {
                            'fields': [
                                ('id', 'SERIAL PRIMARY KEY'),
                                ('order_id', 'INTEGER REFERENCES orders(id)'),
                                ('user_id', 'INTEGER REFERENCES users(id)'),
                                ('amount', 'DECIMAL(12, 2) NOT NULL'),
                                ('status', "VARCHAR(50) DEFAULT 'pending'"),  # pending, completed, failed, refunded
                                ('payment_method', 'VARCHAR(50) NOT NULL'),
                                ('payment_gateway', 'VARCHAR(100)'),
                                ('reference_id', 'VARCHAR(255) UNIQUE'),
                                ('gateway_response', 'JSONB'),
                                ('error_message', 'TEXT'),
                                ('retry_count', 'INTEGER DEFAULT 0'),
                                ('created_at', 'TIMESTAMP DEFAULT NOW()'),
                                ('processed_at', 'TIMESTAMP')
                            ],
                            'indexes': ['order_id', 'user_id', 'status', 'created_at'],
                            'mapped_stories': [story['title']]
                        }
                
                # ========== PRODUCT/INVENTORY DATA ==========
                elif any(term in story_text for term in ['product', 'inventory', 'catalog', 'item']):
                    if 'product' not in mapped_entities:
                        mapped_entities['product'] = {
                            'fields': [
                                ('id', 'SERIAL PRIMARY KEY'),
                                ('product_code', 'VARCHAR(100) UNIQUE NOT NULL'),
                                ('name', 'VARCHAR(255) NOT NULL'),
                                ('description', 'TEXT'),
                                ('category', 'VARCHAR(100)'),
                                ('sku', 'VARCHAR(100) UNIQUE NOT NULL'),
                                ('price', 'DECIMAL(12, 2) NOT NULL'),
                                ('cost_price', 'DECIMAL(12, 2)'),
                                ('quantity_available', 'INTEGER DEFAULT 0'),
                                ('quantity_reserved', 'INTEGER DEFAULT 0'),
                                ('reorder_level', 'INTEGER'),
                                ('status', "VARCHAR(50) DEFAULT 'active'"),
                                ('image_url', 'TEXT'),
                                ('created_at', 'TIMESTAMP DEFAULT NOW()'),
                                ('updated_at', 'TIMESTAMP DEFAULT NOW()')
                            ],
                            'indexes': ['sku', 'category', 'status'],
                            'mapped_stories': [story['title']]
                        }
                
                # ========== DASHBOARD/ANALYTICS DATA ==========
                elif any(term in story_text for term in ['dashboard', 'analytics', 'report', 'metric', 'statistics']):
                    if 'audit_log' not in mapped_entities:
                        mapped_entities['audit_log'] = {
                            'fields': [
                                ('id', 'SERIAL PRIMARY KEY'),
                                ('user_id', 'INTEGER REFERENCES users(id)'),
                                ('action', 'VARCHAR(100) NOT NULL'),
                                ('entity_type', 'VARCHAR(100)'),
                                ('entity_id', 'INTEGER'),
                                ('old_values', 'JSONB'),
                                ('new_values', 'JSONB'),
                                ('ip_address', 'VARCHAR(45)'),
                                ('user_agent', 'TEXT'),
                                ('created_at', 'TIMESTAMP DEFAULT NOW()')
                            ],
                            'indexes': ['user_id', 'created_at', 'entity_type'],
                            'mapped_stories': [story['title']]
                        }
            
            # If no specific entities mapped from stories, return N/A
            if not mapped_entities:
                return f"N/A - No specific database entities could be mapped for {comp_name} from provided user stories."
            
            # âš ï¸ ENHANCED: Generate focused database schema with ONLY component-relevant tables
            result = f"""**Database Schema for {comp_name}:**

**Mapped Stories**: {', '.join([s['title'][:30] + '...' if len(s['title']) > 30 else s['title'] for s in mapped_stories[:3]])}

"""
            
            for entity_name in list(mapped_entities.keys())[:5]:  # Limit to 5 tables
                entity_data = mapped_entities[entity_name]
                table_name = entity_name if entity_name.endswith('s') or entity_name.endswith('log') else entity_name + 's'
                
                result += f"""**Table: {table_name.upper()}**

```sql
CREATE TABLE {table_name} (
"""
                
                for field_name, field_type in entity_data['fields']:
                    result += f"    {field_name} {field_type},\n"
                
                result = result.rstrip(',\n') + "\n);\n"
                
                # Add indexes
                for idx_field in entity_data.get('indexes', []):
                    result += f"CREATE INDEX idx_{table_name}_{idx_field} ON {table_name}({idx_field});\n"
                
                result += "```\n\n"
            
            result += f"""**Data Relationships**:
- User authentication and session management ensure secure access control
- User roles enable fine-grained permission management
- Transaction tracking provides audit trail and financial reconciliation
- Timestamps on all tables enable temporal analysis and compliance

**Key Design Principles for {comp_name}:**
- Normalized schema minimizes data redundancy
- Foreign key constraints maintain referential integrity
- Strategic indexing optimizes query performance for common operations
- JSONB fields provide flexibility for semi-structured data
- Audit logging ensures compliance and security tracking"""
            
            return result
        
        # ðŸ”´ CRITICAL: Check if we have components to work with
        print(f"ðŸ”´ [LLD] About to generate LLD with {len(system_components)} components and {len(user_stories)} user stories")
        
        # ðŸ”´ NEW: Generate AI-powered intelligent LLD content based on components
        print(f"ðŸ”´ [LLD] Calling OpenAI to generate intelligent LLD content...")
        
        try:
            # Prepare component and user story context for AI
            comp_context = "## System Components:\n"
            for comp in system_components:
                comp_context += f"\n- **{comp.get('name')}** ({comp.get('type')})\n"
                comp_context += f"  Description: {comp.get('description', 'N/A')}\n"
                comp_context += f"  Technologies: {', '.join(comp.get('technologies', ['N/A']))}\n"
            
            stories_context = "## User Stories:\n"
            for story in user_stories[:10]:  # Limit to first 10 for context
                stories_context += f"\n- **{story.get('id', 'US')}**: {story.get('title', 'N/A')}\n"
                if story.get('description'):
                    stories_context += f"  {story['description']}\n"
            
            # Create prompt for OpenAI
            prompt = f"""You are an expert Low-Level Design (LLD) document generator for software architecture.

Generate comprehensive, context-aware Component-Wise LLD documentation based on these system components and requirements:

{comp_context}

{stories_context}

### Task:
For EACH component, generate a complete 12-section LLD entry with the following structure:

## Component: [Component Name]

### 1. Purpose & Overview
[Clear description of the component's purpose, why it's needed, and what it does]

### 2. Responsibilities & Scope
[List 3-5 key responsibilities and functional scope]

### 3. Technical Architecture
[Describe the architecture pattern, design principles, and technology choices]

### 4. API Endpoints / Interfaces
[For backend/service components: list 5-7 key endpoints with HTTP methods and purposes]
[For frontend: describe key page routes and components]
[For database: describe main entities and relationships]

### 5. Data Models & Schema
[Describe the data structures, key entities, and their relationships]

### 6. Integration Points
[List external systems, services, and components this integrates with]

### 7. Security & Authorization
[Describe authentication, authorization, validation, and security measures]

### 8. Error Handling & Edge Cases
[List common error scenarios and how they're handled]

### 9. Performance & Scalability
[Describe caching, optimization, and scalability considerations]

### 10. Testing Strategy
[Describe unit tests, integration tests, and test coverage approach]

### 11. Deployment & DevOps
[Describe deployment process, environment variables, and monitoring]

### 12. Maintenance & Monitoring
[Describe logging, monitoring, alerts, and maintenance procedures]

---

Generate the LLD content for ALL {len(system_components)} components. Make it detailed, technical, and production-ready. 
Include specific technology choices, best practices, and consider the user stories and epics provided."""
            
            # Call OpenAI
            response = await self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system",
                        "content": "You are an expert Low-Level Design document generator. Generate comprehensive, detailed, and production-ready LLD documentation in markdown format."
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=4000
            )
            
            ai_generated_content = response.choices[0].message.content.strip()
            print(f"ðŸŸ¢ [LLD] OpenAI generated {len(ai_generated_content)} characters of intelligent LLD content")
            
            # Build final document with AI content
            document = f"""# Component-Wise Low-Level Design (LLD)

**Project**: {project_name}
**Generated**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**Total Components**: {len(system_components)}
**User Stories**: {len(user_stories)}
**Generation Method**: AI-Powered Intelligent Design

## Document Overview

This document provides comprehensive low-level design specifications for each system component. It includes 12 detailed sections per component covering all aspects of implementation, from purpose and design to deployment and monitoring. All content has been intelligently generated using AI analysis of system requirements and architecture.

---

{ai_generated_content}

---

## Appendix: Technical Summary

**Components**: {len(system_components)}
**User Stories**: {len(user_stories)}
**Epics**: {len(epics)}
**Generation Timestamp**: {datetime.now().isoformat()}

Generated with AI-powered intelligent content generation for technical accuracy and implementation readiness."""
            
        except Exception as e:
            print(f"ðŸ”´ [LLD] OpenAI generation failed: {str(e)}, falling back to template-based generation")
            
            # Fallback to template generation if AI fails
            document = f"""# Component-Wise Low-Level Design (LLD)

**Project**: {project_name}
**Generated**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**Total Components**: {len(system_components)}
**User Stories**: {len(user_stories)}

## Document Overview

This document provides comprehensive low-level design specifications for each system component. Each component includes 12 detailed sections covering all aspects of implementation, from purpose and design to deployment and monitoring.

### Component Summary

| Component | Type | Stories | Tech Stack | Layer |
|-----------|------|---------|-----------|--------|"""

        # Add component summary
        for comp in system_components:
            analysis = analyze_component(comp)
            mapped_stories = map_stories_to_component(comp, user_stories)
            tech_stack = ', '.join(comp.get('technologies', ['Not specified'])[:2])
            layer = 'Frontend' if analysis['is_frontend'] else 'Backend' if analysis['is_backend'] else 'Database' if analysis['is_database'] else 'Infrastructure'
            
            document += f"""
| {comp.get('name', 'Unknown')} | {comp.get('type', 'Unknown')} | {len(mapped_stories)} | {tech_stack} | {layer} |"""

        document += """

---

## Component Specifications

*Each component follows the complete 12-section LLD structure with proper formatting and relevant content.*

"""

        # Generate detailed sections for each component
        for idx, component in enumerate(system_components, 1):
            comp_name = component.get('name', f'Component {idx}')
            comp_type = component.get('type', 'Unknown')
            comp_desc = component.get('description', 'No description available')
            
            analysis = analyze_component(component)
            mapped_stories = map_stories_to_component(component, user_stories)
            
            document += f"""## Component {idx}: {comp_name}

**Type**: {comp_type}
**Technology**: {', '.join(component.get('technologies', ['Not specified']))}
**Architecture Layer**: {'Frontend' if analysis['is_frontend'] else 'Backend' if analysis['is_backend'] else 'Database' if analysis['is_database'] else 'Infrastructure'}

### 1. Purpose

{comp_name} serves as {comp_desc}.

### 2. Mapped User Stories
"""
            
            # Add mapped stories with Epic grouping
            if mapped_stories:
                epic_map = {}
                epic_counter = 1
                
                for story in mapped_stories:
                    story_title = story.get('title', '').lower()
                    
                    # Categorize into epics based on functionality
                    epic_key = None
                    if any(term in story_title for term in ['login', 'auth', 'signin', 'register', 'password']):
                        epic_key = f"Epic E{epic_counter} - User Authentication System"
                    elif any(term in story_title for term in ['profile', 'account', 'settings', 'manage']):
                        epic_key = f"Epic E{epic_counter} - User Account Management"
                    elif any(term in story_title for term in ['dashboard', 'overview', 'analytics', 'report']):
                        epic_key = f"Epic E{epic_counter} - Dashboard & Analytics"
                    elif any(term in story_title for term in ['create', 'add', 'new', 'form']):
                        epic_key = f"Epic E{epic_counter} - Data Creation & Input"
                    elif any(term in story_title for term in ['list', 'view', 'display', 'browse']):
                        epic_key = f"Epic E{epic_counter} - Data Display & Navigation"
                    elif any(term in story_title for term in ['admin', 'manage', 'control', 'configure']):
                        epic_key = f"Epic E{epic_counter} - Administrative Controls"
                    else:
                        epic_key = f"Epic E{epic_counter} - Core Business Logic"
                    
                    if epic_key not in epic_map:
                        epic_map[epic_key] = []
                        if epic_key.startswith(f"Epic E{epic_counter}"):
                            epic_counter += 1
                    
                    epic_map[epic_key].append(story)
                
                # Display stories grouped by Epic
                for epic_name, stories in epic_map.items():
                    document += f"**{epic_name}**:\n"
                    for story in stories:
                        story_id = story.get('id', 'US001')
                        story_title = story.get('title', 'User Story')
                        story_priority = story.get('priority', 'Medium')
                        
                        document += f"â€¢ **{story_id}**: {story_title}\n"
                        if story.get('description'):
                            desc = story['description'][:80] + "..." if len(story['description']) > 80 else story['description']
                            document += f"  â—¦ {desc}\n"
                        document += f"  â—¦ Priority: {story_priority}\n"
                    document += "\n"
            else:
                document += "â€¢ Core functionality as defined in system architecture\n"

            document += f"""
### 3. Conceptual Design

**Architecture Pattern**: {'Component-based architecture with React' if analysis['is_frontend'] else 'Microservice architecture with REST APIs' if analysis['is_backend'] else 'Relational database design' if analysis['is_database'] else 'Infrastructure service pattern'}
**Design Approach**: {'Responsive UI with component hierarchy' if analysis['is_frontend'] else 'Service-oriented with clear API boundaries' if analysis['is_backend'] else 'Normalized data schema with optimized queries' if analysis['is_database'] else 'High availability with redundancy'}

**Key Design Decisions**:
â€¢ Technology stack: {', '.join(component.get('technologies', ['Not specified']))}
â€¢ {'State management through Redux/Context API' if analysis['is_frontend'] else 'Stateless service design with JWT authentication' if analysis['is_backend'] else 'ACID compliance with optimistic locking' if analysis['is_database'] else 'Load balancing with health checks'}
â€¢ {'Client-side routing with lazy loading' if analysis['is_frontend'] else 'RESTful API design following OpenAPI standards' if analysis['is_backend'] else 'Indexing strategy for query performance' if analysis['is_database'] else 'Caching strategy for performance optimization'}

### 4. API Endpoints

{generate_api_table(component, analysis, mapped_stories)}

### 5. UI Modules / Screens

{generate_ui_table(component, analysis, mapped_stories)}

### 6. Class Diagram / Modules

**Primary Modules**:
- {'Component classes and hooks' if analysis['is_frontend'] else 'Service classes and business logic' if analysis['is_backend'] else 'Entity models and repositories' if analysis['is_database'] else 'Infrastructure modules'}
- Data models and interfaces  
- Utility and helper modules
- Configuration and constants

### 6. Database Design

{generate_sql_schema(component, analysis, mapped_stories)}

### 7. Business Logic & Validation

**Core Business Rules**:
â€¢ {'Input validation and user feedback' if analysis['is_frontend'] else 'Business rule validation and data processing' if analysis['is_backend'] else 'Data integrity and consistency enforcement' if analysis['is_database'] else 'Service availability and performance monitoring'}
â€¢ {'Client-side validation with server confirmation' if analysis['is_frontend'] else 'Authentication and authorization checks' if analysis['is_backend'] else 'Transaction management and rollback procedures' if analysis['is_database'] else 'Auto-scaling based on demand'}

**Validation Rules**:
â€¢ All entity creation requires proper field validation
â€¢ Business workflow checks at required field validation
â€¢ User permission validation for restricted endpoints

### 8. Integration Points

**Internal Integrations**:
â€¢ {'API integration with backend services' if analysis['is_frontend'] else 'Database connectivity and ORM integration' if analysis['is_backend'] else 'Application layer connectivity' if analysis['is_database'] else 'Cross-service communication'}
â€¢ {'State synchronization across components' if analysis['is_frontend'] else 'Message queue integration for async processing' if analysis['is_backend'] else 'Backup and replication coordination' if analysis['is_database'] else 'Load balancer and proxy configuration'}

**External Integrations**:
- {'CDN for static assets and performance' if analysis['is_frontend'] else 'Third-party API integrations' if analysis['is_backend'] else 'External backup and monitoring services' if analysis['is_database'] else 'Cloud infrastructure services'}

### 9. Security & Authorization

**Security Measures**:
- {'HTTPS enforcement and XSS protection' if analysis['is_frontend'] else 'JWT authentication and role-based access' if analysis['is_backend'] else 'Data encryption at rest and in transit' if analysis['is_database'] else 'Network security and access controls'}
- {'Input sanitization and validation' if analysis['is_frontend'] else 'SQL injection prevention and input validation' if analysis['is_backend'] else 'User access controls and audit trails' if analysis['is_database'] else 'Service isolation and security monitoring'}
- Role-based Access Control (RBAC): implement checks
- Authentication and data checks required for requests

### 10. Error Handling & Edge Cases

**Error Categories**:
- {'UI errors and validation failures (client-side)' if analysis['is_frontend'] else 'Business logic errors (400-499 HTTP codes)' if analysis['is_backend'] else 'Database connection and query errors' if analysis['is_database'] else 'Service availability and network errors'}
- Integration failures and timeout handling
- Data validation and constraint violations

**Recovery Strategies**:
- {'Graceful degradation and offline functionality' if analysis['is_frontend'] else 'Circuit breaker pattern for external services' if analysis['is_backend'] else 'Automatic failover and replica promotion' if analysis['is_database'] else 'Auto-restart and health-check recovery'}
- Retry logic: Exponential backoff for external APIs

### 11. Testing Strategy

**Unit Tests**: {comp_name}Modules
- All Service layer logic for a user, I want to test new customer records, so that I can keep track of all interactions
- UI Service layer logic for a user, I want to generate reports on customer interactions, so that I can analyze engagement
- All Service layer logic for an admin, I want to view analytics dashboards, so that I can track system usage and user patterns

**Integration Tests**: API endpoints function with database
- All business logic paths through comprehensive tests
- Coverage Target: >80% code coverage
- Contract Testing: API responses conform to database

### 12. Performance & Scalability

**Background Jobs**: Queue heavy operations (QuickProfilesJobQueue)
**Response Caching**: Redis for frequently accessed data (5-15 min TTL)
**Horizontal Scaling**: Load balancer &plus; multiple service instances 
**Database Connection Pooling**: Max 15 connections per instance
- {'Page load times and user interactions' if analysis['is_frontend'] else 'API response times and error rates' if analysis['is_backend'] else 'Query performance and connection pool usage' if analysis['is_database'] else 'Component performance metrics'}

---

"""

        # Document summary
        document += f"""
## Summary

This Component-Wise LLD document covers {len(system_components)} system components with comprehensive 12-section analysis for each component.

**Generated Content Statistics**:
- Total Components Analyzed: {len(system_components)}
- User Stories Mapped: {len(user_stories)}
- Complete 12-Section Structure: âœ…
- API Endpoints Generated: {'âœ…' if any(analyze_component(c)['has_api'] for c in system_components) else 'N/A'}
- UI Modules Generated: {'âœ…' if any(analyze_component(c)['has_ui'] for c in system_components) else 'N/A'}
- SQL Schemas Generated: {'âœ…' if any(analyze_component(c)['stores_data'] for c in system_components) else 'N/A'}

**Quality Features**:
- Complete 12-section structure per component
- Context-aware content generation based on component type
- Story-to-component mapping with relevance scoring
- Technical depth appropriate for implementation teams
- Production-ready specifications and guidelines

**12-Section Structure per Component**:
1. Purpose & Mapped User Stories
2. Conceptual Design  
3. API Endpoints
4. UI Modules / Screens
5. Class Diagram / Modules
6. Database Design
7. Business Logic & Validation
8. Integration Points
9. Security & Authorization
10. Error Handling & Edge Cases
11. Testing Strategy
12. Performance & Scalability

Generated with enhanced AI analysis for technical accuracy and implementation readiness.
"""

        elapsed = time.time() - start_time
        doc_length = len(document)
        print(f"[TIMING] Generation complete in {elapsed:.2f} seconds")
        print(f"[INFO] Generated document: {doc_length} chars")
        
        return {
            "component_wise_lld_document": document,
            "generated_at": datetime.now().isoformat(),
            "metadata": {
                "components_count": len(system_components),
                "stories_count": len(user_stories),
                "sections_per_component": 12,
                "generation_method": "complete_12_section_structure_with_separated_purpose",
                "features": [
                    "Complete 12-section structure",
                    "Purpose (Section 1)",
                    "Mapped User Stories (Section 2)", 
                    "Conceptual Design",
                    "API Endpoints", 
                    "UI Modules / Screens",
                    "Class Diagram / Modules",
                    "Database Design (Box Format)",
                    "Business Logic & Validation",
                    "Integration Points",
                    "Security & Authorization", 
                    "Error Handling & Edge Cases",
                    "Testing Strategy",
                    "Performance & Scalability"
                ]
            }
        }

    
    async def _generate_user_story_dev_delivery(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Generate code deliverables for Phase 5 using AI-powered code generation.
        Uses OpenAI to generate REAL, UNIQUE code for each user story.
        FULLY DYNAMIC - ONLY generates what's relevant to selected components.
        """
        from datetime import datetime
        import time
        import json
        
        start_time = time.time()
        print("[PHASE5] ========== AI-POWERED CODE GENERATION STARTED ==========")
        
        # Extract context
        user_story = data.get('user_story', {})
        story_id = user_story.get('story_id') or user_story.get('id')
        
        selected_components = data.get('selected_components', [])
        selected_component_names = data.get('selected_component_names', [])
        preferences = data.get('preferences', {})
        
        story_title = user_story.get('title', '')
        story_desc = user_story.get('description', '')
        story_criteria = user_story.get('acceptanceCriteria', [])
        
        # Normalize component data
        if isinstance(selected_components, list) and len(selected_components) > 0:
            if isinstance(selected_components[0], dict):
                component_names = [c.get('name', '') for c in selected_components]
                component_types = [c.get('type', '') for c in selected_components]
            else:
                component_names = selected_component_names or selected_components
                component_types = []
        else:
            component_names = selected_component_names or []
            component_types = []
        
        language = preferences.get('language', 'python')
        test_framework = preferences.get('tests', 'pytest')
        
        print(f"\n[PHASE5] ðŸ“– USER STORY CONTEXT:")
        print(f"   Story ID: {story_id}")
        print(f"   Story Title: '{story_title}'")
        print(f"   Description: {story_desc[:80] if story_desc else 'N/A'}")
        print(f"   Criteria: {len(story_criteria) if isinstance(story_criteria, list) else 0} items")
        print(f"   Components: {component_names}")
        print(f"   Tech: {language}, {test_framework}\n")
        
        # Check for API components - must explicitly have "API" in the name
        # Don't use generic keywords like 'service' or 'backend' as those can be UI or other layers
        api_component_keywords = ['api', 'gateway', 'router', 'endpoint']  # Removed 'backend' and 'service' - too generic
        has_api_component = any(
            keyword in comp_name.lower() 
            for comp_name in component_names 
            for keyword in api_component_keywords
        )
        
        print(f"[PHASE5] API Keywords: {api_component_keywords}")
        print(f"[PHASE5] Component names lower: {[c.lower() for c in component_names]}")
        print(f"[PHASE5] Has API component: {has_api_component}\n")
        
        # === LANGUAGE-SPECIFIC CONFIGURATION ===
        lang_lower = language.lower() if language else 'python'
        
        # Determine file extensions and framework based on language
        if 'node' in lang_lower or 'javascript' in lang_lower or 'express' in lang_lower:
            service_ext = '.js'
            router_ext = '.js'
            test_ext = '.js'
            lang_display = 'JavaScript (Express)'
            framework = 'Express.js'
            service_template = 'class'
            test_framework_name = test_framework if 'jest' in test_framework.lower() or 'mocha' in test_framework.lower() else 'Jest'
        elif 'typescript' in lang_lower:
            service_ext = '.ts'
            router_ext = '.ts'
            test_ext = '.ts'
            lang_display = 'TypeScript'
            framework = 'Express.js with TypeScript'
            service_template = 'class'
            test_framework_name = test_framework if 'jest' in test_framework.lower() else 'Jest'
        elif 'python' in lang_lower or 'fastapi' in lang_lower:
            service_ext = '.py'
            router_ext = '.py'
            test_ext = '.py'
            lang_display = 'Python'
            framework = 'FastAPI'
            service_template = 'class'
            test_framework_name = test_framework if 'pytest' in test_framework.lower() else 'pytest'
        elif 'java' in lang_lower:
            service_ext = '.java'
            router_ext = '.java'
            test_ext = '.java'
            lang_display = 'Java'
            framework = 'Spring Boot'
            service_template = 'class'
            test_framework_name = 'JUnit'
        elif 'go' in lang_lower or 'golang' in lang_lower:
            service_ext = '.go'
            router_ext = '.go'
            test_ext = '_test.go'
            lang_display = 'Go'
            framework = 'Gin/Echo'
            service_template = 'struct'
            test_framework_name = 'testing'
        elif 'dotnet' in lang_lower or 'csharp' in lang_lower or 'c#' in lang_lower:
            service_ext = '.cs'
            router_ext = '.cs'
            test_ext = '.cs'
            lang_display = 'C#'
            framework = '.NET Core'
            service_template = 'class'
            test_framework_name = 'xUnit'
        else:
            service_ext = '.py'
            router_ext = '.py'
            test_ext = '.py'
            lang_display = 'Python'
            framework = 'FastAPI'
            service_template = 'class'
            test_framework_name = 'pytest'
        
        print(f"[PHASE5] ðŸ”§ Language Config: {lang_display} | Framework: {framework} | Tests: {test_framework_name}")
        
        # Convert story title to code names
        pascal_case_name = self._to_pascal_case(story_title) if story_title else 'Feature'
        snake_case_name = self._to_snake_case(story_title) if story_title else 'feature'
        kebab_case_name = snake_case_name.replace('_', '-')
        camel_case_name = self._to_camel_case(story_title) if story_title else 'feature'
        
        code_files = []
        test_files = []
        api_endpoints = []
        
        try:
            # === GENERATE SERVICE CODE WITH AI (Language-Aware) ===
            print(f"[PHASE5] ðŸ¤– Generating service code via OpenAI ({lang_display})...")
            
            service_prompt = f"""Generate a professional {lang_display} service implementation for the following user story:

**User Story:** {story_title}
**Description:** {story_desc}
**Acceptance Criteria:** {', '.join(story_criteria[:3]) if story_criteria else 'N/A'}
**Components:** {', '.join(component_names)}
**Language:** {lang_display}
**Framework:** {framework}

Requirements:
1. Create a {service_template} named {pascal_case_name}Service
2. Include proper initialization/constructor with version and metadata
3. Implement relevant methods based on the story (e.g., create, read, update, delete if applicable)
4. Add proper documentation/comments and error handling
5. Return appropriate data structures for {lang_display}
6. Include logging where appropriate
7. Use {lang_display} idioms and best practices
8. Make it production-ready

Generate ONLY valid {lang_display} code. Start with proper module/package declarations."""

            service_response = await self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": f"You are an expert {lang_display} developer specializing in {framework}. Generate production-ready, idiomatic code."},
                    {"role": "user", "content": service_prompt}
                ],
                temperature=0.7,
                max_tokens=1500
            )
            
            service_code = service_response.choices[0].message.content.strip()
            
            code_files.append({
                "file": f"{snake_case_name}_service{service_ext}",
                "language": lang_display,
                "content": service_code
            })
            
            elapsed = time.time() - start_time
            print(f"[PHASE5] âœ… Service code generated ({elapsed:.2f}s)")
            
            # === GENERATE API CODE IF NEEDED (Language-Aware) ===
            if has_api_component:
                print(f"[PHASE5] ðŸ¤– Generating API router code via OpenAI ({lang_display})...")
                
                api_framework = 'Express.js' if 'node' in lang_lower or 'javascript' in lang_lower else (
                    'Express.js with TypeScript' if 'typescript' in lang_lower else (
                    'FastAPI' if 'python' in lang_lower else (
                    'Spring Boot' if 'java' in lang_lower else (
                    'Gin/Echo' if 'go' in lang_lower else (
                    '.NET Core' if 'dotnet' in lang_lower or 'csharp' in lang_lower else 'Express.js'
                )))))
                
                api_prompt = f"""Generate a {lang_display} API router for the following user story:

**Story:** {story_title}
**Description:** {story_desc}
**Components:** {', '.join(component_names)}
**Framework:** {api_framework}
**Service Class/Module:** {pascal_case_name}Service

Requirements:
1. Create router with appropriate routing mechanism for {api_framework}
2. Define request/response models appropriate for {lang_display}
3. Implement ONLY relevant endpoints for this story (don't force CRUD)
4. Include proper status codes and error handling
5. Add logging for each endpoint
6. Import and use the service
7. Add proper type hints/annotations for {lang_display}
8. Use {lang_display} idioms and framework conventions

Generate ONLY valid {lang_display} code with all necessary imports."""

                api_response = await self.client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": f"You are an expert {lang_display} API developer using {api_framework}. Generate production-ready API code specific to this story."},
                        {"role": "user", "content": api_prompt}
                    ],
                    temperature=0.7,
                    max_tokens=2000
                )
                
                api_router_code = api_response.choices[0].message.content.strip()
                
                code_files.append({
                    "file": f"{snake_case_name}_router{router_ext}",
                    "language": lang_display,
                    "content": api_router_code
                })
                
                # Extract endpoints from generated code - parse @router.method decorators
                import re
                api_endpoints = []
                
                # Find all decorator lines like @router.post("/path"), @router.get, etc
                # Pattern matches @router.METHOD("path") or @router.METHOD('/path')
                decorator_pattern = r'@router\.(get|post|put|delete|patch|head|options)\s*\(\s*["\']([^"\']+)["\']'
                matches = re.findall(decorator_pattern, api_router_code, re.IGNORECASE)
                
                if matches:
                    print(f"[PHASE5] ðŸ” Found {len(matches)} API endpoints in generated code:")
                    for method, path in matches:
                        # Construct full path if not already /api/...
                        if not path.startswith('/api'):
                            full_path = f"/api/{snake_case_name}{path}"
                        else:
                            full_path = path
                        
                        api_endpoints.append({
                            "method": method.upper(),
                            "path": full_path,
                            "description": f"{method.upper()} endpoint"
                        })
                        print(f"   âœ“ {method.upper()} {full_path}")
                    
                    elapsed = time.time() - start_time
                    print(f"[PHASE5] âœ… API code generated ({elapsed:.2f}s) with {len(api_endpoints)} endpoint(s)")
                else:
                    print(f"[PHASE5] âš ï¸  No API endpoints found in generated code for story: {story_title}")
                    print(f"[PHASE5]    This may happen if AI generated non-standard decorator patterns")
                    print(f"[PHASE5]    Generated code sample: {api_router_code[:200]}...")
                    
                    # Try to generate smart defaults based on story semantics
                    print(f"[PHASE5] ðŸ”„ Generating smart API endpoints based on story context...")
                    
                    # Analyze story to determine likely CRUD operations
                    story_lower = story_title.lower()
                    has_create = any(word in story_lower for word in ['create', 'add', 'new', 'save', 'register', 'submit'])
                    has_read = any(word in story_lower for word in ['read', 'get', 'view', 'fetch', 'show', 'list', 'display', 'view'])
                    has_update = any(word in story_lower for word in ['update', 'edit', 'modify', 'change', 'save'])
                    has_delete = any(word in story_lower for word in ['delete', 'remove', 'discard', 'cancel'])
                    
                    # Generate endpoints based on detected operations
                    base_path = f"/api/{snake_case_name}"
                    
                    if has_create or (has_read and not has_update and not has_delete):  # Default to POST for basic creation
                        api_endpoints.append({
                            "method": "POST",
                            "path": f"{base_path}/",
                            "description": f"Create {story_title.lower()}"
                        })
                    
                    if has_read:
                        api_endpoints.append({
                            "method": "GET",
                            "path": f"{base_path}/",
                            "description": f"List {story_title.lower()}"
                        })
                        api_endpoints.append({
                            "method": "GET",
                            "path": f"{base_path}/{{id}}",
                            "description": f"Get {story_title.lower()} by ID"
                        })
                    
                    if has_update:
                        api_endpoints.append({
                            "method": "PUT",
                            "path": f"{base_path}/{{id}}",
                            "description": f"Update {story_title.lower()}"
                        })
                    
                    if has_delete:
                        api_endpoints.append({
                            "method": "DELETE",
                            "path": f"{base_path}/{{id}}",
                            "description": f"Delete {story_title.lower()}"
                        })
                    
                    # If no operations detected, provide minimal CRUD
                    if not api_endpoints:
                        api_endpoints = [
                            {"method": "POST", "path": f"{base_path}/", "description": f"Create {story_title.lower()}"},
                            {"method": "GET", "path": f"{base_path}/", "description": f"List {story_title.lower()}"},
                            {"method": "GET", "path": f"{base_path}/{{id}}", "description": f"Get {story_title.lower()} by ID"},
                        ]
                    
                    elapsed = time.time() - start_time
                    print(f"[PHASE5] âœ… Smart API endpoints generated ({elapsed:.2f}s) with {len(api_endpoints)} endpoint(s)")
                    for ep in api_endpoints:
                        print(f"   âœ“ {ep['method']} {ep['path']}")
            else:
                print("[PHASE5] â­ï¸  Skipping API code (no API component selected)")
                api_endpoints = []
            
            # === GENERATE TESTS WITH AI (Language-Aware) ===
            print(f"[PHASE5] ðŸ¤– Generating test code via OpenAI ({lang_display})...")
            
            # Map test framework to language if needed
            if 'node' in lang_lower or 'javascript' in lang_lower or 'typescript' in lang_lower:
                if 'jest' not in test_framework.lower() and 'mocha' not in test_framework.lower():
                    test_framework_display = 'Jest'
                else:
                    test_framework_display = test_framework
            elif 'python' in lang_lower or 'fastapi' in lang_lower:
                if 'pytest' not in test_framework.lower():
                    test_framework_display = 'pytest'
                else:
                    test_framework_display = test_framework
            elif 'java' in lang_lower:
                test_framework_display = 'JUnit'
            elif 'go' in lang_lower:
                test_framework_display = 'Go testing package'
            elif 'csharp' in lang_lower or 'dotnet' in lang_lower:
                test_framework_display = 'xUnit'
            else:
                test_framework_display = test_framework
            
            test_prompt = f"""Generate comprehensive unit tests for the following in {test_framework_display}:

**Story:** {story_title}
**Language:** {lang_display}
**Test Framework:** {test_framework_display}
**Service Class:** {pascal_case_name}Service
**Components:** {', '.join(component_names)}
{f'**Include API Tests:** Yes (router in {snake_case_name}_router.py)' if has_api_component else '**Include API Tests:** No'}

Requirements:
1. Create a test class or suite for Test{pascal_case_name}Service
2. Include setup/teardown methods if needed ({lang_display} specific)
3. Test service initialization
4. Test main service methods with various inputs
5. Add assertions for expected behavior
6. Include edge case tests
7. Use {test_framework_display} features (fixtures, mocking, etc.)
{f'8. Include API endpoint tests' if has_api_component else ''}
9. Use {lang_display} conventions and idioms

Generate ONLY valid {lang_display} test code using {test_framework_display}. Include all necessary imports and follow {lang_display} best practices."""

            test_response = await self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": f"You are an expert {lang_display} test developer using {test_framework_display}. Generate comprehensive, production-ready test code in {lang_display}."},
                    {"role": "user", "content": test_prompt}
                ],
                temperature=0.7,
                max_tokens=1500
            )
            
            test_code = test_response.choices[0].message.content.strip()
            
            test_files.append({
                "file": f"test_{snake_case_name}{test_ext}",
                "language": lang_display,
                "content": test_code
            })
            
            elapsed = time.time() - start_time
            print(f"[PHASE5] âœ… Test code generated ({elapsed:.2f}s)")
            
        except Exception as e:
            print(f"[PHASE5] âŒ AI Generation Error: {str(e)}")
            print("[PHASE5] âš ï¸  Falling back to template generation...")
            
            # Fallback to template if AI fails (Language-aware)
            if 'node' in lang_lower or 'javascript' in lang_lower:
                service_code = f'''/**
 * {story_title} - Business Logic Implementation (Fallback)
 */

class {pascal_case_name}Service {{
  constructor() {{
    this.name = "{pascal_case_name}";
    this.version = "1.0.0";
  }}

  execute(params = {{}}) {{
    return {{
      status: "success",
      message: "Executed",
      components: {component_names},
      data: {{}}
    }};
  }}
}}

module.exports = {pascal_case_name}Service;
'''
                test_code = f'''/**
 * Tests for {story_title}
 */
const {pascal_case_name}Service = require('./{snake_case_name}_service');

describe('{pascal_case_name}Service', () => {{
  let service;

  beforeEach(() => {{
    service = new {pascal_case_name}Service();
  }});

  test('should initialize correctly', () => {{
    expect(service.name).toBe("{pascal_case_name}");
  }});
}});
'''
            elif 'python' in lang_lower:
                service_code = f'''"""
{story_title} - Business Logic Implementation (Fallback)
"""

class {pascal_case_name}Service:
    """Service for {story_title.lower()}"""
    
    def __init__(self):
        self.name = "{pascal_case_name}"
        self.version = "1.0.0"
    
    def execute(self, **kwargs):
        """Execute service logic"""
        return {{"status": "success", "message": "Executed", "components": {component_names}}}

{snake_case_name}_service = {pascal_case_name}Service()
'''
                test_code = f'''"""Tests for {story_title}"""
import pytest
from {snake_case_name}_service import {snake_case_name}_service

class Test{pascal_case_name}Service:
    def test_initialization(self):
        assert {snake_case_name}_service.name == "{pascal_case_name}"
'''
            elif 'java' in lang_lower:
                service_code = f'''/**
 * {story_title} - Business Logic Implementation (Fallback)
 */
public class {pascal_case_name}Service {{
    private String name;
    private String version;

    public {pascal_case_name}Service() {{
        this.name = "{pascal_case_name}";
        this.version = "1.0.0";
    }}

    public Map<String, Object> execute(Map<String, Object> params) {{
        return Map.of(
            "status", "success",
            "message", "Executed",
            "components", {component_names}
        );
    }}
}}
'''
                test_code = f'''/**
 * Tests for {story_title}
 */
import org.junit.jupiter.api.Test;
import static org.junit.jupiter.api.Assertions.*;

public class Test{pascal_case_name}Service {{
    @Test
    void testInitialization() {{
        {pascal_case_name}Service service = new {pascal_case_name}Service();
        assertEquals("{pascal_case_name}", service.getName());
    }}
}}
'''
            else:
                # Default to Python
                service_code = f'''"""
{story_title} - Business Logic Implementation (Fallback)
"""

class {pascal_case_name}Service:
    """Service for {story_title.lower()}"""
    
    def __init__(self):
        self.name = "{pascal_case_name}"
        self.version = "1.0.0"
    
    def execute(self, **kwargs):
        """Execute service logic"""
        return {{"status": "success", "message": "Executed", "components": {component_names}}}
'''
                test_code = f'''"""Tests for {story_title}"""
import pytest
from {snake_case_name}_service import {snake_case_name}_service

class Test{pascal_case_name}Service:
    def test_initialization(self):
        assert {snake_case_name}_service.name == "{pascal_case_name}"
'''
            
            code_files.append({
                "file": f"{snake_case_name}_service{service_ext}",
                "language": lang_display,
                "content": service_code
            })
            
            test_files.append({
                "file": f"test_{snake_case_name}{test_ext}",
                "language": lang_display,
                "content": test_code
            })
        
        # === GENERATE README ===
        readme_content = f"""# {story_title}

## Overview
{story_desc or 'No description provided'}

## Configuration
- **Language:** {lang_display}
- **Framework:** {framework}
- **Test Framework:** {test_framework_display}
- **Components:** {', '.join(component_names)}

## User Story
**ID:** {story_id}  
**Title:** {story_title}

## Acceptance Criteria
{chr(10).join([f"- {c}" for c in story_criteria[:5]]) if story_criteria else "N/A"}

## Selected Components
{chr(10).join([f"- {c}" for c in component_names]) if component_names else "N/A"}

## Technology Stack
- **Language:** {lang_display}
- **Framework:** {framework}
- **Test Framework:** {test_framework_display}

## Generated Code Structure
- `{snake_case_name}_service{service_ext}` - Business logic implementation ({lang_display})
{f'- `{snake_case_name}_router{router_ext}` - {framework} router and endpoints' if has_api_component else ''}
- `test_{snake_case_name}{test_ext}` - Comprehensive test suite ({test_framework_display})

## API Endpoints
{f'''| Method | Path | Description |
|--------|------|-------------|
{chr(10).join([f"| {ep['method']} | `{ep['path']}` | {ep['description']} |" for ep in api_endpoints])}''' if has_api_component and api_endpoints else 'N/A - No API component selected for this story'}

## Implementation Notes
- Code was generated using AI-powered code generation tailored to this specific story
- Service logic handles the unique requirements of: **{story_title}**
{f'- API endpoints provide REST interface based on story requirements' if has_api_component and api_endpoints else '- No API endpoints generated (API component not selected or not applicable)'}
- Comprehensive tests ensure functionality and reliability
- All code is production-ready and follows {lang_display} best practices

## How to Use
1. Review the generated code files in this package
2. Integrate `{snake_case_name}_service{service_ext}` into your backend application
{f'3. Include `{snake_case_name}_router{router_ext}` in your {framework} application' if has_api_component and api_endpoints else ''}
3. Run the test suite using {test_framework_display}: `{test_framework_name} test_{snake_case_name}{test_ext}`
4. Customize as needed for your specific deployment environment

---
Generated by TAO SDLC Phase 5 (AI-Powered Generation)  
User Story: {story_title}  
Components: {', '.join(component_names) if component_names else 'N/A'}  
Language: {lang_display}  
Generation Method: {f'AI-Generated with {len(api_endpoints)} API endpoint(s)' if has_api_component and api_endpoints else 'AI-Generated (No API)'}
"""
        
        elapsed = time.time() - start_time
        print(f"\n[PHASE5] âœ… Generation complete in {elapsed:.2f}s")
        print(f"[PHASE5] Generated {len(code_files)} code file(s), {len(test_files)} test file(s)")
        print(f"[PHASE5] API Endpoints: {len(api_endpoints)}")
        print(f"[PHASE5] Language: {lang_display} | Framework: {framework} | Tests: {test_framework_display}")
        print(f"[PHASE5] ========== COMPLETE ==========\n")
        
        result = {
            "code": code_files,
            "tests": test_files,
            "api": {"endpoints": api_endpoints},
            "readme": readme_content,
            "metadata": {
                "story_id": story_id,
                "story_title": story_title,
                "components": component_names,
                "has_api": has_api_component,
                "language": lang_display,
                "framework": framework,
                "test_framework": test_framework_display,
                "generated_at": datetime.now().isoformat(),
                "generation_time_seconds": elapsed,
                "generation_method": "AI-Powered" if elapsed > 1 else "Template-Fallback"
            }
        }
        
        return result
        
        elapsed = time.time() - start_time
        print(f"\n[PHASE5] âœ… Generation complete in {elapsed:.2f}s")
        print(f"[PHASE5] Generated {len(code_files)} code file(s), {len(test_files)} test file(s)")
        print(f"[PHASE5] API Endpoints: {len(api_endpoints)}")
        print(f"[PHASE5] ========== COMPLETE ==========\n")
        
        result = {
            "code": code_files,
            "tests": test_files,
            "api": {"endpoints": api_endpoints},
            "readme": readme_content,
            "metadata": {
                "story_id": story_id,
                "story_title": story_title,
                "components": component_names,
                "has_api": has_api_component,
                "language": language,
                "test_framework": test_framework,
                "generated_at": datetime.now().isoformat(),
                "generation_time_seconds": elapsed,
                "generation_method": "AI-Powered" if elapsed > 1 else "Template-Fallback"
            }
        }
        
        return result
    
    def _to_pascal_case(self, text: str) -> str:
        """Convert text to PascalCase"""
        words = text.replace('-', ' ').replace('_', ' ').split()
        return ''.join(word.capitalize() for word in words if word)
    
    def _to_camel_case(self, text: str) -> str:
        """Convert text to camelCase"""
        pascal = self._to_pascal_case(text)
        return pascal[0].lower() + pascal[1:] if pascal else ''
    
    def _to_snake_case(self, text: str) -> str:
        """Convert text to snake_case"""
        import re
        s1 = re.sub('(.)([A-Z][a-z]+)', r'\1_\2', text)
        return re.sub('([a-z0-9])([A-Z])', r'\1_\2', s1).lower().replace(' ', '_').replace('-', '_')

    async def generate_api_summary(self, openapi_spec: Dict[str, Any]) -> str:
        """
        Generate a high-level summary of the API specification
        
        Args:
            openapi_spec: Complete OpenAPI specification
            
        Returns:
            Markdown formatted summary
        """
        print("[INFO] Generating API summary using AI")
        
        # Extract key information
        info = openapi_spec.get('info', {})
        paths = openapi_spec.get('paths', {})
        tags = openapi_spec.get('tags', [])
        
        # Count endpoints by method
        method_counts = {}
        endpoint_list = []
        
        for path, methods in paths.items():
            for method in methods.keys():
                method_upper = method.upper()
                method_counts[method_upper] = method_counts.get(method_upper, 0) + 1
                endpoint_list.append(f"{method_upper} {path}")
        
        total_endpoints = len(endpoint_list)
        
        # Prepare context for AI
        endpoints_summary = '\n'.join([f"- {ep}" for ep in endpoint_list[:20]])  # First 20
        if len(endpoint_list) > 20:
            endpoints_summary += f"\n... and {len(endpoint_list) - 20} more"
        
        tags_summary = ', '.join([t.get('name', '') for t in tags]) if tags else 'Not categorized'
        
        # Build prompt without problematic f-string with triple quotes
        prompt_lines = [
            "You are an expert API documentation writer. Analyze this API specification and create a concise, insightful executive summary.",
            "",
            f"API Title: {info.get('title', 'API')}",
            f"Version: {info.get('version', '1.0.0')}",
            f"Description: {info.get('description', 'No description')}",
            "",
            f"Total Endpoints: {total_endpoints}",
            f"Methods: {', '.join([f'{method}: {count}' for method, count in method_counts.items()])}",
            f"Categories: {tags_summary}",
            "",
            "Endpoints Summary:",
            endpoints_summary,
            "",
            "Create a summary with:",
            "1. Overview (2-3 sentences)",
            "2. Key Features (bullet points)",
            "3. Endpoint Breakdown",
            "4. Authentication",
            "5. Best Use Cases",
            "",
            "Keep it concise (200-300 words). Return in markdown format."
        ]
        prompt = "\n".join(prompt_lines)

        try:
            response = await self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system",
                        "content": "You are an expert technical writer creating clear API documentation summaries."
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.5,
                max_tokens=800
            )
            
            summary = response.choices[0].message.content.strip()
            print("[OK] Generated API summary")
            return summary
            
        except Exception as e:
            print(f"[WARNING] Failed to generate AI summary: {str(e)}, using basic summary")
            
            # Fallback summary
            methods_str = ", ".join([f"{method} ({count})" for method, count in method_counts.items()])
            return f"## API Summary\n\n**{info.get('title', 'API')}** (v{info.get('version', '1.0.0')})\n\n{info.get('description', 'No description')}\n\n### Statistics\n- **Total Endpoints**: {total_endpoints}\n- **HTTP Methods**: {methods_str}\n- **Categories**: {tags_summary}\n\n### Purpose\nThis API provides programmatic access through RESTful endpoints."

    # ========================================================================
    # PHASE 5 PERSISTENCE METHODS
    # ========================================================================
    
    def get_persisted_deliverable(self, db, project_id: int, story_id: str) -> Dict[str, Any]:
        """
        Retrieve a persisted Phase 5 deliverable from the database
        
        Args:
            db: SQLAlchemy database session
            project_id: Project ID
            story_id: User story ID
            
        Returns:
            Formatted deliverable or None if not found
        """
        try:
            from app import models
            
            deliverable = db.query(models.Phase5Deliverable).filter(
                models.Phase5Deliverable.project_id == project_id,
                models.Phase5Deliverable.user_story_id == str(story_id)
            ).first()
            
            if not deliverable:
                print(f"[PHASE5_PERSIST] No deliverable found for story {story_id}")
                return None
            
            print(f"[PHASE5_PERSIST] Retrieved deliverable for story {story_id}")
            
            # Format as frontend expects
            return {
                "code": deliverable.code_content or [],
                "tests": deliverable.tests_content or [],
                "api": {
                    "endpoints": deliverable.api_endpoints or []
                },
                "readme": deliverable.readme_content or "",
                "metadata": {
                    "story_id": deliverable.user_story_id,
                    "story_title": deliverable.story_title,
                    "components_used": deliverable.selected_components or [],
                    "language": deliverable.language,
                    "test_framework": deliverable.test_framework,
                    "generated_at": deliverable.generated_at.isoformat() if deliverable.generated_at else None,
                    "updated_at": deliverable.updated_at.isoformat() if deliverable.updated_at else None
                }
            }
            
        except Exception as e:
            print(f"[ERROR] Failed to retrieve persisted deliverable: {str(e)}")
            return None
    
    def save_deliverable_to_db(self, db, project_id: int, deliverable: Dict[str, Any]) -> bool:
        """
        Save a Phase 5 deliverable to the database
        
        Args:
            db: SQLAlchemy database session
            project_id: Project ID
            deliverable: Deliverable dict with code, tests, api, readme, metadata
            
        Returns:
            True if saved successfully, False otherwise
        """
        try:
            from app import models
            from datetime import datetime
            
            metadata = deliverable.get("metadata", {})
            story_id = str(metadata.get("story_id", ""))
            
            if not story_id:
                print("[PHASE5_PERSIST] ERROR: No story_id in metadata")
                return False
            
            print(f"[PHASE5_PERSIST] Saving deliverable for story {story_id}")
            
            # Check if already exists
            existing = db.query(models.Phase5Deliverable).filter(
                models.Phase5Deliverable.project_id == project_id,
                models.Phase5Deliverable.user_story_id == story_id
            ).first()
            
            if existing:
                # Update existing
                print(f"[PHASE5_PERSIST] Updating existing deliverable for story {story_id}")
                existing.code_content = deliverable.get("code", [])
                existing.tests_content = deliverable.get("tests", [])
                existing.api_endpoints = deliverable.get("api", {}).get("endpoints", [])
                existing.readme_content = deliverable.get("readme", "")
                existing.story_title = metadata.get("story_title", "")
                existing.story_description = metadata.get("story_description", "")
                existing.epic_id = metadata.get("epic_id", "")
                existing.language = metadata.get("language", "")
                existing.test_framework = metadata.get("test_framework", "")
                existing.selected_components = metadata.get("components_used", [])
                existing.updated_at = datetime.utcnow()
                existing.ai_enhanced = metadata.get("ai_enhanced", False)
            else:
                # Create new
                print(f"[PHASE5_PERSIST] Creating new deliverable for story {story_id}")
                new_deliverable = models.Phase5Deliverable(
                    project_id=project_id,
                    user_story_id=story_id,
                    epic_id=metadata.get("epic_id", ""),
                    story_title=metadata.get("story_title", ""),
                    story_description=metadata.get("story_description", ""),
                    code_content=deliverable.get("code", []),
                    tests_content=deliverable.get("tests", []),
                    api_endpoints=deliverable.get("api", {}).get("endpoints", []),
                    readme_content=deliverable.get("readme", ""),
                    language=metadata.get("language", ""),
                    test_framework=metadata.get("test_framework", ""),
                    selected_components=metadata.get("components_used", []),
                    ai_enhanced=metadata.get("ai_enhanced", False)
                )
                db.add(new_deliverable)
            
            db.commit()
            print(f"[PHASE5_PERSIST] âœ… Deliverable saved for story {story_id}")
            return True
            
        except Exception as e:
            print(f"[ERROR] Failed to save deliverable to database: {str(e)}")
            db.rollback()
            return False

